{"prompt": "def reverse(input_string: str) -> str:\n    \"\"\"\n    Returns the string with its chars reversed.\n\n    *Example:*\n\n    >>> reverse('hello') # returns 'olleh'\n\n    :param input_string: String to revert.\n    :type input_string: str\n    :return: Reversed string.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/0", "ground_truth": "    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    return input_string[::-1]", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 281, "line_no": 293, "id": 0, "target_function_prompt": "def reverse(input_string: str) -> str:\n    \"\"\"\n    Returns the string with its chars reversed.\n\n    *Example:*\n\n    >>> reverse('hello') # returns 'olleh'\n\n    :param input_string: String to revert.\n    :type input_string: str\n    :return: Reversed string.\n    \"\"\"\n", "function_signature": "def reverse(input_string: str) -> str:"}}
{"prompt": "def camel_case_to_snake(input_string, separator='_'):\n    \"\"\"\n    Convert a camel case string into a snake case one.\n    (The original string is returned if is not a valid camel case string)\n\n    *Example:*\n\n    >>> camel_case_to_snake('ThisIsACamelStringTest') # returns 'this_is_a_camel_case_string_test'\n\n    :param input_string: String to convert.\n    :type input_string: str\n    :param separator: Sign to use as separator.\n    :type separator: str\n    :return: Converted string.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/1", "ground_truth": "    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    if not is_camel_case(input_string):\n        return input_string\n\n    return CAMEL_CASE_REPLACE_RE.sub(lambda m: m.group(1) + separator, input_string).lower()", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 299, "line_no": 314, "id": 1, "target_function_prompt": "def camel_case_to_snake(input_string, separator='_'):\n    \"\"\"\n    Convert a camel case string into a snake case one.\n    (The original string is returned if is not a valid camel case string)\n\n    *Example:*\n\n    >>> camel_case_to_snake('ThisIsACamelStringTest') # returns 'this_is_a_camel_case_string_test'\n\n    :param input_string: String to convert.\n    :type input_string: str\n    :param separator: Sign to use as separator.\n    :type separator: str\n    :return: Converted string.\n    \"\"\"\n", "function_signature": "def camel_case_to_snake(input_string, separator='_'):"}}
{"prompt": "def snake_case_to_camel(input_string: str, upper_case_first: bool = True, separator: str = '_') -> str:\n    \"\"\"\n    Convert a snake case string into a camel case one.\n    (The original string is returned if is not a valid snake case string)\n\n    *Example:*\n\n    >>> snake_case_to_camel('the_snake_is_green') # returns 'TheSnakeIsGreen'\n\n    :param input_string: String to convert.\n    :type input_string: str\n    :param upper_case_first: True to turn the first letter into uppercase (default).\n    :type upper_case_first: bool\n    :param separator: Sign to use as separator (default to \"_\").\n    :type separator: str\n    :return: Converted string\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/2", "ground_truth": "    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    if not is_snake_case(input_string, separator):\n        return input_string\n\n    tokens = [s.title() for s in input_string.split(separator) if is_full_string(s)]\n\n    if not upper_case_first:\n        tokens[0] = tokens[0].lower()\n\n    out = ''.join(tokens)\n\n    return out", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 323, "line_no": 340, "id": 2, "target_function_prompt": "def snake_case_to_camel(input_string: str, upper_case_first: bool = True, separator: str = '_') -> str:\n    \"\"\"\n    Convert a snake case string into a camel case one.\n    (The original string is returned if is not a valid snake case string)\n\n    *Example:*\n\n    >>> snake_case_to_camel('the_snake_is_green') # returns 'TheSnakeIsGreen'\n\n    :param input_string: String to convert.\n    :type input_string: str\n    :param upper_case_first: True to turn the first letter into uppercase (default).\n    :type upper_case_first: bool\n    :param separator: Sign to use as separator (default to \"_\").\n    :type separator: str\n    :return: Converted string\n    \"\"\"\n", "function_signature": "def snake_case_to_camel(input_string: str, upper_case_first: bool = True, separator: str = '_') -> str:"}}
{"prompt": "def strip_html(input_string: str, keep_tag_content: bool = False) -> str:\n    \"\"\"\n    Remove html code contained into the given string.\n\n    *Examples:*\n\n    >>> strip_html('test: <a href=\"foo/bar\">click here</a>') # returns 'test: '\n    >>> strip_html('test: <a href=\"foo/bar\">click here</a>', keep_tag_content=True) # returns 'test: click here'\n\n    :param input_string: String to manipulate.\n    :type input_string: str\n    :param keep_tag_content: True to preserve tag content, False to remove tag and its content too (default).\n    :type keep_tag_content: bool\n    :return: String with html removed.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/3", "ground_truth": "    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    r = HTML_TAG_ONLY_RE if keep_tag_content else HTML_RE\n\n    return r.sub('', input_string)", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 381, "line_no": 396, "id": 4, "target_function_prompt": "def strip_html(input_string: str, keep_tag_content: bool = False) -> str:\n    \"\"\"\n    Remove html code contained into the given string.\n\n    *Examples:*\n\n    >>> strip_html('test: <a href=\"foo/bar\">click here</a>') # returns 'test: '\n    >>> strip_html('test: <a href=\"foo/bar\">click here</a>', keep_tag_content=True) # returns 'test: click here'\n\n    :param input_string: String to manipulate.\n    :type input_string: str\n    :param keep_tag_content: True to preserve tag content, False to remove tag and its content too (default).\n    :type keep_tag_content: bool\n    :return: String with html removed.\n    \"\"\"\n", "function_signature": "def strip_html(input_string: str, keep_tag_content: bool = False) -> str:"}}
{"prompt": "def prettify(input_string: str) -> str:\n    \"\"\"\n    Reformat a string by applying the following basic grammar and formatting rules:\n\n    - String cannot start or end with spaces\n    - The first letter in the string and the ones after a dot, an exclamation or a question mark must be uppercase\n    - String cannot have multiple sequential spaces, empty lines or punctuation (except for \"?\", \"!\" and \".\")\n    - Arithmetic operators (+, -, /, \\\\*, =) must have one, and only one space before and after themselves\n    - One, and only one space should follow a dot, a comma, an exclamation or a question mark\n    - Text inside double quotes cannot start or end with spaces, but one, and only one space must come first and \\\n    after quotes (foo\" bar\"baz -> foo \"bar\" baz)\n    - Text inside round brackets cannot start or end with spaces, but one, and only one space must come first and \\\n    after brackets (\"foo(bar )baz\" -> \"foo (bar) baz\")\n    - Percentage sign (\"%\") cannot be preceded by a space if there is a number before (\"100 %\" -> \"100%\")\n    - Saxon genitive is correct (\"Dave' s dog\" -> \"Dave's dog\")\n\n    *Examples:*\n\n    >>> prettify(' unprettified string ,, like this one,will be\"prettified\" .it\\\\' s awesome! ')\n    >>> # -> 'Unprettified string, like this one, will be \"prettified\". It\\'s awesome!'\n\n    :param input_string: String to manipulate\n    :return: Prettified string.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/4", "ground_truth": "    formatted = __StringFormatter(input_string).format()\n    return formatted", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 404, "line_no": 428, "id": 5, "target_function_prompt": "def prettify(input_string: str) -> str:\n    \"\"\"\n    Reformat a string by applying the following basic grammar and formatting rules:\n\n    - String cannot start or end with spaces\n    - The first letter in the string and the ones after a dot, an exclamation or a question mark must be uppercase\n    - String cannot have multiple sequential spaces, empty lines or punctuation (except for \"?\", \"!\" and \".\")\n    - Arithmetic operators (+, -, /, \\\\*, =) must have one, and only one space before and after themselves\n    - One, and only one space should follow a dot, a comma, an exclamation or a question mark\n    - Text inside double quotes cannot start or end with spaces, but one, and only one space must come first and \\\n    after quotes (foo\" bar\"baz -> foo \"bar\" baz)\n    - Text inside round brackets cannot start or end with spaces, but one, and only one space must come first and \\\n    after brackets (\"foo(bar )baz\" -> \"foo (bar) baz\")\n    - Percentage sign (\"%\") cannot be preceded by a space if there is a number before (\"100 %\" -> \"100%\")\n    - Saxon genitive is correct (\"Dave' s dog\" -> \"Dave's dog\")\n\n    *Examples:*\n\n    >>> prettify(' unprettified string ,, like this one,will be\"prettified\" .it\\\\' s awesome! ')\n    >>> # -> 'Unprettified string, like this one, will be \"prettified\". It\\'s awesome!'\n\n    :param input_string: String to manipulate\n    :return: Prettified string.\n    \"\"\"\n", "function_signature": "def prettify(input_string: str) -> str:"}}
{"prompt": "def asciify(input_string: str) -> str:\n    \"\"\"\n    Force string content to be ascii-only by translating all non-ascii chars into the closest possible representation\n    (eg: \u00f3 -> o, \u00cb -> E, \u00e7 -> c...).\n\n    **Bear in mind**: Some chars may be lost if impossible to translate.\n\n    *Example:*\n\n    >>> asciify('\u00e8\u00e9\u00f9\u00fa\u00f2\u00f3\u00e4\u00e5\u00eb\u00fd\u00f1\u00c5\u00c0\u00c1\u00c7\u00cc\u00cd\u00d1\u00d3\u00cb') # returns 'eeuuooaaeynAAACIINOE'\n\n    :param input_string: String to convert\n    :return: Ascii utf-8 string\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/5", "ground_truth": "    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    # \"NFKD\" is the algorithm which is able to successfully translate the most of non-ascii chars\n    normalized = unicodedata.normalize('NFKD', input_string)\n\n    # encode string forcing ascii and ignore any errors (unrepresentable chars will be stripped out)\n    ascii_bytes = normalized.encode('ascii', 'ignore')\n\n    # turns encoded bytes into an utf-8 string\n    ascii_string = ascii_bytes.decode('utf-8')\n\n    return ascii_string", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 432, "line_no": 446, "id": 6, "target_function_prompt": "def asciify(input_string: str) -> str:\n    \"\"\"\n    Force string content to be ascii-only by translating all non-ascii chars into the closest possible representation\n    (eg: \u00f3 -> o, \u00cb -> E, \u00e7 -> c...).\n\n    **Bear in mind**: Some chars may be lost if impossible to translate.\n\n    *Example:*\n\n    >>> asciify('\u00e8\u00e9\u00f9\u00fa\u00f2\u00f3\u00e4\u00e5\u00eb\u00fd\u00f1\u00c5\u00c0\u00c1\u00c7\u00cc\u00cd\u00d1\u00d3\u00cb') # returns 'eeuuooaaeynAAACIINOE'\n\n    :param input_string: String to convert\n    :return: Ascii utf-8 string\n    \"\"\"\n", "function_signature": "def asciify(input_string: str) -> str:"}}
{"prompt": "def slugify(input_string: str, separator: str = '-') -> str:\n    \"\"\"\n    Converts a string into a \"slug\" using provided separator.\n    The returned string has the following properties:\n\n    - it has no spaces\n    - all letters are in lower case\n    - all punctuation signs and non alphanumeric chars are removed\n    - words are divided using provided separator\n    - all chars are encoded as ascii (by using `asciify()`)\n    - is safe for URL\n\n    *Examples:*\n\n    >>> slugify('Top 10 Reasons To Love Dogs!!!') # returns: 'top-10-reasons-to-love-dogs'\n    >>> slugify('M\u00f6nst\u00e9r M\u00e4gn\u00ebt') # returns 'monster-magnet'\n\n    :param input_string: String to convert.\n    :type input_string: str\n    :param separator: Sign used to join string tokens (default to \"-\").\n    :type separator: str\n    :return: Slug string\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/6", "ground_truth": "    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    # replace any character that is NOT letter or number with spaces\n    out = NO_LETTERS_OR_NUMBERS_RE.sub(' ', input_string.lower()).strip()\n\n    # replace spaces with join sign\n    out = SPACES_RE.sub(separator, out)\n\n    # normalize joins (remove duplicates)\n    out = re.sub(re.escape(separator) + r'+', separator, out)\n\n    return asciify(out)", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 461, "line_no": 484, "id": 7, "target_function_prompt": "def slugify(input_string: str, separator: str = '-') -> str:\n    \"\"\"\n    Converts a string into a \"slug\" using provided separator.\n    The returned string has the following properties:\n\n    - it has no spaces\n    - all letters are in lower case\n    - all punctuation signs and non alphanumeric chars are removed\n    - words are divided using provided separator\n    - all chars are encoded as ascii (by using `asciify()`)\n    - is safe for URL\n\n    *Examples:*\n\n    >>> slugify('Top 10 Reasons To Love Dogs!!!') # returns: 'top-10-reasons-to-love-dogs'\n    >>> slugify('M\u00f6nst\u00e9r M\u00e4gn\u00ebt') # returns 'monster-magnet'\n\n    :param input_string: String to convert.\n    :type input_string: str\n    :param separator: Sign used to join string tokens (default to \"-\").\n    :type separator: str\n    :return: Slug string\n    \"\"\"\n", "function_signature": "def slugify(input_string: str, separator: str = '-') -> str:"}}
{"prompt": "def booleanize(input_string: str) -> bool:\n    \"\"\"\n    Turns a string into a boolean based on its content (CASE INSENSITIVE).\n\n    A positive boolean (True) is returned if the string value is one of the following:\n\n    - \"true\"\n    - \"1\"\n    - \"yes\"\n    - \"y\"\n\n    Otherwise False is returned.\n\n    *Examples:*\n\n    >>> booleanize('true') # returns True\n    >>> booleanize('YES') # returns True\n    >>> booleanize('nope') # returns False\n\n    :param input_string: String to convert\n    :type input_string: str\n    :return: True if the string contains a boolean-like positive value, false otherwise\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/7", "ground_truth": "    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    return input_string.lower() in ('true', '1', 'yes', 'y')", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 499, "line_no": 522, "id": 8, "target_function_prompt": "def booleanize(input_string: str) -> bool:\n    \"\"\"\n    Turns a string into a boolean based on its content (CASE INSENSITIVE).\n\n    A positive boolean (True) is returned if the string value is one of the following:\n\n    - \"true\"\n    - \"1\"\n    - \"yes\"\n    - \"y\"\n\n    Otherwise False is returned.\n\n    *Examples:*\n\n    >>> booleanize('true') # returns True\n    >>> booleanize('YES') # returns True\n    >>> booleanize('nope') # returns False\n\n    :param input_string: String to convert\n    :type input_string: str\n    :return: True if the string contains a boolean-like positive value, false otherwise\n    \"\"\"\n", "function_signature": "def booleanize(input_string: str) -> bool:"}}
{"prompt": "def strip_margin(input_string: str) -> str:\n    \"\"\"\n    Removes tab indentation from multi line strings (inspired by analogous Scala function).\n\n    *Example:*\n\n    >>> strip_margin('''\n    >>>                 line 1\n    >>>                 line 2\n    >>>                 line 3\n    >>> ''')\n    >>> # returns:\n    >>> '''\n    >>> line 1\n    >>> line 2\n    >>> line 3\n    >>> '''\n\n    :param input_string: String to format\n    :type input_string: str\n    :return: A string without left margins\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/8", "ground_truth": "    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    line_separator = '\\n'\n    lines = [MARGIN_RE.sub('', line) for line in input_string.split(line_separator)]\n    out = line_separator.join(lines)\n\n    return out", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 528, "line_no": 550, "id": 9, "target_function_prompt": "def strip_margin(input_string: str) -> str:\n    \"\"\"\n    Removes tab indentation from multi line strings (inspired by analogous Scala function).\n\n    *Example:*\n\n    >>> strip_margin('''\n    >>>                 line 1\n    >>>                 line 2\n    >>>                 line 3\n    >>> ''')\n    >>> # returns:\n    >>> '''\n    >>> line 1\n    >>> line 2\n    >>> line 3\n    >>> '''\n\n    :param input_string: String to format\n    :type input_string: str\n    :return: A string without left margins\n    \"\"\"\n", "function_signature": "def strip_margin(input_string: str) -> str:"}}
{"prompt": "def decompress(input_string: str, encoding: str = 'utf-8') -> str:\n    \"\"\"\n    Restore a previously compressed string (obtained using `compress()`) back to its original state.\n\n    :param input_string: String to restore.\n    :type input_string: str\n    :param encoding: Original string encoding.\n    :type encoding: str\n    :return: Decompressed string.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/9", "ground_truth": "    return __StringCompressor.decompress(input_string, encoding)", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 597, "line_no": 607, "id": 10, "target_function_prompt": "def decompress(input_string: str, encoding: str = 'utf-8') -> str:\n    \"\"\"\n    Restore a previously compressed string (obtained using `compress()`) back to its original state.\n\n    :param input_string: String to restore.\n    :type input_string: str\n    :param encoding: Original string encoding.\n    :type encoding: str\n    :return: Decompressed string.\n    \"\"\"\n", "function_signature": "def decompress(input_string: str, encoding: str = 'utf-8') -> str:"}}
{"prompt": "def roman_encode(input_number: Union[str, int]) -> str:\n    \"\"\"\n    Convert the given number/string into a roman number.\n\n    The passed input must represents a positive integer in the range 1-3999 (inclusive).\n\n    Why this limit? You may be wondering:\n\n    1. zero is forbidden since there is no related representation in roman numbers\n    2. the upper bound 3999 is due to the limitation in the ascii charset\\\n    (the higher quantity sign displayable in ascii is \"M\" which is equal to 1000, therefore based on\\\n    roman numbers rules we can use 3 times M to reach 3000 but we can't go any further in thousands without\\\n    special \"boxed chars\").\n\n    *Examples:*\n\n    >>> roman_encode(37) # returns 'XXXVIII'\n    >>> roman_encode('2020') # returns 'MMXX'\n\n    :param input_number: An integer or a string to be converted.\n    :type input_number: Union[str, int]\n    :return: Roman number string.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/10", "ground_truth": "    return __RomanNumbers.encode(input_number)", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 610, "line_no": 633, "id": 11, "target_function_prompt": "def roman_encode(input_number: Union[str, int]) -> str:\n    \"\"\"\n    Convert the given number/string into a roman number.\n\n    The passed input must represents a positive integer in the range 1-3999 (inclusive).\n\n    Why this limit? You may be wondering:\n\n    1. zero is forbidden since there is no related representation in roman numbers\n    2. the upper bound 3999 is due to the limitation in the ascii charset\\\n    (the higher quantity sign displayable in ascii is \"M\" which is equal to 1000, therefore based on\\\n    roman numbers rules we can use 3 times M to reach 3000 but we can't go any further in thousands without\\\n    special \"boxed chars\").\n\n    *Examples:*\n\n    >>> roman_encode(37) # returns 'XXXVIII'\n    >>> roman_encode('2020') # returns 'MMXX'\n\n    :param input_number: An integer or a string to be converted.\n    :type input_number: Union[str, int]\n    :return: Roman number string.\n    \"\"\"\n", "function_signature": "def roman_encode(input_number: Union[str, int]) -> str:"}}
{"prompt": "def roman_decode(input_string: str) -> int:\n    \"\"\"\n    Decode a roman number string into an integer if the provided string is valid.\n\n    *Example:*\n\n    >>> roman_decode('VII') # returns 7\n\n    :param input_string: (Assumed) Roman number\n    :type input_string: str\n    :return: Integer value\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/11", "ground_truth": "    return __RomanNumbers.decode(input_string)", "fpath_tuple": ["python-string-utils", "string_utils", "manipulation.py"], "context_start_lineno": 636, "line_no": 648, "id": 12, "target_function_prompt": "def roman_decode(input_string: str) -> int:\n    \"\"\"\n    Decode a roman number string into an integer if the provided string is valid.\n\n    *Example:*\n\n    >>> roman_decode('VII') # returns 7\n\n    :param input_string: (Assumed) Roman number\n    :type input_string: str\n    :return: Integer value\n    \"\"\"\n", "function_signature": "def roman_decode(input_string: str) -> int:"}}
{"prompt": "def is_string(obj: Any) -> bool:\n    \"\"\"\n    Checks if an object is a string.\n\n    *Example:*\n\n    >>> is_string('foo') # returns true\n    >>> is_string(b'foo') # returns false\n\n    :param obj: Object to test.\n    :return: True if string, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/12", "ground_truth": "    return isinstance(obj, str)", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 82, "line_no": 94, "id": 13, "target_function_prompt": "def is_string(obj: Any) -> bool:\n    \"\"\"\n    Checks if an object is a string.\n\n    *Example:*\n\n    >>> is_string('foo') # returns true\n    >>> is_string(b'foo') # returns false\n\n    :param obj: Object to test.\n    :return: True if string, false otherwise.\n    \"\"\"\n", "function_signature": "def is_string(obj: Any) -> bool:"}}
{"prompt": "def is_full_string(input_string: Any) -> bool:\n    \"\"\"\n    Check if a string is not empty (it must contains at least one non space character).\n\n    *Examples:*\n\n    >>> is_full_string(None) # returns false\n    >>> is_full_string('') # returns false\n    >>> is_full_string(' ') # returns false\n    >>> is_full_string('hello') # returns true\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if not empty, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/13", "ground_truth": "    return is_string(input_string) and input_string.strip() != ''", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 97, "line_no": 112, "id": 14, "target_function_prompt": "def is_full_string(input_string: Any) -> bool:\n    \"\"\"\n    Check if a string is not empty (it must contains at least one non space character).\n\n    *Examples:*\n\n    >>> is_full_string(None) # returns false\n    >>> is_full_string('') # returns false\n    >>> is_full_string(' ') # returns false\n    >>> is_full_string('hello') # returns true\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if not empty, false otherwise.\n    \"\"\"\n", "function_signature": "def is_full_string(input_string: Any) -> bool:"}}
{"prompt": "def is_number(input_string: str) -> bool:\n    \"\"\"\n    Checks if a string is a valid number.\n\n    The number can be a signed (eg: +1, -2, -3.3) or unsigned (eg: 1, 2, 3.3) integer or double\n    or use the \"scientific notation\" (eg: 1e5).\n\n    *Examples:*\n\n    >>> is_number('42') # returns true\n    >>> is_number('19.99') # returns true\n    >>> is_number('-9.12') # returns true\n    >>> is_number('1e3') # returns true\n    >>> is_number('1 2 3') # returns false\n\n    :param input_string: String to check\n    :type input_string: str\n    :return: True if the string represents a number, false otherwise\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/14", "ground_truth": "    if not isinstance(input_string, str):\n        raise InvalidInputError(input_string)\n\n    return NUMBER_RE.match(input_string) is not None", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 115, "line_no": 134, "id": 15, "target_function_prompt": "def is_number(input_string: str) -> bool:\n    \"\"\"\n    Checks if a string is a valid number.\n\n    The number can be a signed (eg: +1, -2, -3.3) or unsigned (eg: 1, 2, 3.3) integer or double\n    or use the \"scientific notation\" (eg: 1e5).\n\n    *Examples:*\n\n    >>> is_number('42') # returns true\n    >>> is_number('19.99') # returns true\n    >>> is_number('-9.12') # returns true\n    >>> is_number('1e3') # returns true\n    >>> is_number('1 2 3') # returns false\n\n    :param input_string: String to check\n    :type input_string: str\n    :return: True if the string represents a number, false otherwise\n    \"\"\"\n", "function_signature": "def is_number(input_string: str) -> bool:"}}
{"prompt": "def is_integer(input_string: str) -> bool:\n    \"\"\"\n    Checks whether the given string represents an integer or not.\n\n    An integer may be signed or unsigned or use a \"scientific notation\".\n\n    *Examples:*\n\n    >>> is_integer('42') # returns true\n    >>> is_integer('42.0') # returns false\n\n    :param input_string: String to check\n    :type input_string: str\n    :return: True if integer, false otherwise\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/15", "ground_truth": "    return is_number(input_string) and '.' not in input_string", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 140, "line_no": 155, "id": 16, "target_function_prompt": "def is_integer(input_string: str) -> bool:\n    \"\"\"\n    Checks whether the given string represents an integer or not.\n\n    An integer may be signed or unsigned or use a \"scientific notation\".\n\n    *Examples:*\n\n    >>> is_integer('42') # returns true\n    >>> is_integer('42.0') # returns false\n\n    :param input_string: String to check\n    :type input_string: str\n    :return: True if integer, false otherwise\n    \"\"\"\n", "function_signature": "def is_integer(input_string: str) -> bool:"}}
{"prompt": "def is_decimal(input_string: str) -> bool:\n    \"\"\"\n    Checks whether the given string represents a decimal or not.\n\n    A decimal may be signed or unsigned or use a \"scientific notation\".\n\n    >>> is_decimal('42.0') # returns true\n    >>> is_decimal('42') # returns false\n\n    :param input_string: String to check\n    :type input_string: str\n    :return: True if integer, false otherwise\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/16", "ground_truth": "    return is_number(input_string) and '.' in input_string", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 158, "line_no": 171, "id": 17, "target_function_prompt": "def is_decimal(input_string: str) -> bool:\n    \"\"\"\n    Checks whether the given string represents a decimal or not.\n\n    A decimal may be signed or unsigned or use a \"scientific notation\".\n\n    >>> is_decimal('42.0') # returns true\n    >>> is_decimal('42') # returns false\n\n    :param input_string: String to check\n    :type input_string: str\n    :return: True if integer, false otherwise\n    \"\"\"\n", "function_signature": "def is_decimal(input_string: str) -> bool:"}}
{"prompt": "def is_url(input_string: Any, allowed_schemes: Optional[List[str]] = None) -> bool:\n    \"\"\"\n    Check if a string is a valid url.\n\n    *Examples:*\n\n    >>> is_url('http://www.mysite.com') # returns true\n    >>> is_url('https://mysite.com') # returns true\n    >>> is_url('.mysite.com') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :param allowed_schemes: List of valid schemes ('http', 'https', 'ftp'...). Default to None (any scheme is valid).\n    :type allowed_schemes: Optional[List[str]]\n    :return: True if url, false otherwise\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/17", "ground_truth": "    if not is_full_string(input_string):\n        return False\n\n    valid = URL_RE.match(input_string) is not None\n\n    if allowed_schemes:\n        return valid and any([input_string.startswith(s) for s in allowed_schemes])\n\n    return valid", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 176, "line_no": 192, "id": 18, "target_function_prompt": "def is_url(input_string: Any, allowed_schemes: Optional[List[str]] = None) -> bool:\n    \"\"\"\n    Check if a string is a valid url.\n\n    *Examples:*\n\n    >>> is_url('http://www.mysite.com') # returns true\n    >>> is_url('https://mysite.com') # returns true\n    >>> is_url('.mysite.com') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :param allowed_schemes: List of valid schemes ('http', 'https', 'ftp'...). Default to None (any scheme is valid).\n    :type allowed_schemes: Optional[List[str]]\n    :return: True if url, false otherwise\n    \"\"\"\n", "function_signature": "def is_url(input_string: Any, allowed_schemes: Optional[List[str]] = None) -> bool:"}}
{"prompt": "def is_email(input_string: Any) -> bool:\n    \"\"\"\n    Check if a string is a valid email.\n\n    Reference: https://tools.ietf.org/html/rfc3696#section-3\n\n    *Examples:*\n\n    >>> is_email('my.email@the-provider.com') # returns true\n    >>> is_email('@gmail.com') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if email, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/18", "ground_truth": "    # first simple \"pre check\": it must be a non empty string with max len 320 and cannot start with a dot\n    if not is_full_string(input_string) or len(input_string) > 320 or input_string.startswith('.'):\n        return False\n\n    try:\n        # we expect 2 tokens, one before \"@\" and one after, otherwise we have an exception and the email is not valid\n        head, tail = input_string.split('@')\n\n        # head's size must be <= 64, tail <= 255, head must not start with a dot or contain multiple consecutive dots\n        if len(head) > 64 or len(tail) > 255 or head.endswith('.') or ('..' in head):\n            return False\n\n        # removes escaped spaces, so that later on the test regex will accept the string\n        head = head.replace('\\\\ ', '')\n        if head.startswith('\"') and head.endswith('\"'):\n            head = head.replace(' ', '')[1:-1]\n\n        return EMAIL_RE.match(head + '@' + tail) is not None\n\n    except ValueError:\n        # borderline case in which we have multiple \"@\" signs but the head part is correctly escaped\n        if ESCAPED_AT_SIGN.search(input_string) is not None:\n            # replace \"@\" with \"a\" in the head\n            return is_email(ESCAPED_AT_SIGN.sub('a', input_string))\n\n        return False", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 203, "line_no": 218, "id": 19, "target_function_prompt": "def is_email(input_string: Any) -> bool:\n    \"\"\"\n    Check if a string is a valid email.\n\n    Reference: https://tools.ietf.org/html/rfc3696#section-3\n\n    *Examples:*\n\n    >>> is_email('my.email@the-provider.com') # returns true\n    >>> is_email('@gmail.com') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if email, false otherwise.\n    \"\"\"\n", "function_signature": "def is_email(input_string: Any) -> bool:"}}
{"prompt": "def is_credit_card(input_string: Any, card_type: str = None) -> bool:\n    \"\"\"\n    Checks if a string is a valid credit card number.\n    If card type is provided then it checks against that specific type only,\n    otherwise any known credit card number will be accepted.\n\n    Supported card types are the following:\n\n    - VISA\n    - MASTERCARD\n    - AMERICAN_EXPRESS\n    - DINERS_CLUB\n    - DISCOVER\n    - JCB\n\n    :param input_string: String to check.\n    :type input_string: str\n    :param card_type: Card type. Default to None (any card).\n    :type card_type: str\n\n    :return: True if credit card, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/19", "ground_truth": "    if not is_full_string(input_string):\n        return False\n\n    if card_type:\n        if card_type not in CREDIT_CARDS:\n            raise KeyError(\n                'Invalid card type \"{}\". Valid types are: {}'.format(card_type, ', '.join(CREDIT_CARDS.keys()))\n            )\n        return CREDIT_CARDS[card_type].match(input_string) is not None\n\n    for c in CREDIT_CARDS:\n        if CREDIT_CARDS[c].match(input_string) is not None:\n            return True\n\n    return False", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 246, "line_no": 268, "id": 20, "target_function_prompt": "def is_credit_card(input_string: Any, card_type: str = None) -> bool:\n    \"\"\"\n    Checks if a string is a valid credit card number.\n    If card type is provided then it checks against that specific type only,\n    otherwise any known credit card number will be accepted.\n\n    Supported card types are the following:\n\n    - VISA\n    - MASTERCARD\n    - AMERICAN_EXPRESS\n    - DINERS_CLUB\n    - DISCOVER\n    - JCB\n\n    :param input_string: String to check.\n    :type input_string: str\n    :param card_type: Card type. Default to None (any card).\n    :type card_type: str\n\n    :return: True if credit card, false otherwise.\n    \"\"\"\n", "function_signature": "def is_credit_card(input_string: Any, card_type: str = None) -> bool:"}}
{"prompt": "def is_camel_case(input_string: Any) -> bool:\n    \"\"\"\n    Checks if a string is formatted as camel case.\n\n    A string is considered camel case when:\n\n    - it's composed only by letters ([a-zA-Z]) and optionally numbers ([0-9])\n    - it contains both lowercase and uppercase letters\n    - it does not start with a number\n\n    *Examples:*\n\n    >>> is_camel_case('MyString') # returns true\n    >>> is_camel_case('mystring') # returns false\n\n    :param input_string: String to test.\n    :type input_string: str\n    :return: True for a camel case string, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/20", "ground_truth": "    return is_full_string(input_string) and CAMEL_CASE_TEST_RE.match(input_string) is not None", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 285, "line_no": 304, "id": 21, "target_function_prompt": "def is_camel_case(input_string: Any) -> bool:\n    \"\"\"\n    Checks if a string is formatted as camel case.\n\n    A string is considered camel case when:\n\n    - it's composed only by letters ([a-zA-Z]) and optionally numbers ([0-9])\n    - it contains both lowercase and uppercase letters\n    - it does not start with a number\n\n    *Examples:*\n\n    >>> is_camel_case('MyString') # returns true\n    >>> is_camel_case('mystring') # returns false\n\n    :param input_string: String to test.\n    :type input_string: str\n    :return: True for a camel case string, false otherwise.\n    \"\"\"\n", "function_signature": "def is_camel_case(input_string: Any) -> bool:"}}
{"prompt": "def is_snake_case(input_string: Any, separator: str = '_') -> bool:\n    \"\"\"\n    Checks if a string is formatted as \"snake case\".\n\n    A string is considered snake case when:\n\n    - it's composed only by lowercase/uppercase letters and digits\n    - it contains at least one underscore (or provided separator)\n    - it does not start with a number\n\n    *Examples:*\n\n    >>> is_snake_case('foo_bar_baz') # returns true\n    >>> is_snake_case('foo') # returns false\n\n    :param input_string: String to test.\n    :type input_string: str\n    :param separator: String to use as separator.\n    :type separator: str\n    :return: True for a snake case string, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/21", "ground_truth": "    if is_full_string(input_string):\n        re_map = {\n            '_': SNAKE_CASE_TEST_RE,\n            '-': SNAKE_CASE_TEST_DASH_RE\n        }\n        re_template = r'([a-z]+\\d*{sign}[a-z\\d{sign}]*|{sign}+[a-z\\d]+[a-z\\d{sign}]*)'\n        r = re_map.get(\n            separator,\n            re.compile(re_template.format(sign=re.escape(separator)), re.IGNORECASE)\n        )\n\n        return r.match(input_string) is not None\n\n    return False", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 307, "line_no": 328, "id": 22, "target_function_prompt": "def is_snake_case(input_string: Any, separator: str = '_') -> bool:\n    \"\"\"\n    Checks if a string is formatted as \"snake case\".\n\n    A string is considered snake case when:\n\n    - it's composed only by lowercase/uppercase letters and digits\n    - it contains at least one underscore (or provided separator)\n    - it does not start with a number\n\n    *Examples:*\n\n    >>> is_snake_case('foo_bar_baz') # returns true\n    >>> is_snake_case('foo') # returns false\n\n    :param input_string: String to test.\n    :type input_string: str\n    :param separator: String to use as separator.\n    :type separator: str\n    :return: True for a snake case string, false otherwise.\n    \"\"\"\n", "function_signature": "def is_snake_case(input_string: Any, separator: str = '_') -> bool:"}}
{"prompt": "def is_json(input_string: Any) -> bool:\n    \"\"\"\n    Check if a string is a valid json.\n\n    *Examples:*\n\n    >>> is_json('{\"name\": \"Peter\"}') # returns true\n    >>> is_json('[1, 2, 3]') # returns true\n    >>> is_json('{nope}') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if json, false otherwise\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/22", "ground_truth": "    if is_full_string(input_string) and JSON_WRAPPER_RE.match(input_string) is not None:\n        try:\n            return isinstance(json.loads(input_string), (dict, list))\n        except (TypeError, ValueError, OverflowError):\n            pass\n\n    return False", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 344, "line_no": 358, "id": 23, "target_function_prompt": "def is_json(input_string: Any) -> bool:\n    \"\"\"\n    Check if a string is a valid json.\n\n    *Examples:*\n\n    >>> is_json('{\"name\": \"Peter\"}') # returns true\n    >>> is_json('[1, 2, 3]') # returns true\n    >>> is_json('{nope}') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if json, false otherwise\n    \"\"\"\n", "function_signature": "def is_json(input_string: Any) -> bool:"}}
{"prompt": "def is_uuid(input_string: Any, allow_hex: bool = False) -> bool:\n    \"\"\"\n    Check if a string is a valid UUID.\n\n    *Example:*\n\n    >>> is_uuid('6f8aa2f9-686c-4ac3-8766-5712354a04cf') # returns true\n    >>> is_uuid('6f8aa2f9686c4ac387665712354a04cf') # returns false\n    >>> is_uuid('6f8aa2f9686c4ac387665712354a04cf', allow_hex=True) # returns true\n\n    :param input_string: String to check.\n    :type input_string: str\n    :param allow_hex: True to allow UUID hex representation as valid, false otherwise (default)\n    :type allow_hex: bool\n    :return: True if UUID, false otherwise\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/23", "ground_truth": "    # string casting is used to allow UUID itself as input data type\n    s = str(input_string)\n\n    if allow_hex:\n        return UUID_HEX_OK_RE.match(s) is not None\n\n    return UUID_RE.match(s) is not None", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 367, "line_no": 383, "id": 24, "target_function_prompt": "def is_uuid(input_string: Any, allow_hex: bool = False) -> bool:\n    \"\"\"\n    Check if a string is a valid UUID.\n\n    *Example:*\n\n    >>> is_uuid('6f8aa2f9-686c-4ac3-8766-5712354a04cf') # returns true\n    >>> is_uuid('6f8aa2f9686c4ac387665712354a04cf') # returns false\n    >>> is_uuid('6f8aa2f9686c4ac387665712354a04cf', allow_hex=True) # returns true\n\n    :param input_string: String to check.\n    :type input_string: str\n    :param allow_hex: True to allow UUID hex representation as valid, false otherwise (default)\n    :type allow_hex: bool\n    :return: True if UUID, false otherwise\n    \"\"\"\n", "function_signature": "def is_uuid(input_string: Any, allow_hex: bool = False) -> bool:"}}
{"prompt": "def is_ip_v4(input_string: Any) -> bool:\n    \"\"\"\n    Checks if a string is a valid ip v4.\n\n    *Examples:*\n\n    >>> is_ip_v4('255.200.100.75') # returns true\n    >>> is_ip_v4('nope') # returns false (not an ip)\n    >>> is_ip_v4('255.200.100.999') # returns false (999 is out of range)\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if an ip v4, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/24", "ground_truth": "    if not is_full_string(input_string) or SHALLOW_IP_V4_RE.match(input_string) is None:\n        return False\n\n    # checks that each entry in the ip is in the valid range (0 to 255)\n    for token in input_string.split('.'):\n        if not (0 <= int(token) <= 255):\n            return False\n\n    return True", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 392, "line_no": 406, "id": 25, "target_function_prompt": "def is_ip_v4(input_string: Any) -> bool:\n    \"\"\"\n    Checks if a string is a valid ip v4.\n\n    *Examples:*\n\n    >>> is_ip_v4('255.200.100.75') # returns true\n    >>> is_ip_v4('nope') # returns false (not an ip)\n    >>> is_ip_v4('255.200.100.999') # returns false (999 is out of range)\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if an ip v4, false otherwise.\n    \"\"\"\n", "function_signature": "def is_ip_v4(input_string: Any) -> bool:"}}
{"prompt": "def is_ip_v6(input_string: Any) -> bool:\n    \"\"\"\n    Checks if a string is a valid ip v6.\n\n    *Examples:*\n\n    >>> is_ip_v6('2001:db8:85a3:0000:0000:8a2e:370:7334') # returns true\n    >>> is_ip_v6('2001:db8:85a3:0000:0000:8a2e:370:?') # returns false (invalid \"?\")\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if a v6 ip, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/25", "ground_truth": "    return is_full_string(input_string) and IP_V6_RE.match(input_string) is not None", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 417, "line_no": 430, "id": 26, "target_function_prompt": "def is_ip_v6(input_string: Any) -> bool:\n    \"\"\"\n    Checks if a string is a valid ip v6.\n\n    *Examples:*\n\n    >>> is_ip_v6('2001:db8:85a3:0000:0000:8a2e:370:7334') # returns true\n    >>> is_ip_v6('2001:db8:85a3:0000:0000:8a2e:370:?') # returns false (invalid \"?\")\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if a v6 ip, false otherwise.\n    \"\"\"\n", "function_signature": "def is_ip_v6(input_string: Any) -> bool:"}}
{"prompt": "def is_ip(input_string: Any) -> bool:\n    \"\"\"\n    Checks if a string is a valid ip (either v4 or v6).\n\n    *Examples:*\n\n    >>> is_ip('255.200.100.75') # returns true\n    >>> is_ip('2001:db8:85a3:0000:0000:8a2e:370:7334') # returns true\n    >>> is_ip('1.2.3') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if an ip, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/26", "ground_truth": "    return is_ip_v6(input_string) or is_ip_v4(input_string)", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 433, "line_no": 447, "id": 27, "target_function_prompt": "def is_ip(input_string: Any) -> bool:\n    \"\"\"\n    Checks if a string is a valid ip (either v4 or v6).\n\n    *Examples:*\n\n    >>> is_ip('255.200.100.75') # returns true\n    >>> is_ip('2001:db8:85a3:0000:0000:8a2e:370:7334') # returns true\n    >>> is_ip('1.2.3') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if an ip, false otherwise.\n    \"\"\"\n", "function_signature": "def is_ip(input_string: Any) -> bool:"}}
{"prompt": "def is_palindrome(input_string: Any, ignore_spaces: bool = False, ignore_case: bool = False) -> bool:\n    \"\"\"\n    Checks if the string is a palindrome (https://en.wikipedia.org/wiki/Palindrome).\n\n    *Examples:*\n\n    >>> is_palindrome('LOL') # returns true\n    >>> is_palindrome('Lol') # returns false\n    >>> is_palindrome('Lol', ignore_case=True) # returns true\n    >>> is_palindrome('ROTFL') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :param ignore_spaces: False if white spaces matter (default), true otherwise.\n    :type ignore_spaces: bool\n    :param ignore_case: False if char case matters (default), true otherwise.\n    :type ignore_case: bool\n    :return: True if the string is a palindrome (like \"otto\", or \"i topi non avevano nipoti\" if strict=False),\\\n    False otherwise\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/27", "ground_truth": "    if not is_full_string(input_string):\n        return False\n\n    if ignore_spaces:\n        input_string = SPACES_RE.sub('', input_string)\n\n    string_len = len(input_string)\n\n    # Traverse the string one char at step, and for each step compares the\n    # \"head_char\" (the one on the left of the string) to the \"tail_char\" (the one on the right).\n    # In this way we avoid to manipulate the whole string in advance if not necessary and provide a faster\n    # algorithm which can scale very well for long strings.\n    for index in range(string_len):\n        head_char = input_string[index]\n        tail_char = input_string[string_len - index - 1]\n\n        if ignore_case:\n            head_char = head_char.lower()\n            tail_char = tail_char.lower()\n\n        if head_char != tail_char:\n            return False\n\n    return True", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 450, "line_no": 470, "id": 28, "target_function_prompt": "def is_palindrome(input_string: Any, ignore_spaces: bool = False, ignore_case: bool = False) -> bool:\n    \"\"\"\n    Checks if the string is a palindrome (https://en.wikipedia.org/wiki/Palindrome).\n\n    *Examples:*\n\n    >>> is_palindrome('LOL') # returns true\n    >>> is_palindrome('Lol') # returns false\n    >>> is_palindrome('Lol', ignore_case=True) # returns true\n    >>> is_palindrome('ROTFL') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :param ignore_spaces: False if white spaces matter (default), true otherwise.\n    :type ignore_spaces: bool\n    :param ignore_case: False if char case matters (default), true otherwise.\n    :type ignore_case: bool\n    :return: True if the string is a palindrome (like \"otto\", or \"i topi non avevano nipoti\" if strict=False),\\\n    False otherwise\n    \"\"\"\n", "function_signature": "def is_palindrome(input_string: Any, ignore_spaces: bool = False, ignore_case: bool = False) -> bool:"}}
{"prompt": "def is_pangram(input_string: Any) -> bool:\n    \"\"\"\n    Checks if the string is a pangram (https://en.wikipedia.org/wiki/Pangram).\n\n    *Examples:*\n\n    >>> is_pangram('The quick brown fox jumps over the lazy dog') # returns true\n    >>> is_pangram('hello world') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if the string is a pangram, False otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/28", "ground_truth": "    if not is_full_string(input_string):\n        return False\n\n    return set(SPACES_RE.sub('', input_string)).issuperset(set(string.ascii_lowercase))", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 496, "line_no": 509, "id": 29, "target_function_prompt": "def is_pangram(input_string: Any) -> bool:\n    \"\"\"\n    Checks if the string is a pangram (https://en.wikipedia.org/wiki/Pangram).\n\n    *Examples:*\n\n    >>> is_pangram('The quick brown fox jumps over the lazy dog') # returns true\n    >>> is_pangram('hello world') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if the string is a pangram, False otherwise.\n    \"\"\"\n", "function_signature": "def is_pangram(input_string: Any) -> bool:"}}
{"prompt": "def is_isogram(input_string: Any) -> bool:\n    \"\"\"\n    Checks if the string is an isogram (https://en.wikipedia.org/wiki/Isogram).\n\n    *Examples:*\n\n    >>> is_isogram('dermatoglyphics') # returns true\n    >>> is_isogram('hello') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if isogram, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/29", "ground_truth": "    return is_full_string(input_string) and len(set(input_string)) == len(input_string)", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 515, "line_no": 528, "id": 30, "target_function_prompt": "def is_isogram(input_string: Any) -> bool:\n    \"\"\"\n    Checks if the string is an isogram (https://en.wikipedia.org/wiki/Isogram).\n\n    *Examples:*\n\n    >>> is_isogram('dermatoglyphics') # returns true\n    >>> is_isogram('hello') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: True if isogram, false otherwise.\n    \"\"\"\n", "function_signature": "def is_isogram(input_string: Any) -> bool:"}}
{"prompt": "def is_slug(input_string: Any, separator: str = '-') -> bool:\n    \"\"\"\n    Checks if a given string is a slug (as created by `slugify()`).\n\n    *Examples:*\n\n    >>> is_slug('my-blog-post-title') # returns true\n    >>> is_slug('My blog post title') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :param separator: Join sign used by the slug.\n    :type separator: str\n    :return: True if slug, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/30", "ground_truth": "    if not is_full_string(input_string):\n        return False\n\n    rex = r'^([a-z\\d]+' + re.escape(separator) + r'*?)*[a-z\\d]$'\n\n    return re.match(rex, input_string) is not None", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 531, "line_no": 546, "id": 31, "target_function_prompt": "def is_slug(input_string: Any, separator: str = '-') -> bool:\n    \"\"\"\n    Checks if a given string is a slug (as created by `slugify()`).\n\n    *Examples:*\n\n    >>> is_slug('my-blog-post-title') # returns true\n    >>> is_slug('My blog post title') # returns false\n\n    :param input_string: String to check.\n    :type input_string: str\n    :param separator: Join sign used by the slug.\n    :type separator: str\n    :return: True if slug, false otherwise.\n    \"\"\"\n", "function_signature": "def is_slug(input_string: Any, separator: str = '-') -> bool:"}}
{"prompt": "def contains_html(input_string: str) -> bool:\n    \"\"\"\n    Checks if the given string contains HTML/XML tags.\n\n    By design, this function matches ANY type of tag, so don't expect to use it\n    as an HTML validator, its goal is to detect \"malicious\" or undesired tags in the text.\n\n    *Examples:*\n\n    >>> contains_html('my string is <strong>bold</strong>') # returns true\n    >>> contains_html('my string is not bold') # returns false\n\n    :param input_string: Text to check\n    :type input_string: str\n    :return: True if string contains html, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/31", "ground_truth": "    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    return HTML_RE.search(input_string) is not None", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 554, "line_no": 570, "id": 32, "target_function_prompt": "def contains_html(input_string: str) -> bool:\n    \"\"\"\n    Checks if the given string contains HTML/XML tags.\n\n    By design, this function matches ANY type of tag, so don't expect to use it\n    as an HTML validator, its goal is to detect \"malicious\" or undesired tags in the text.\n\n    *Examples:*\n\n    >>> contains_html('my string is <strong>bold</strong>') # returns true\n    >>> contains_html('my string is not bold') # returns false\n\n    :param input_string: Text to check\n    :type input_string: str\n    :return: True if string contains html, false otherwise.\n    \"\"\"\n", "function_signature": "def contains_html(input_string: str) -> bool:"}}
{"prompt": "def words_count(input_string: str) -> int:\n    \"\"\"\n    Returns the number of words contained into the given string.\n\n    This method is smart, it does consider only sequence of one or more letter and/or numbers\n    as \"words\", so a string like this: \"! @ # % ... []\" will return zero!\n    Moreover it is aware of punctuation, so the count for a string like \"one,two,three.stop\"\n    will be 4 not 1 (even if there are no spaces in the string).\n\n    *Examples:*\n\n    >>> words_count('hello world') # returns 2\n    >>> words_count('one,two,three.stop') # returns 4\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: Number of words.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/32", "ground_truth": "    if not is_string(input_string):\n        raise InvalidInputError(input_string)\n\n    return len(WORDS_COUNT_RE.findall(input_string))", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 576, "line_no": 594, "id": 33, "target_function_prompt": "def words_count(input_string: str) -> int:\n    \"\"\"\n    Returns the number of words contained into the given string.\n\n    This method is smart, it does consider only sequence of one or more letter and/or numbers\n    as \"words\", so a string like this: \"! @ # % ... []\" will return zero!\n    Moreover it is aware of punctuation, so the count for a string like \"one,two,three.stop\"\n    will be 4 not 1 (even if there are no spaces in the string).\n\n    *Examples:*\n\n    >>> words_count('hello world') # returns 2\n    >>> words_count('one,two,three.stop') # returns 4\n\n    :param input_string: String to check.\n    :type input_string: str\n    :return: Number of words.\n    \"\"\"\n", "function_signature": "def words_count(input_string: str) -> int:"}}
{"prompt": "def is_isbn_10(input_string: str, normalize: bool = True) -> bool:\n    \"\"\"\n    Checks if the given string represents a valid ISBN 10 (International Standard Book Number).\n    By default hyphens in the string are ignored, so digits can be separated in different ways, by calling this\n    function with `normalize=False` only digit-only strings will pass the validation.\n\n    *Examples:*\n\n    >>> is_isbn_10('1506715214') # returns true\n    >>> is_isbn_10('150-6715214') # returns true\n    >>> is_isbn_10('150-6715214', normalize=False) # returns false\n\n    :param input_string: String to check.\n    :param normalize: True to ignore hyphens (\"-\") in the string (default), false otherwise.\n    :return: True if valid ISBN 10, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/33", "ground_truth": "    checker = __ISBNChecker(input_string, normalize)\n    return checker.is_isbn_10()", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 600, "line_no": 616, "id": 34, "target_function_prompt": "def is_isbn_10(input_string: str, normalize: bool = True) -> bool:\n    \"\"\"\n    Checks if the given string represents a valid ISBN 10 (International Standard Book Number).\n    By default hyphens in the string are ignored, so digits can be separated in different ways, by calling this\n    function with `normalize=False` only digit-only strings will pass the validation.\n\n    *Examples:*\n\n    >>> is_isbn_10('1506715214') # returns true\n    >>> is_isbn_10('150-6715214') # returns true\n    >>> is_isbn_10('150-6715214', normalize=False) # returns false\n\n    :param input_string: String to check.\n    :param normalize: True to ignore hyphens (\"-\") in the string (default), false otherwise.\n    :return: True if valid ISBN 10, false otherwise.\n    \"\"\"\n", "function_signature": "def is_isbn_10(input_string: str, normalize: bool = True) -> bool:"}}
{"prompt": "def is_isbn_13(input_string: str, normalize: bool = True) -> bool:\n    \"\"\"\n    Checks if the given string represents a valid ISBN 13 (International Standard Book Number).\n    By default hyphens in the string are ignored, so digits can be separated in different ways, by calling this\n    function with `normalize=False` only digit-only strings will pass the validation.\n\n    *Examples:*\n\n    >>> is_isbn_13('9780312498580') # returns true\n    >>> is_isbn_13('978-0312498580') # returns true\n    >>> is_isbn_13('978-0312498580', normalize=False) # returns false\n\n    :param input_string: String to check.\n    :param normalize: True to ignore hyphens (\"-\") in the string (default), false otherwise.\n    :return: True if valid ISBN 13, false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/34", "ground_truth": "    checker = __ISBNChecker(input_string, normalize)\n    return checker.is_isbn_13()", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 620, "line_no": 636, "id": 35, "target_function_prompt": "def is_isbn_13(input_string: str, normalize: bool = True) -> bool:\n    \"\"\"\n    Checks if the given string represents a valid ISBN 13 (International Standard Book Number).\n    By default hyphens in the string are ignored, so digits can be separated in different ways, by calling this\n    function with `normalize=False` only digit-only strings will pass the validation.\n\n    *Examples:*\n\n    >>> is_isbn_13('9780312498580') # returns true\n    >>> is_isbn_13('978-0312498580') # returns true\n    >>> is_isbn_13('978-0312498580', normalize=False) # returns false\n\n    :param input_string: String to check.\n    :param normalize: True to ignore hyphens (\"-\") in the string (default), false otherwise.\n    :return: True if valid ISBN 13, false otherwise.\n    \"\"\"\n", "function_signature": "def is_isbn_13(input_string: str, normalize: bool = True) -> bool:"}}
{"prompt": "def is_isbn(input_string: str, normalize: bool = True) -> bool:\n    \"\"\"\n    Checks if the given string represents a valid ISBN (International Standard Book Number).\n    By default hyphens in the string are ignored, so digits can be separated in different ways, by calling this\n    function with `normalize=False` only digit-only strings will pass the validation.\n\n    *Examples:*\n\n    >>> is_isbn('9780312498580') # returns true\n    >>> is_isbn('1506715214') # returns true\n\n    :param input_string: String to check.\n    :param normalize: True to ignore hyphens (\"-\") in the string (default), false otherwise.\n    :return: True if valid ISBN (10 or 13), false otherwise.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/35", "ground_truth": "    checker = __ISBNChecker(input_string, normalize)\n    return checker.is_isbn_13() or checker.is_isbn_10()", "fpath_tuple": ["python-string-utils", "string_utils", "validation.py"], "context_start_lineno": 640, "line_no": 655, "id": 36, "target_function_prompt": "def is_isbn(input_string: str, normalize: bool = True) -> bool:\n    \"\"\"\n    Checks if the given string represents a valid ISBN (International Standard Book Number).\n    By default hyphens in the string are ignored, so digits can be separated in different ways, by calling this\n    function with `normalize=False` only digit-only strings will pass the validation.\n\n    *Examples:*\n\n    >>> is_isbn('9780312498580') # returns true\n    >>> is_isbn('1506715214') # returns true\n\n    :param input_string: String to check.\n    :param normalize: True to ignore hyphens (\"-\") in the string (default), false otherwise.\n    :return: True if valid ISBN (10 or 13), false otherwise.\n    \"\"\"\n", "function_signature": "def is_isbn(input_string: str, normalize: bool = True) -> bool:"}}
{"prompt": "def uuid(as_hex: bool = False) -> str:\n    \"\"\"\n    Generated an UUID string (using `uuid.uuid4()`).\n\n    *Examples:*\n\n    >>> uuid() # possible output: '97e3a716-6b33-4ab9-9bb1-8128cb24d76b'\n    >>> uuid(as_hex=True) # possible output: '97e3a7166b334ab99bb18128cb24d76b'\n\n    :param as_hex: True to return the hex value of the UUID, False to get its default representation (default).\n    :return: uuid string.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/36", "ground_truth": "    uid = uuid4()\n\n    if as_hex:\n        return uid.hex\n\n    return str(uid)", "fpath_tuple": ["python-string-utils", "string_utils", "generation.py"], "context_start_lineno": 20, "line_no": 32, "id": 37, "target_function_prompt": "def uuid(as_hex: bool = False) -> str:\n    \"\"\"\n    Generated an UUID string (using `uuid.uuid4()`).\n\n    *Examples:*\n\n    >>> uuid() # possible output: '97e3a716-6b33-4ab9-9bb1-8128cb24d76b'\n    >>> uuid(as_hex=True) # possible output: '97e3a7166b334ab99bb18128cb24d76b'\n\n    :param as_hex: True to return the hex value of the UUID, False to get its default representation (default).\n    :return: uuid string.\n    \"\"\"\n", "function_signature": "def uuid(as_hex: bool = False) -> str:"}}
{"prompt": "def secure_random_hex(byte_count: int) -> str:\n    \"\"\"\n    Generates a random string using secure low level random generator (os.urandom).\n\n    **Bear in mind**: due to hex conversion, the returned string will have a size that is exactly\\\n    the double of the given `byte_count`.\n\n    *Example:*\n\n    >>> secure_random_hex(9) # possible output: 'aac4cf1d1d87bd5036'\n\n    :param byte_count: Number of random bytes to generate\n    :type byte_count: int\n    :return: Hexadecimal string representation of generated random bytes\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/37", "ground_truth": "    if not isinstance(byte_count, int) or byte_count < 1:\n        raise ValueError('byte_count must be >= 1')\n\n    random_bytes = os.urandom(byte_count)\n    hex_bytes = binascii.hexlify(random_bytes)\n    hex_string = hex_bytes.decode()\n\n    return hex_string", "fpath_tuple": ["python-string-utils", "string_utils", "generation.py"], "context_start_lineno": 62, "line_no": 77, "id": 39, "target_function_prompt": "def secure_random_hex(byte_count: int) -> str:\n    \"\"\"\n    Generates a random string using secure low level random generator (os.urandom).\n\n    **Bear in mind**: due to hex conversion, the returned string will have a size that is exactly\\\n    the double of the given `byte_count`.\n\n    *Example:*\n\n    >>> secure_random_hex(9) # possible output: 'aac4cf1d1d87bd5036'\n\n    :param byte_count: Number of random bytes to generate\n    :type byte_count: int\n    :return: Hexadecimal string representation of generated random bytes\n    \"\"\"\n", "function_signature": "def secure_random_hex(byte_count: int) -> str:"}}
{"prompt": "def roman_range(stop: int, start: int = 1, step: int = 1) -> Generator:\n    \"\"\"\n    Similarly to native Python's `range()`, returns a Generator object which generates a new roman number\n    on each iteration instead of an integer.\n\n    *Example:*\n\n    >>> for n in roman_range(7): print(n)\n    >>> # prints: I, II, III, IV, V, VI, VII\n    >>> for n in roman_range(start=7, stop=1, step=-1): print(n)\n    >>> # prints: VII, VI, V, IV, III, II, I\n\n    :param stop: Number at which the generation must stop (must be <= 3999).\n    :param start: Number at which the generation must start (must be >= 1).\n    :param step: Increment of each generation step (default to 1).\n    :return: Generator of roman numbers.\n    \"\"\"\n", "metadata": {"task_id": "python-string-utils/38", "ground_truth": "\n    def validate(arg_value, arg_name, allow_negative=False):\n        msg = '\"{}\" must be an integer in the range 1-3999'.format(arg_name)\n\n        if not isinstance(arg_value, int):\n            raise ValueError(msg)\n\n        if allow_negative:\n            arg_value = abs(arg_value)\n\n        if arg_value < 1 or arg_value > 3999:\n            raise ValueError(msg)\n\n    def generate():\n        current = start\n\n        # generate values for each step\n        while current != stop:\n            yield roman_encode(current)\n            current += step\n\n        # last value to return\n        yield roman_encode(current)\n\n    # checks each single argument value\n    validate(stop, 'stop')\n    validate(start, 'start')\n    validate(step, 'step', allow_negative=True)\n\n    # checks if the provided configuration leads to a feasible iteration with respect to boundaries or not\n    forward_exceed = step > 0 and (start > stop or start + step > stop)\n    backward_exceed = step < 0 and (start < stop or start + step < stop)\n    if forward_exceed or backward_exceed:\n        raise OverflowError('Invalid start/stop/step configuration')\n\n    return generate()", "fpath_tuple": ["python-string-utils", "string_utils", "generation.py"], "context_start_lineno": 87, "line_no": 104, "id": 40, "target_function_prompt": "def roman_range(stop: int, start: int = 1, step: int = 1) -> Generator:\n    \"\"\"\n    Similarly to native Python's `range()`, returns a Generator object which generates a new roman number\n    on each iteration instead of an integer.\n\n    *Example:*\n\n    >>> for n in roman_range(7): print(n)\n    >>> # prints: I, II, III, IV, V, VI, VII\n    >>> for n in roman_range(start=7, stop=1, step=-1): print(n)\n    >>> # prints: VII, VI, V, IV, III, II, I\n\n    :param stop: Number at which the generation must stop (must be <= 3999).\n    :param start: Number at which the generation must start (must be >= 1).\n    :param step: Increment of each generation step (default to 1).\n    :return: Generator of roman numbers.\n    \"\"\"\n", "function_signature": "def roman_range(stop: int, start: int = 1, step: int = 1) -> Generator:"}}
{"prompt": "def urlparse_cached(request_or_response: Union[Request, Response]) -> ParseResult:\n    \"\"\"Return urlparse.urlparse caching the result, where the argument can be a\n    Request or Response object\n    \"\"\"\n", "metadata": {"task_id": "scrapy/0", "ground_truth": "    if request_or_response not in _urlparse_cache:\n        _urlparse_cache[request_or_response] = urlparse(request_or_response.url)\n    return _urlparse_cache[request_or_response]", "fpath_tuple": ["scrapy", "scrapy", "utils", "httpobj.py"], "context_start_lineno": 12, "line_no": 16, "id": 41, "target_function_prompt": "def urlparse_cached(request_or_response: Union[Request, Response]) -> ParseResult:\n    \"\"\"Return urlparse.urlparse caching the result, where the argument can be a\n    Request or Response object\n    \"\"\"\n", "function_signature": "def urlparse_cached(request_or_response: Union[Request, Response]) -> ParseResult:"}}
{"prompt": "def string_camelcase(string):\n    \"\"\" Convert a word  to its CamelCase version and remove invalid chars\n\n    >>> string_camelcase('lost-pound')\n    'LostPound'\n\n    >>> string_camelcase('missing_images')\n    'MissingImages'\n\n    \"\"\"\n", "metadata": {"task_id": "scrapy/1", "ground_truth": "    return CAMELCASE_INVALID_CHARS.sub('', string.title())", "fpath_tuple": ["scrapy", "scrapy", "utils", "template.py"], "context_start_lineno": 25, "line_no": 35, "id": 42, "target_function_prompt": "def string_camelcase(string):\n    \"\"\" Convert a word  to its CamelCase version and remove invalid chars\n\n    >>> string_camelcase('lost-pound')\n    'LostPound'\n\n    >>> string_camelcase('missing_images')\n    'MissingImages'\n\n    \"\"\"\n", "function_signature": "def string_camelcase(string):"}}
{"prompt": "def flatten(x):\n    \"\"\"flatten(sequence) -> list\n\n    Returns a single, flat list which contains all elements retrieved\n    from the sequence and all recursively contained sub-sequences\n    (iterables).\n\n    Examples:\n    >>> [1, 2, [3,4], (5,6)]\n    [1, 2, [3, 4], (5, 6)]\n    >>> flatten([[[1,2,3], (42,None)], [4,5], [6], 7, (8,9,10)])\n    [1, 2, 3, 42, None, 4, 5, 6, 7, 8, 9, 10]\n    >>> flatten([\"foo\", \"bar\"])\n    ['foo', 'bar']\n    >>> flatten([\"foo\", [\"baz\", 42], \"bar\"])\n    ['foo', 'baz', 42, 'bar']\n    \"\"\"\n", "metadata": {"task_id": "scrapy/2", "ground_truth": "    return list(iflatten(x))", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 17, "line_no": 34, "id": 43, "target_function_prompt": "def flatten(x):\n    \"\"\"flatten(sequence) -> list\n\n    Returns a single, flat list which contains all elements retrieved\n    from the sequence and all recursively contained sub-sequences\n    (iterables).\n\n    Examples:\n    >>> [1, 2, [3,4], (5,6)]\n    [1, 2, [3, 4], (5, 6)]\n    >>> flatten([[[1,2,3], (42,None)], [4,5], [6], 7, (8,9,10)])\n    [1, 2, 3, 42, None, 4, 5, 6, 7, 8, 9, 10]\n    >>> flatten([\"foo\", \"bar\"])\n    ['foo', 'bar']\n    >>> flatten([\"foo\", [\"baz\", 42], \"bar\"])\n    ['foo', 'baz', 42, 'bar']\n    \"\"\"\n", "function_signature": "def flatten(x):"}}
{"prompt": "def is_listlike(x):\n    \"\"\"\n    >>> is_listlike(\"foo\")\n    False\n    >>> is_listlike(5)\n    False\n    >>> is_listlike(b\"foo\")\n    False\n    >>> is_listlike([b\"foo\"])\n    True\n    >>> is_listlike((b\"foo\",))\n    True\n    >>> is_listlike({})\n    True\n    >>> is_listlike(set())\n    True\n    >>> is_listlike((x for x in range(3)))\n    True\n    >>> is_listlike(range(5))\n    True\n    \"\"\"\n", "metadata": {"task_id": "scrapy/3", "ground_truth": "    return hasattr(x, \"__iter__\") and not isinstance(x, (str, bytes))", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 49, "line_no": 70, "id": 44, "target_function_prompt": "def is_listlike(x):\n    \"\"\"\n    >>> is_listlike(\"foo\")\n    False\n    >>> is_listlike(5)\n    False\n    >>> is_listlike(b\"foo\")\n    False\n    >>> is_listlike([b\"foo\"])\n    True\n    >>> is_listlike((b\"foo\",))\n    True\n    >>> is_listlike({})\n    True\n    >>> is_listlike(set())\n    True\n    >>> is_listlike((x for x in range(3)))\n    True\n    >>> is_listlike(range(5))\n    True\n    \"\"\"\n", "function_signature": "def is_listlike(x):"}}
{"prompt": "def unique(list_, key=lambda x: x):\n    \"\"\"efficient function to uniquify a list preserving item order\"\"\"\n", "metadata": {"task_id": "scrapy/4", "ground_truth": "    seen = set()\n    result = []\n    for item in list_:\n        seenkey = key(item)\n        if seenkey in seen:\n            continue\n        seen.add(seenkey)\n        result.append(item)\n    return result", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 73, "line_no": 75, "id": 45, "target_function_prompt": "def unique(list_, key=lambda x: x):\n    \"\"\"efficient function to uniquify a list preserving item order\"\"\"\n", "function_signature": "def unique(list_, key=lambda x: x):"}}
{"prompt": "def to_unicode(text, encoding=None, errors='strict'):\n    \"\"\"Return the unicode representation of a bytes object ``text``. If\n    ``text`` is already an unicode object, return it as-is.\"\"\"\n", "metadata": {"task_id": "scrapy/5", "ground_truth": "    if isinstance(text, str):\n        return text\n    if not isinstance(text, (bytes, str)):\n        raise TypeError('to_unicode must receive a bytes or str '\n                        f'object, got {type(text).__name__}')\n    if encoding is None:\n        encoding = 'utf-8'\n    return text.decode(encoding, errors)", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 86, "line_no": 89, "id": 46, "target_function_prompt": "def to_unicode(text, encoding=None, errors='strict'):\n    \"\"\"Return the unicode representation of a bytes object ``text``. If\n    ``text`` is already an unicode object, return it as-is.\"\"\"\n", "function_signature": "def to_unicode(text, encoding=None, errors='strict'):"}}
{"prompt": "def to_bytes(text, encoding=None, errors='strict'):\n    \"\"\"Return the binary representation of ``text``. If ``text``\n    is already a bytes object, return it as-is.\"\"\"\n", "metadata": {"task_id": "scrapy/6", "ground_truth": "    if isinstance(text, bytes):\n        return text\n    if not isinstance(text, str):\n        raise TypeError('to_bytes must receive a str or bytes '\n                        f'object, got {type(text).__name__}')\n    if encoding is None:\n        encoding = 'utf-8'\n    return text.encode(encoding, errors)", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 99, "line_no": 102, "id": 47, "target_function_prompt": "def to_bytes(text, encoding=None, errors='strict'):\n    \"\"\"Return the binary representation of ``text``. If ``text``\n    is already a bytes object, return it as-is.\"\"\"\n", "function_signature": "def to_bytes(text, encoding=None, errors='strict'):"}}
{"prompt": "def to_native_str(text, encoding=None, errors='strict'):\n    \"\"\" Return str representation of ``text``. \"\"\"\n", "metadata": {"task_id": "scrapy/7", "ground_truth": "    return to_unicode(text, encoding, errors)", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 113, "line_no": 115, "id": 48, "target_function_prompt": "def to_native_str(text, encoding=None, errors='strict'):\n    \"\"\" Return str representation of ``text``. \"\"\"\n", "function_signature": "def to_native_str(text, encoding=None, errors='strict'):"}}
{"prompt": "def re_rsearch(pattern, text, chunk_size=1024):\n    \"\"\"\n    This function does a reverse search in a text using a regular expression\n    given in the attribute 'pattern'.\n    Since the re module does not provide this functionality, we have to find for\n    the expression into chunks of text extracted from the end (for the sake of efficiency).\n    At first, a chunk of 'chunk_size' kilobytes is extracted from the end, and searched for\n    the pattern. If the pattern is not found, another chunk is extracted, and another\n    search is performed.\n    This process continues until a match is found, or until the whole file is read.\n    In case the pattern wasn't found, None is returned, otherwise it returns a tuple containing\n    the start position of the match, and the ending (regarding the entire text).\n    \"\"\"\n", "metadata": {"task_id": "scrapy/8", "ground_truth": "\n    def _chunk_iter():\n        offset = len(text)\n        while True:\n            offset -= (chunk_size * 1024)\n            if offset <= 0:\n                break\n            yield (text[offset:], offset)\n        yield (text, 0)\n\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern)\n\n    for chunk, offset in _chunk_iter():\n        matches = [match for match in pattern.finditer(chunk)]\n        if matches:\n            start, end = matches[-1].span()\n            return offset + start, offset + end\n    return None", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 118, "line_no": 131, "id": 49, "target_function_prompt": "def re_rsearch(pattern, text, chunk_size=1024):\n    \"\"\"\n    This function does a reverse search in a text using a regular expression\n    given in the attribute 'pattern'.\n    Since the re module does not provide this functionality, we have to find for\n    the expression into chunks of text extracted from the end (for the sake of efficiency).\n    At first, a chunk of 'chunk_size' kilobytes is extracted from the end, and searched for\n    the pattern. If the pattern is not found, another chunk is extracted, and another\n    search is performed.\n    This process continues until a match is found, or until the whole file is read.\n    In case the pattern wasn't found, None is returned, otherwise it returns a tuple containing\n    the start position of the match, and the ending (regarding the entire text).\n    \"\"\"\n", "function_signature": "def re_rsearch(pattern, text, chunk_size=1024):"}}
{"prompt": "def memoizemethod_noargs(method):\n    \"\"\"Decorator to cache the result of a method (without arguments) using a\n    weak reference to its object\n    \"\"\"\n", "metadata": {"task_id": "scrapy/9", "ground_truth": "    cache = weakref.WeakKeyDictionary()\n\n    @wraps(method)\n    def new_method(self, *args, **kwargs):\n        if self not in cache:\n            cache[self] = method(self, *args, **kwargs)\n        return cache[self]\n\n    return new_method", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 152, "line_no": 156, "id": 50, "target_function_prompt": "def memoizemethod_noargs(method):\n    \"\"\"Decorator to cache the result of a method (without arguments) using a\n    weak reference to its object\n    \"\"\"\n", "function_signature": "def memoizemethod_noargs(method):"}}
{"prompt": "def binary_is_text(data):\n    \"\"\" Returns ``True`` if the given ``data`` argument (a ``bytes`` object)\n    does not contain unprintable control characters.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/10", "ground_truth": "    if not isinstance(data, bytes):\n        raise TypeError(f\"data must be bytes, got '{type(data).__name__}'\")\n    return all(c not in _BINARYCHARS for c in data)", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 171, "line_no": 175, "id": 51, "target_function_prompt": "def binary_is_text(data):\n    \"\"\" Returns ``True`` if the given ``data`` argument (a ``bytes`` object)\n    does not contain unprintable control characters.\n    \"\"\"\n", "function_signature": "def binary_is_text(data):"}}
{"prompt": "def _getargspec_py23(func):\n    \"\"\"_getargspec_py23(function) -> named tuple ArgSpec(args, varargs, keywords,\n    defaults)\n\n    Was identical to inspect.getargspec() in python2, but uses\n    inspect.getfullargspec() for python3 behind the scenes to avoid\n    DeprecationWarning.\n\n    >>> def f(a, b=2, *ar, **kw):\n    ...     pass\n\n    >>> _getargspec_py23(f)\n    ArgSpec(args=['a', 'b'], varargs='ar', keywords='kw', defaults=(2,))\n    \"\"\"\n", "metadata": {"task_id": "scrapy/11", "ground_truth": "    return inspect.ArgSpec(*inspect.getfullargspec(func)[:4])", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 180, "line_no": 194, "id": 52, "target_function_prompt": "def _getargspec_py23(func):\n    \"\"\"_getargspec_py23(function) -> named tuple ArgSpec(args, varargs, keywords,\n    defaults)\n\n    Was identical to inspect.getargspec() in python2, but uses\n    inspect.getfullargspec() for python3 behind the scenes to avoid\n    DeprecationWarning.\n\n    >>> def f(a, b=2, *ar, **kw):\n    ...     pass\n\n    >>> _getargspec_py23(f)\n    ArgSpec(args=['a', 'b'], varargs='ar', keywords='kw', defaults=(2,))\n    \"\"\"\n", "function_signature": "def _getargspec_py23(func):"}}
{"prompt": "def get_func_args(func, stripself=False):\n    \"\"\"Return the argument name list of a callable\"\"\"\n", "metadata": {"task_id": "scrapy/12", "ground_truth": "    if inspect.isfunction(func):\n        spec = inspect.getfullargspec(func)\n        func_args = spec.args + spec.kwonlyargs\n    elif inspect.isclass(func):\n        return get_func_args(func.__init__, True)\n    elif inspect.ismethod(func):\n        return get_func_args(func.__func__, True)\n    elif inspect.ismethoddescriptor(func):\n        return []\n    elif isinstance(func, partial):\n        return [x for x in get_func_args(func.func)[len(func.args):]\n                if not (func.keywords and x in func.keywords)]\n    elif hasattr(func, '__call__'):\n        if inspect.isroutine(func):\n            return []\n        elif getattr(func, '__name__', None) == '__call__':\n            return []\n        else:\n            return get_func_args(func.__call__, True)\n    else:\n        raise TypeError(f'{type(func)} is not callable')\n    if stripself:\n        func_args.pop(0)\n    return func_args", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 197, "line_no": 199, "id": 53, "target_function_prompt": "def get_func_args(func, stripself=False):\n    \"\"\"Return the argument name list of a callable\"\"\"\n", "function_signature": "def get_func_args(func, stripself=False):"}}
{"prompt": "def get_spec(func):\n    \"\"\"Returns (args, kwargs) tuple for a function\n    >>> import re\n    >>> get_spec(re.match)\n    (['pattern', 'string'], {'flags': 0})\n\n    >>> class Test:\n    ...     def __call__(self, val):\n    ...         pass\n    ...     def method(self, val, flags=0):\n    ...         pass\n\n    >>> get_spec(Test)\n    (['self', 'val'], {})\n\n    >>> get_spec(Test.method)\n    (['self', 'val'], {'flags': 0})\n\n    >>> get_spec(Test().method)\n    (['self', 'val'], {'flags': 0})\n    \"\"\"\n", "metadata": {"task_id": "scrapy/13", "ground_truth": "\n    if inspect.isfunction(func) or inspect.ismethod(func):\n        spec = _getargspec_py23(func)\n    elif hasattr(func, '__call__'):\n        spec = _getargspec_py23(func.__call__)\n    else:\n        raise TypeError(f'{type(func)} is not callable')\n\n    defaults = spec.defaults or []\n\n    firstdefault = len(spec.args) - len(defaults)\n    args = spec.args[:firstdefault]\n    kwargs = dict(zip(spec.args[firstdefault:], defaults))\n    return args, kwargs", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 225, "line_no": 246, "id": 54, "target_function_prompt": "def get_spec(func):\n    \"\"\"Returns (args, kwargs) tuple for a function\n    >>> import re\n    >>> get_spec(re.match)\n    (['pattern', 'string'], {'flags': 0})\n\n    >>> class Test:\n    ...     def __call__(self, val):\n    ...         pass\n    ...     def method(self, val, flags=0):\n    ...         pass\n\n    >>> get_spec(Test)\n    (['self', 'val'], {})\n\n    >>> get_spec(Test.method)\n    (['self', 'val'], {'flags': 0})\n\n    >>> get_spec(Test().method)\n    (['self', 'val'], {'flags': 0})\n    \"\"\"\n", "function_signature": "def get_spec(func):"}}
{"prompt": "def equal_attributes(obj1, obj2, attributes):\n    \"\"\"Compare two objects attributes\"\"\"\n", "metadata": {"task_id": "scrapy/14", "ground_truth": "    # not attributes given return False by default\n    if not attributes:\n        return False\n\n    temp1, temp2 = object(), object()\n    for attr in attributes:\n        # support callables like itemgetter\n        if callable(attr):\n            if attr(obj1) != attr(obj2):\n                return False\n        elif getattr(obj1, attr, temp1) != getattr(obj2, attr, temp2):\n            return False\n    # all attributes equal\n    return True", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 262, "line_no": 264, "id": 55, "target_function_prompt": "def equal_attributes(obj1, obj2, attributes):\n    \"\"\"Compare two objects attributes\"\"\"\n", "function_signature": "def equal_attributes(obj1, obj2, attributes):"}}
{"prompt": "def retry_on_eintr(function, *args, **kw):\n    \"\"\"Run a function and retry it while getting EINTR errors\"\"\"\n", "metadata": {"task_id": "scrapy/15", "ground_truth": "    while True:\n        try:\n            return function(*args, **kw)\n        except IOError as e:\n            if e.errno != errno.EINTR:\n                raise", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 294, "line_no": 296, "id": 56, "target_function_prompt": "def retry_on_eintr(function, *args, **kw):\n    \"\"\"Run a function and retry it while getting EINTR errors\"\"\"\n", "function_signature": "def retry_on_eintr(function, *args, **kw):"}}
{"prompt": "def without_none_values(iterable):\n    \"\"\"Return a copy of ``iterable`` with all ``None`` entries removed.\n\n    If ``iterable`` is a mapping, return a dictionary where all pairs that have\n    value ``None`` have been removed.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/16", "ground_truth": "    try:\n        return {k: v for k, v in iterable.items() if v is not None}\n    except AttributeError:\n        return type(iterable)((v for v in iterable if v is not None))", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 304, "line_no": 310, "id": 57, "target_function_prompt": "def without_none_values(iterable):\n    \"\"\"Return a copy of ``iterable`` with all ``None`` entries removed.\n\n    If ``iterable`` is a mapping, return a dictionary where all pairs that have\n    value ``None`` have been removed.\n    \"\"\"\n", "function_signature": "def without_none_values(iterable):"}}
{"prompt": "def global_object_name(obj):\n    \"\"\"\n    Return full name of a global object.\n\n    >>> from scrapy import Request\n    >>> global_object_name(Request)\n    'scrapy.http.request.Request'\n    \"\"\"\n", "metadata": {"task_id": "scrapy/17", "ground_truth": "    return f\"{obj.__module__}.{obj.__name__}\"", "fpath_tuple": ["scrapy", "scrapy", "utils", "python.py"], "context_start_lineno": 316, "line_no": 324, "id": 58, "target_function_prompt": "def global_object_name(obj):\n    \"\"\"\n    Return full name of a global object.\n\n    >>> from scrapy import Request\n    >>> global_object_name(Request)\n    'scrapy.http.request.Request'\n    \"\"\"\n", "function_signature": "def global_object_name(obj):"}}
{"prompt": "def request_fingerprint(\n    request: Request,\n    include_headers: Optional[Iterable[Union[bytes, str]]] = None,\n    keep_fragments: bool = False,\n):\n    \"\"\"\n    Return the request fingerprint.\n\n    The request fingerprint is a hash that uniquely identifies the resource the\n    request points to. For example, take the following two urls:\n\n    http://www.example.com/query?id=111&cat=222\n    http://www.example.com/query?cat=222&id=111\n\n    Even though those are two different URLs both point to the same resource\n    and are equivalent (i.e. they should return the same response).\n\n    Another example are cookies used to store session ids. Suppose the\n    following page is only accessible to authenticated users:\n\n    http://www.example.com/members/offers.html\n\n    Lot of sites use a cookie to store the session id, which adds a random\n    component to the HTTP Request and thus should be ignored when calculating\n    the fingerprint.\n\n    For this reason, request headers are ignored by default when calculating\n    the fingeprint. If you want to include specific headers use the\n    include_headers argument, which is a list of Request headers to include.\n\n    Also, servers usually ignore fragments in urls when handling requests,\n    so they are also ignored by default when calculating the fingerprint.\n    If you want to include them, set the keep_fragments argument to True\n    (for instance when handling requests with a headless browser).\n\n    \"\"\"\n", "metadata": {"task_id": "scrapy/18", "ground_truth": "    headers: Optional[Tuple[bytes, ...]] = None\n    if include_headers:\n        headers = tuple(to_bytes(h.lower()) for h in sorted(include_headers))\n    cache = _fingerprint_cache.setdefault(request, {})\n    cache_key = (headers, keep_fragments)\n    if cache_key not in cache:\n        fp = hashlib.sha1()\n        fp.update(to_bytes(request.method))\n        fp.update(to_bytes(canonicalize_url(request.url, keep_fragments=keep_fragments)))\n        fp.update(request.body or b'')\n        if headers:\n            for hdr in headers:\n                if hdr in request.headers:\n                    fp.update(hdr)\n                    for v in request.headers.getlist(hdr):\n                        fp.update(v)\n        cache[cache_key] = fp.hexdigest()\n    return cache[cache_key]", "fpath_tuple": ["scrapy", "scrapy", "utils", "request.py"], "context_start_lineno": 22, "line_no": 58, "id": 59, "target_function_prompt": "def request_fingerprint(\n    request: Request,\n    include_headers: Optional[Iterable[Union[bytes, str]]] = None,\n    keep_fragments: bool = False,\n):\n    \"\"\"\n    Return the request fingerprint.\n\n    The request fingerprint is a hash that uniquely identifies the resource the\n    request points to. For example, take the following two urls:\n\n    http://www.example.com/query?id=111&cat=222\n    http://www.example.com/query?cat=222&id=111\n\n    Even though those are two different URLs both point to the same resource\n    and are equivalent (i.e. they should return the same response).\n\n    Another example are cookies used to store session ids. Suppose the\n    following page is only accessible to authenticated users:\n\n    http://www.example.com/members/offers.html\n\n    Lot of sites use a cookie to store the session id, which adds a random\n    component to the HTTP Request and thus should be ignored when calculating\n    the fingerprint.\n\n    For this reason, request headers are ignored by default when calculating\n    the fingeprint. If you want to include specific headers use the\n    include_headers argument, which is a list of Request headers to include.\n\n    Also, servers usually ignore fragments in urls when handling requests,\n    so they are also ignored by default when calculating the fingerprint.\n    If you want to include them, set the keep_fragments argument to True\n    (for instance when handling requests with a headless browser).\n\n    \"\"\"\n", "function_signature": "def request_fingerprint(\n    request: Request,\n    include_headers: Optional[Iterable[Union[bytes, str]]] = None,\n    keep_fragments: bool = False,\n):"}}
{"prompt": "def request_httprepr(request: Request) -> bytes:\n    \"\"\"Return the raw HTTP representation (as bytes) of the given request.\n    This is provided only for reference since it's not the actual stream of\n    bytes that will be send when performing the request (that's controlled\n    by Twisted).\n    \"\"\"\n", "metadata": {"task_id": "scrapy/19", "ground_truth": "    parsed = urlparse_cached(request)\n    path = urlunparse(('', '', parsed.path or '/', parsed.params, parsed.query, ''))\n    s = to_bytes(request.method) + b\" \" + to_bytes(path) + b\" HTTP/1.1\\r\\n\"\n    s += b\"Host: \" + to_bytes(parsed.hostname or b'') + b\"\\r\\n\"\n    if request.headers:\n        s += request.headers.to_string() + b\"\\r\\n\"\n    s += b\"\\r\\n\"\n    s += request.body\n    return s", "fpath_tuple": ["scrapy", "scrapy", "utils", "request.py"], "context_start_lineno": 85, "line_no": 91, "id": 60, "target_function_prompt": "def request_httprepr(request: Request) -> bytes:\n    \"\"\"Return the raw HTTP representation (as bytes) of the given request.\n    This is provided only for reference since it's not the actual stream of\n    bytes that will be send when performing the request (that's controlled\n    by Twisted).\n    \"\"\"\n", "function_signature": "def request_httprepr(request: Request) -> bytes:"}}
{"prompt": "def referer_str(request: Request) -> Optional[str]:\n    \"\"\" Return Referer HTTP header suitable for logging. \"\"\"\n", "metadata": {"task_id": "scrapy/20", "ground_truth": "    referrer = request.headers.get('Referer')\n    if referrer is None:\n        return referrer\n    return to_unicode(referrer, errors='replace')", "fpath_tuple": ["scrapy", "scrapy", "utils", "request.py"], "context_start_lineno": 102, "line_no": 104, "id": 61, "target_function_prompt": "def referer_str(request: Request) -> Optional[str]:\n    \"\"\" Return Referer HTTP header suitable for logging. \"\"\"\n", "function_signature": "def referer_str(request: Request) -> Optional[str]:"}}
{"prompt": "def get_engine_status(engine):\n    \"\"\"Return a report of the current engine status\"\"\"\n", "metadata": {"task_id": "scrapy/21", "ground_truth": "    tests = [\n        \"time()-engine.start_time\",\n        \"engine.has_capacity()\",\n        \"len(engine.downloader.active)\",\n        \"engine.scraper.is_idle()\",\n        \"engine.spider.name\",\n        \"engine.spider_is_idle(engine.spider)\",\n        \"engine.slot.closing\",\n        \"len(engine.slot.inprogress)\",\n        \"len(engine.slot.scheduler.dqs or [])\",\n        \"len(engine.slot.scheduler.mqs)\",\n        \"len(engine.scraper.slot.queue)\",\n        \"len(engine.scraper.slot.active)\",\n        \"engine.scraper.slot.active_size\",\n        \"engine.scraper.slot.itemproc_size\",\n        \"engine.scraper.slot.needs_backout()\",\n    ]\n\n    checks = []\n    for test in tests:\n        try:\n            checks += [(test, eval(test))]\n        except Exception as e:\n            checks += [(test, f\"{type(e).__name__} (exception)\")]\n\n    return checks", "fpath_tuple": ["scrapy", "scrapy", "utils", "engine.py"], "context_start_lineno": 6, "line_no": 8, "id": 62, "target_function_prompt": "def get_engine_status(engine):\n    \"\"\"Return a report of the current engine status\"\"\"\n", "function_signature": "def get_engine_status(engine):"}}
{"prompt": "def parse_cachecontrol(header):\n    \"\"\"Parse Cache-Control header\n\n    https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9\n\n    >>> parse_cachecontrol(b'public, max-age=3600') == {b'public': None,\n    ...                                                 b'max-age': b'3600'}\n    True\n    >>> parse_cachecontrol(b'') == {}\n    True\n\n    \"\"\"\n", "metadata": {"task_id": "scrapy/22", "ground_truth": "    directives = {}\n    for directive in header.split(b','):\n        key, sep, val = directive.strip().partition(b'=')\n        if key:\n            directives[key.lower()] = val if sep else None\n    return directives", "fpath_tuple": ["scrapy", "scrapy", "extensions", "httpcache.py"], "context_start_lineno": 346, "line_no": 358, "id": 63, "target_function_prompt": "def parse_cachecontrol(header):\n    \"\"\"Parse Cache-Control header\n\n    https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9\n\n    >>> parse_cachecontrol(b'public, max-age=3600') == {b'public': None,\n    ...                                                 b'max-age': b'3600'}\n    True\n    >>> parse_cachecontrol(b'') == {}\n    True\n\n    \"\"\"\n", "function_signature": "def parse_cachecontrol(header):"}}
{"prompt": "def gunzip(data):\n    \"\"\"Gunzip the given data and return as much data as possible.\n\n    This is resilient to CRC checksum errors.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/23", "ground_truth": "    f = GzipFile(fileobj=BytesIO(data))\n    output_list = []\n    chunk = b'.'\n    while chunk:\n        try:\n            chunk = f.read1(8196)\n            output_list.append(chunk)\n        except (IOError, EOFError, struct.error):\n            # complete only if there is some data, otherwise re-raise\n            # see issue 87 about catching struct.error\n            # some pages are quite small so output_list is empty and f.extrabuf\n            # contains the whole page content\n            if output_list or getattr(f, 'extrabuf', None):\n                try:\n                    output_list.append(f.extrabuf[-f.extrasize:])\n                finally:\n                    break\n            else:\n                raise\n    return b''.join(output_list)", "fpath_tuple": ["scrapy", "scrapy", "utils", "gz.py"], "context_start_lineno": 16, "line_no": 21, "id": 64, "target_function_prompt": "def gunzip(data):\n    \"\"\"Gunzip the given data and return as much data as possible.\n\n    This is resilient to CRC checksum errors.\n    \"\"\"\n", "function_signature": "def gunzip(data):"}}
{"prompt": "def csviter(obj, delimiter=None, headers=None, encoding=None, quotechar=None):\n    \"\"\" Returns an iterator of dictionaries from the given csv object\n\n    obj can be:\n    - a Response object\n    - a unicode string\n    - a string encoded as utf-8\n\n    delimiter is the character used to separate fields on the given obj.\n\n    headers is an iterable that when provided offers the keys\n    for the returned dictionaries, if not the first row is used.\n\n    quotechar is the character used to enclosure fields on the given obj.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/24", "ground_truth": "\n    encoding = obj.encoding if isinstance(obj, TextResponse) else encoding or 'utf-8'\n\n    def row_to_unicode(row_):\n        return [to_unicode(field, encoding) for field in row_]\n\n    lines = StringIO(_body_or_str(obj, unicode=True))\n\n    kwargs = {}\n    if delimiter:\n        kwargs[\"delimiter\"] = delimiter\n    if quotechar:\n        kwargs[\"quotechar\"] = quotechar\n    csv_r = csv.reader(lines, **kwargs)\n\n    if not headers:\n        try:\n            row = next(csv_r)\n        except StopIteration:\n            return\n        headers = row_to_unicode(row)\n\n    for row in csv_r:\n        row = row_to_unicode(row)\n        if len(row) != len(headers):\n            logger.warning(\"ignoring row %(csvlnum)d (length: %(csvrow)d, \"\n                           \"should be: %(csvheader)d)\",\n                           {'csvlnum': csv_r.line_num, 'csvrow': len(row),\n                            'csvheader': len(headers)})\n            continue\n        else:\n            yield dict(zip(headers, row))", "fpath_tuple": ["scrapy", "scrapy", "utils", "iterators.py"], "context_start_lineno": 95, "line_no": 110, "id": 65, "target_function_prompt": "def csviter(obj, delimiter=None, headers=None, encoding=None, quotechar=None):\n    \"\"\" Returns an iterator of dictionaries from the given csv object\n\n    obj can be:\n    - a Response object\n    - a unicode string\n    - a string encoded as utf-8\n\n    delimiter is the character used to separate fields on the given obj.\n\n    headers is an iterable that when provided offers the keys\n    for the returned dictionaries, if not the first row is used.\n\n    quotechar is the character used to enclosure fields on the given obj.\n    \"\"\"\n", "function_signature": "def csviter(obj, delimiter=None, headers=None, encoding=None, quotechar=None):"}}
{"prompt": "def _path_safe(text):\n    \"\"\"\n    Return a filesystem-safe version of a string ``text``\n\n    >>> _path_safe('simple.org').startswith('simple.org')\n    True\n    >>> _path_safe('dash-underscore_.org').startswith('dash-underscore_.org')\n    True\n    >>> _path_safe('some@symbol?').startswith('some_symbol_')\n    True\n    \"\"\"\n", "metadata": {"task_id": "scrapy/25", "ground_truth": "    pathable_slot = \"\".join([c if c.isalnum() or c in '-._' else '_'\n                             for c in text])\n    # as we replace some letters we can get collision for different slots\n    # add we add unique part\n    unique_slot = hashlib.md5(text.encode('utf8')).hexdigest()\n    return '-'.join([pathable_slot, unique_slot])", "fpath_tuple": ["scrapy", "scrapy", "pqueues.py"], "context_start_lineno": 8, "line_no": 19, "id": 66, "target_function_prompt": "def _path_safe(text):\n    \"\"\"\n    Return a filesystem-safe version of a string ``text``\n\n    >>> _path_safe('simple.org').startswith('simple.org')\n    True\n    >>> _path_safe('dash-underscore_.org').startswith('dash-underscore_.org')\n    True\n    >>> _path_safe('some@symbol?').startswith('some_symbol_')\n    True\n    \"\"\"\n", "function_signature": "def _path_safe(text):"}}
{"prompt": "def _embed_ptpython_shell(namespace={}, banner=''):\n    \"\"\"Start a ptpython shell\"\"\"\n", "metadata": {"task_id": "scrapy/26", "ground_truth": "    import ptpython.repl\n\n    @wraps(_embed_ptpython_shell)\n    def wrapper(namespace=namespace, banner=''):\n        print(banner)\n        ptpython.repl.embed(locals=namespace)\n    return wrapper", "fpath_tuple": ["scrapy", "scrapy", "utils", "console.py"], "context_start_lineno": 37, "line_no": 39, "id": 68, "target_function_prompt": "def _embed_ptpython_shell(namespace={}, banner=''):\n    \"\"\"Start a ptpython shell\"\"\"\n", "function_signature": "def _embed_ptpython_shell(namespace={}, banner=''):"}}
{"prompt": "def _request_deferred(request):\n    \"\"\"Wrap a request inside a Deferred.\n\n    This function is harmful, do not use it until you know what you are doing.\n\n    This returns a Deferred whose first pair of callbacks are the request\n    callback and errback. The Deferred also triggers when the request\n    callback/errback is executed (i.e. when the request is downloaded)\n\n    WARNING: Do not call request.replace() until after the deferred is called.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/27", "ground_truth": "    request_callback = request.callback\n    request_errback = request.errback\n\n    def _restore_callbacks(result):\n        request.callback = request_callback\n        request.errback = request_errback\n        return result\n\n    d = defer.Deferred()\n    d.addBoth(_restore_callbacks)\n    if request.callback:\n        d.addCallbacks(request.callback, request.errback)\n\n    request.callback, request.errback = d.callback, d.errback\n    return d", "fpath_tuple": ["scrapy", "scrapy", "shell.py"], "context_start_lineno": 163, "line_no": 174, "id": 70, "target_function_prompt": "def _request_deferred(request):\n    \"\"\"Wrap a request inside a Deferred.\n\n    This function is harmful, do not use it until you know what you are doing.\n\n    This returns a Deferred whose first pair of callbacks are the request\n    callback and errback. The Deferred also triggers when the request\n    callback/errback is executed (i.e. when the request is downloaded)\n\n    WARNING: Do not call request.replace() until after the deferred is called.\n    \"\"\"\n", "function_signature": "def _request_deferred(request):"}}
{"prompt": "def wrap_loader_context(function, context):\n    \"\"\"Wrap functions that receive loader_context to contain the context\n    \"pre-loaded\" and expose a interface that receives only one argument\n    \"\"\"\n", "metadata": {"task_id": "scrapy/28", "ground_truth": "    warnings.warn(\n        \"scrapy.loader.common.wrap_loader_context has moved to a new library.\"\n        \"Please update your reference to itemloaders.common.wrap_loader_context\",\n        ScrapyDeprecationWarning,\n        stacklevel=2\n    )\n\n    return common.wrap_loader_context(function, context)", "fpath_tuple": ["scrapy", "scrapy", "loader", "common.py"], "context_start_lineno": 9, "line_no": 13, "id": 71, "target_function_prompt": "def wrap_loader_context(function, context):\n    \"\"\"Wrap functions that receive loader_context to contain the context\n    \"pre-loaded\" and expose a interface that receives only one argument\n    \"\"\"\n", "function_signature": "def wrap_loader_context(function, context):"}}
{"prompt": "def _has_ajaxcrawlable_meta(text):\n    \"\"\"\n    >>> _has_ajaxcrawlable_meta('<html><head><meta name=\"fragment\"  content=\"!\"/></head><body></body></html>')\n    True\n    >>> _has_ajaxcrawlable_meta(\"<html><head><meta name='fragment' content='!'></head></html>\")\n    True\n    >>> _has_ajaxcrawlable_meta('<html><head><!--<meta name=\"fragment\"  content=\"!\"/>--></head><body></body></html>')\n    False\n    >>> _has_ajaxcrawlable_meta('<html></html>')\n    False\n    \"\"\"\n", "metadata": {"task_id": "scrapy/29", "ground_truth": "\n    # Stripping scripts and comments is slow (about 20x slower than\n    # just checking if a string is in text); this is a quick fail-fast\n    # path that should work for most pages.\n    if 'fragment' not in text:\n        return False\n    if 'content' not in text:\n        return False\n\n    text = html.remove_tags_with_content(text, ('script', 'noscript'))\n    text = html.replace_entities(text)\n    text = html.remove_comments(text)\n    return _ajax_crawlable_re.search(text) is not None", "fpath_tuple": ["scrapy", "scrapy", "downloadermiddlewares", "ajaxcrawl.py"], "context_start_lineno": 69, "line_no": 80, "id": 72, "target_function_prompt": "def _has_ajaxcrawlable_meta(text):\n    \"\"\"\n    >>> _has_ajaxcrawlable_meta('<html><head><meta name=\"fragment\"  content=\"!\"/></head><body></body></html>')\n    True\n    >>> _has_ajaxcrawlable_meta(\"<html><head><meta name='fragment' content='!'></head></html>\")\n    True\n    >>> _has_ajaxcrawlable_meta('<html><head><!--<meta name=\"fragment\"  content=\"!\"/>--></head><body></body></html>')\n    False\n    >>> _has_ajaxcrawlable_meta('<html></html>')\n    False\n    \"\"\"\n", "function_signature": "def _has_ajaxcrawlable_meta(text):"}}
{"prompt": "def create_deprecated_class(\n    name,\n    new_class,\n    clsdict=None,\n    warn_category=ScrapyDeprecationWarning,\n    warn_once=True,\n    old_class_path=None,\n    new_class_path=None,\n    subclass_warn_message=\"{cls} inherits from deprecated class {old}, please inherit from {new}.\",\n    instance_warn_message=\"{cls} is deprecated, instantiate {new} instead.\"\n):\n    \"\"\"\n    Return a \"deprecated\" class that causes its subclasses to issue a warning.\n    Subclasses of ``new_class`` are considered subclasses of this class.\n    It also warns when the deprecated class is instantiated, but do not when\n    its subclasses are instantiated.\n\n    It can be used to rename a base class in a library. For example, if we\n    have\n\n    class OldName(SomeClass):\n    # ...\n\n    and we want to rename it to NewName, we can do the following::\n\n    class NewName(SomeClass):\n    # ...\n\n    OldName = create_deprecated_class('OldName', NewName)\n\n    Then, if user class inherits from OldName, warning is issued. Also, if\n    some code uses ``issubclass(sub, OldName)`` or ``isinstance(sub(), OldName)``\n    checks they'll still return True if sub is a subclass of NewName instead of\n    OldName.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/30", "ground_truth": "\n    class DeprecatedClass(new_class.__class__):\n\n        deprecated_class = None\n        warned_on_subclass = False\n\n        def __new__(metacls, name, bases, clsdict_):\n            cls = super().__new__(metacls, name, bases, clsdict_)\n            if metacls.deprecated_class is None:\n                metacls.deprecated_class = cls\n            return cls\n\n        def __init__(cls, name, bases, clsdict_):\n            meta = cls.__class__\n            old = meta.deprecated_class\n            if old in bases and not (warn_once and meta.warned_on_subclass):\n                meta.warned_on_subclass = True\n                msg = subclass_warn_message.format(cls=_clspath(cls),\n                                                   old=_clspath(old, old_class_path),\n                                                   new=_clspath(new_class, new_class_path))\n                if warn_once:\n                    msg += ' (warning only on first subclass, there may be others)'\n                warnings.warn(msg, warn_category, stacklevel=2)\n            super().__init__(name, bases, clsdict_)\n\n        # see https://www.python.org/dev/peps/pep-3119/#overloading-isinstance-and-issubclass\n        # and https://docs.python.org/reference/datamodel.html#customizing-instance-and-subclass-checks\n        # for implementation details\n        def __instancecheck__(cls, inst):\n            return any(cls.__subclasscheck__(c)\n                       for c in {type(inst), inst.__class__})\n\n        def __subclasscheck__(cls, sub):\n            if cls is not DeprecatedClass.deprecated_class:\n                # we should do the magic only if second `issubclass` argument\n                # is the deprecated class itself - subclasses of the\n                # deprecated class should not use custom `__subclasscheck__`\n                # method.\n                return super().__subclasscheck__(sub)\n\n            if not inspect.isclass(sub):\n                raise TypeError(\"issubclass() arg 1 must be a class\")\n\n            mro = getattr(sub, '__mro__', ())\n            return any(c in {cls, new_class} for c in mro)\n\n        def __call__(cls, *args, **kwargs):\n            old = DeprecatedClass.deprecated_class\n            if cls is old:\n                msg = instance_warn_message.format(cls=_clspath(cls, old_class_path),\n                                                   new=_clspath(new_class, new_class_path))\n                warnings.warn(msg, warn_category, stacklevel=2)\n            return super().__call__(*args, **kwargs)\n\n    deprecated_cls = DeprecatedClass(name, (new_class,), clsdict or {})\n\n    try:\n        frm = inspect.stack()[1]\n        parent_module = inspect.getmodule(frm[0])\n        if parent_module is not None:\n            deprecated_cls.__module__ = parent_module.__name__\n    except Exception as e:\n        # Sometimes inspect.stack() fails (e.g. when the first import of\n        # deprecated class is in jinja2 template). __module__ attribute is not\n        # important enough to raise an exception as users may be unable\n        # to fix inspect.stack() errors.\n        warnings.warn(f\"Error detecting parent module: {e!r}\")\n\n    return deprecated_cls", "fpath_tuple": ["scrapy", "scrapy", "utils", "deprecate.py"], "context_start_lineno": 16, "line_no": 51, "id": 73, "target_function_prompt": "def create_deprecated_class(\n    name,\n    new_class,\n    clsdict=None,\n    warn_category=ScrapyDeprecationWarning,\n    warn_once=True,\n    old_class_path=None,\n    new_class_path=None,\n    subclass_warn_message=\"{cls} inherits from deprecated class {old}, please inherit from {new}.\",\n    instance_warn_message=\"{cls} is deprecated, instantiate {new} instead.\"\n):\n    \"\"\"\n    Return a \"deprecated\" class that causes its subclasses to issue a warning.\n    Subclasses of ``new_class`` are considered subclasses of this class.\n    It also warns when the deprecated class is instantiated, but do not when\n    its subclasses are instantiated.\n\n    It can be used to rename a base class in a library. For example, if we\n    have\n\n    class OldName(SomeClass):\n    # ...\n\n    and we want to rename it to NewName, we can do the following::\n\n    class NewName(SomeClass):\n    # ...\n\n    OldName = create_deprecated_class('OldName', NewName)\n\n    Then, if user class inherits from OldName, warning is issued. Also, if\n    some code uses ``issubclass(sub, OldName)`` or ``isinstance(sub(), OldName)``\n    checks they'll still return True if sub is a subclass of NewName instead of\n    OldName.\n    \"\"\"\n", "function_signature": "def create_deprecated_class(\n    name,\n    new_class,\n    clsdict=None,\n    warn_category=ScrapyDeprecationWarning,\n    warn_once=True,\n    old_class_path=None,\n    new_class_path=None,\n    subclass_warn_message=\"{cls} inherits from deprecated class {old}, please inherit from {new}.\",\n    instance_warn_message=\"{cls} is deprecated, instantiate {new} instead.\"\n):"}}
{"prompt": "def update_classpath(path):\n    \"\"\"Update a deprecated path from an object with its new location\"\"\"\n", "metadata": {"task_id": "scrapy/31", "ground_truth": "    for prefix, replacement in DEPRECATION_RULES:\n        if isinstance(path, str) and path.startswith(prefix):\n            new_path = path.replace(prefix, replacement, 1)\n            warnings.warn(f\"`{path}` class is deprecated, use `{new_path}` instead\",\n                          ScrapyDeprecationWarning)\n            return new_path\n    return path", "fpath_tuple": ["scrapy", "scrapy", "utils", "deprecate.py"], "context_start_lineno": 133, "line_no": 135, "id": 74, "target_function_prompt": "def update_classpath(path):\n    \"\"\"Update a deprecated path from an object with its new location\"\"\"\n", "function_signature": "def update_classpath(path):"}}
{"prompt": "def _load_policy_class(policy, warning_only=False):\n    \"\"\"\n    Expect a string for the path to the policy class,\n    otherwise try to interpret the string as a standard value\n    from https://www.w3.org/TR/referrer-policy/#referrer-policies\n    \"\"\"\n", "metadata": {"task_id": "scrapy/32", "ground_truth": "    try:\n        return load_object(policy)\n    except ValueError:\n        try:\n            return _policy_classes[policy.lower()]\n        except KeyError:\n            msg = f\"Could not load referrer policy {policy!r}\"\n            if not warning_only:\n                raise RuntimeError(msg)\n            else:\n                warnings.warn(msg, RuntimeWarning)\n                return None", "fpath_tuple": ["scrapy", "scrapy", "spidermiddlewares", "referer.py"], "context_start_lineno": 270, "line_no": 276, "id": 75, "target_function_prompt": "def _load_policy_class(policy, warning_only=False):\n    \"\"\"\n    Expect a string for the path to the policy class,\n    otherwise try to interpret the string as a standard value\n    from https://www.w3.org/TR/referrer-policy/#referrer-policies\n    \"\"\"\n", "function_signature": "def _load_policy_class(policy, warning_only=False):"}}
{"prompt": "def get_base_url(response: \"scrapy.http.response.text.TextResponse\") -> str:\n    \"\"\"Return the base url of the given response, joined with the response url\"\"\"\n", "metadata": {"task_id": "scrapy/33", "ground_truth": "    if response not in _baseurl_cache:\n        text = response.text[0:4096]\n        _baseurl_cache[response] = html.get_base_url(text, response.url, response.encoding)\n    return _baseurl_cache[response]", "fpath_tuple": ["scrapy", "scrapy", "utils", "response.py"], "context_start_lineno": 21, "line_no": 23, "id": 76, "target_function_prompt": "def get_base_url(response: \"scrapy.http.response.text.TextResponse\") -> str:\n    \"\"\"Return the base url of the given response, joined with the response url\"\"\"\n", "function_signature": "def get_base_url(response: \"scrapy.http.response.text.TextResponse\") -> str:"}}
{"prompt": "def get_meta_refresh(\n    response: \"scrapy.http.response.text.TextResponse\",\n    ignore_tags: Optional[Iterable[str]] = ('script', 'noscript'),\n) -> Union[Tuple[None, None], Tuple[float, str]]:\n    \"\"\"Parse the http-equiv refrsh parameter from the given response\"\"\"\n", "metadata": {"task_id": "scrapy/34", "ground_truth": "    if response not in _metaref_cache:\n        text = response.text[0:4096]\n        _metaref_cache[response] = html.get_meta_refresh(\n            text, response.url, response.encoding, ignore_tags=ignore_tags)\n    return _metaref_cache[response]", "fpath_tuple": ["scrapy", "scrapy", "utils", "response.py"], "context_start_lineno": 32, "line_no": 37, "id": 77, "target_function_prompt": "def get_meta_refresh(\n    response: \"scrapy.http.response.text.TextResponse\",\n    ignore_tags: Optional[Iterable[str]] = ('script', 'noscript'),\n) -> Union[Tuple[None, None], Tuple[float, str]]:\n    \"\"\"Parse the http-equiv refrsh parameter from the given response\"\"\"\n", "function_signature": "def get_meta_refresh(\n    response: \"scrapy.http.response.text.TextResponse\",\n    ignore_tags: Optional[Iterable[str]] = ('script', 'noscript'),\n) -> Union[Tuple[None, None], Tuple[float, str]]:"}}
{"prompt": "def response_status_message(status: Union[bytes, float, int, str]) -> str:\n    \"\"\"Return status code plus status text descriptive message\n    \"\"\"\n", "metadata": {"task_id": "scrapy/35", "ground_truth": "    status_int = int(status)\n    message = http.RESPONSES.get(status_int, \"Unknown Status\")\n    return f'{status_int} {to_unicode(message)}'", "fpath_tuple": ["scrapy", "scrapy", "utils", "response.py"], "context_start_lineno": 44, "line_no": 47, "id": 78, "target_function_prompt": "def response_status_message(status: Union[bytes, float, int, str]) -> str:\n    \"\"\"Return status code plus status text descriptive message\n    \"\"\"\n", "function_signature": "def response_status_message(status: Union[bytes, float, int, str]) -> str:"}}
{"prompt": "def response_httprepr(response: Response) -> bytes:\n    \"\"\"Return raw HTTP representation (as bytes) of the given response. This\n    is provided only for reference, since it's not the exact stream of bytes\n    that was received (that's not exposed by Twisted).\n    \"\"\"\n", "metadata": {"task_id": "scrapy/36", "ground_truth": "    values = [\n        b\"HTTP/1.1 \",\n        to_bytes(str(response.status)),\n        b\" \",\n        to_bytes(http.RESPONSES.get(response.status, b'')),\n        b\"\\r\\n\",\n    ]\n    if response.headers:\n        values.extend([response.headers.to_string(), b\"\\r\\n\"])\n    values.extend([b\"\\r\\n\", response.body])\n    return b\"\".join(values)", "fpath_tuple": ["scrapy", "scrapy", "utils", "response.py"], "context_start_lineno": 52, "line_no": 57, "id": 79, "target_function_prompt": "def response_httprepr(response: Response) -> bytes:\n    \"\"\"Return raw HTTP representation (as bytes) of the given response. This\n    is provided only for reference, since it's not the exact stream of bytes\n    that was received (that's not exposed by Twisted).\n    \"\"\"\n", "function_signature": "def response_httprepr(response: Response) -> bytes:"}}
{"prompt": "def _get_clickable(clickdata, form):\n    \"\"\"\n    Returns the clickable element specified in clickdata,\n    if the latter is given. If not, it returns the first\n    clickable element found\n    \"\"\"\n", "metadata": {"task_id": "scrapy/37", "ground_truth": "    clickables = list(form.xpath(\n        'descendant::input[re:test(@type, \"^(submit|image)$\", \"i\")]'\n        '|descendant::button[not(@type) or re:test(@type, \"^submit$\", \"i\")]',\n        namespaces={\"re\": \"http://exslt.org/regular-expressions\"}\n    ))\n    if not clickables:\n        return\n\n    # If we don't have clickdata, we just use the first clickable element\n    if clickdata is None:\n        el = clickables[0]\n        return (el.get('name'), el.get('value') or '')\n\n    # If clickdata is given, we compare it to the clickable elements to find a\n    # match. We first look to see if the number is specified in clickdata,\n    # because that uniquely identifies the element\n    nr = clickdata.get('nr', None)\n    if nr is not None:\n        try:\n            el = list(form.inputs)[nr]\n        except IndexError:\n            pass\n        else:\n            return (el.get('name'), el.get('value') or '')\n\n    # We didn't find it, so now we build an XPath expression out of the other\n    # arguments, because they can be used as such\n    xpath = './/*' + ''.join(f'[@{k}=\"{v}\"]' for k, v in clickdata.items())\n    el = form.xpath(xpath)\n    if len(el) == 1:\n        return (el[0].get('name'), el[0].get('value') or '')\n    elif len(el) > 1:\n        raise ValueError(f\"Multiple elements found ({el!r}) matching the \"\n                         f\"criteria in clickdata: {clickdata!r}\")\n    else:\n        raise ValueError(f'No clickable element matching clickdata: {clickdata!r}')", "fpath_tuple": ["scrapy", "scrapy", "http", "request", "form.py"], "context_start_lineno": 173, "line_no": 179, "id": 80, "target_function_prompt": "def _get_clickable(clickdata, form):\n    \"\"\"\n    Returns the clickable element specified in clickdata,\n    if the latter is given. If not, it returns the first\n    clickable element found\n    \"\"\"\n", "function_signature": "def _get_clickable(clickdata, form):"}}
{"prompt": "def build_component_list(compdict, custom=None, convert=update_classpath):\n    \"\"\"Compose a component list from a { class: order } dictionary.\"\"\"\n", "metadata": {"task_id": "scrapy/38", "ground_truth": "\n    def _check_components(complist):\n        if len({convert(c) for c in complist}) != len(complist):\n            raise ValueError(f'Some paths in {complist!r} convert to the same object, '\n                             'please update your settings')\n\n    def _map_keys(compdict):\n        if isinstance(compdict, BaseSettings):\n            compbs = BaseSettings()\n            for k, v in compdict.items():\n                prio = compdict.getpriority(k)\n                if compbs.getpriority(convert(k)) == prio:\n                    raise ValueError(f'Some paths in {list(compdict.keys())!r} '\n                                     'convert to the same '\n                                     'object, please update your settings'\n                                     )\n                else:\n                    compbs.set(convert(k), v, priority=prio)\n            return compbs\n        else:\n            _check_components(compdict)\n            return {convert(k): v for k, v in compdict.items()}\n\n    def _validate_values(compdict):\n        \"\"\"Fail if a value in the components dict is not a real number or None.\"\"\"\n        for name, value in compdict.items():\n            if value is not None and not isinstance(value, numbers.Real):\n                raise ValueError(f'Invalid value {value} for component {name}, '\n                                 'please provide a real number or None instead')\n\n    # BEGIN Backward compatibility for old (base, custom) call signature\n    if isinstance(custom, (list, tuple)):\n        _check_components(custom)\n        return type(custom)(convert(c) for c in custom)\n\n    if custom is not None:\n        compdict.update(custom)\n    # END Backward compatibility\n\n    _validate_values(compdict)\n    compdict = without_none_values(_map_keys(compdict))\n    return [k for k, v in sorted(compdict.items(), key=itemgetter(1))]", "fpath_tuple": ["scrapy", "scrapy", "utils", "conf.py"], "context_start_lineno": 14, "line_no": 16, "id": 81, "target_function_prompt": "def build_component_list(compdict, custom=None, convert=update_classpath):\n    \"\"\"Compose a component list from a { class: order } dictionary.\"\"\"\n", "function_signature": "def build_component_list(compdict, custom=None, convert=update_classpath):"}}
{"prompt": "def arglist_to_dict(arglist):\n    \"\"\"Convert a list of arguments like ['arg1=val1', 'arg2=val2', ...] to a\n    dict\n    \"\"\"\n", "metadata": {"task_id": "scrapy/39", "ground_truth": "    return dict(x.split('=', 1) for x in arglist)", "fpath_tuple": ["scrapy", "scrapy", "utils", "conf.py"], "context_start_lineno": 60, "line_no": 64, "id": 82, "target_function_prompt": "def arglist_to_dict(arglist):\n    \"\"\"Convert a list of arguments like ['arg1=val1', 'arg2=val2', ...] to a\n    dict\n    \"\"\"\n", "function_signature": "def arglist_to_dict(arglist):"}}
{"prompt": "def defer_fail(_failure):\n    \"\"\"Same as twisted.internet.defer.fail but delay calling errback until\n    next reactor loop\n\n    It delays by 100ms so reactor has a chance to go through readers and writers\n    before attending pending delayed calls, so do not set delay to zero.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/40", "ground_truth": "    from twisted.internet import reactor\n    d = defer.Deferred()\n    reactor.callLater(0.1, d.errback, _failure)\n    return d", "fpath_tuple": ["scrapy", "scrapy", "utils", "defer.py"], "context_start_lineno": 14, "line_no": 21, "id": 85, "target_function_prompt": "def defer_fail(_failure):\n    \"\"\"Same as twisted.internet.defer.fail but delay calling errback until\n    next reactor loop\n\n    It delays by 100ms so reactor has a chance to go through readers and writers\n    before attending pending delayed calls, so do not set delay to zero.\n    \"\"\"\n", "function_signature": "def defer_fail(_failure):"}}
{"prompt": "def defer_succeed(result):\n    \"\"\"Same as twisted.internet.defer.succeed but delay calling callback until\n    next reactor loop\n\n    It delays by 100ms so reactor has a chance to go trough readers and writers\n    before attending pending delayed calls, so do not set delay to zero.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/41", "ground_truth": "    from twisted.internet import reactor\n    d = defer.Deferred()\n    reactor.callLater(0.1, d.callback, result)\n    return d", "fpath_tuple": ["scrapy", "scrapy", "utils", "defer.py"], "context_start_lineno": 27, "line_no": 34, "id": 86, "target_function_prompt": "def defer_succeed(result):\n    \"\"\"Same as twisted.internet.defer.succeed but delay calling callback until\n    next reactor loop\n\n    It delays by 100ms so reactor has a chance to go trough readers and writers\n    before attending pending delayed calls, so do not set delay to zero.\n    \"\"\"\n", "function_signature": "def defer_succeed(result):"}}
{"prompt": "def mustbe_deferred(f, *args, **kw):\n    \"\"\"Same as twisted.internet.defer.maybeDeferred, but delay calling\n    callback/errback to next reactor loop\n    \"\"\"\n", "metadata": {"task_id": "scrapy/42", "ground_truth": "    try:\n        result = f(*args, **kw)\n    # FIXME: Hack to avoid introspecting tracebacks. This to speed up\n    # processing of IgnoreRequest errors which are, by far, the most common\n    # exception in Scrapy - see #125\n    except IgnoreRequest as e:\n        return defer_fail(failure.Failure(e))\n    except Exception:\n        return defer_fail(failure.Failure())\n    else:\n        return defer_result(result)", "fpath_tuple": ["scrapy", "scrapy", "utils", "defer.py"], "context_start_lineno": 49, "line_no": 53, "id": 87, "target_function_prompt": "def mustbe_deferred(f, *args, **kw):\n    \"\"\"Same as twisted.internet.defer.maybeDeferred, but delay calling\n    callback/errback to next reactor loop\n    \"\"\"\n", "function_signature": "def mustbe_deferred(f, *args, **kw):"}}
{"prompt": "def process_chain(callbacks, input, *a, **kw):\n    \"\"\"Return a Deferred built by chaining the given callbacks\"\"\"\n", "metadata": {"task_id": "scrapy/43", "ground_truth": "    d = defer.Deferred()\n    for x in callbacks:\n        d.addCallback(x, *a, **kw)\n    d.callback(input)\n    return d", "fpath_tuple": ["scrapy", "scrapy", "utils", "defer.py"], "context_start_lineno": 77, "line_no": 79, "id": 88, "target_function_prompt": "def process_chain(callbacks, input, *a, **kw):\n    \"\"\"Return a Deferred built by chaining the given callbacks\"\"\"\n", "function_signature": "def process_chain(callbacks, input, *a, **kw):"}}
{"prompt": "def process_chain_both(callbacks, errbacks, input, *a, **kw):\n    \"\"\"Return a Deferred built by chaining the given callbacks and errbacks\"\"\"\n", "metadata": {"task_id": "scrapy/44", "ground_truth": "    d = defer.Deferred()\n    for cb, eb in zip(callbacks, errbacks):\n        d.addCallbacks(\n            callback=cb, errback=eb,\n            callbackArgs=a, callbackKeywords=kw,\n            errbackArgs=a, errbackKeywords=kw,\n        )\n    if isinstance(input, failure.Failure):\n        d.errback(input)\n    else:\n        d.callback(input)\n    return d", "fpath_tuple": ["scrapy", "scrapy", "utils", "defer.py"], "context_start_lineno": 86, "line_no": 88, "id": 89, "target_function_prompt": "def process_chain_both(callbacks, errbacks, input, *a, **kw):\n    \"\"\"Return a Deferred built by chaining the given callbacks and errbacks\"\"\"\n", "function_signature": "def process_chain_both(callbacks, errbacks, input, *a, **kw):"}}
{"prompt": "def process_parallel(callbacks, input, *a, **kw):\n    \"\"\"Return a Deferred with the output of all successful calls to the given\n    callbacks\n    \"\"\"\n", "metadata": {"task_id": "scrapy/45", "ground_truth": "    dfds = [defer.succeed(input).addCallback(x, *a, **kw) for x in callbacks]\n    d = defer.DeferredList(dfds, fireOnOneErrback=True, consumeErrors=True)\n    d.addCallbacks(lambda r: [x[1] for x in r], lambda f: f.value.subFailure)\n    return d", "fpath_tuple": ["scrapy", "scrapy", "utils", "defer.py"], "context_start_lineno": 102, "line_no": 106, "id": 90, "target_function_prompt": "def process_parallel(callbacks, input, *a, **kw):\n    \"\"\"Return a Deferred with the output of all successful calls to the given\n    callbacks\n    \"\"\"\n", "function_signature": "def process_parallel(callbacks, input, *a, **kw):"}}
{"prompt": "def deferred_from_coro(o):\n    \"\"\"Converts a coroutine into a Deferred, or returns the object as is if it isn't a coroutine\"\"\"\n", "metadata": {"task_id": "scrapy/46", "ground_truth": "    if isinstance(o, defer.Deferred):\n        return o\n    if asyncio.isfuture(o) or inspect.isawaitable(o):\n        if not is_asyncio_reactor_installed():\n            # wrapping the coroutine directly into a Deferred, this doesn't work correctly with coroutines\n            # that use asyncio, e.g. \"await asyncio.sleep(1)\"\n            return defer.ensureDeferred(o)\n        else:\n            # wrapping the coroutine into a Future and then into a Deferred, this requires AsyncioSelectorReactor\n            return defer.Deferred.fromFuture(asyncio.ensure_future(o))\n    return o", "fpath_tuple": ["scrapy", "scrapy", "utils", "defer.py"], "context_start_lineno": 126, "line_no": 128, "id": 91, "target_function_prompt": "def deferred_from_coro(o):\n    \"\"\"Converts a coroutine into a Deferred, or returns the object as is if it isn't a coroutine\"\"\"\n", "function_signature": "def deferred_from_coro(o):"}}
{"prompt": "def deferred_f_from_coro_f(coro_f):\n    \"\"\" Converts a coroutine function into a function that returns a Deferred.\n\n    The coroutine function will be called at the time when the wrapper is called. Wrapper args will be passed to it.\n    This is useful for callback chains, as callback functions are called with the previous callback result.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/47", "ground_truth": "    @wraps(coro_f)\n    def f(*coro_args, **coro_kwargs):\n        return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))\n    return f", "fpath_tuple": ["scrapy", "scrapy", "utils", "defer.py"], "context_start_lineno": 141, "line_no": 147, "id": 92, "target_function_prompt": "def deferred_f_from_coro_f(coro_f):\n    \"\"\" Converts a coroutine function into a function that returns a Deferred.\n\n    The coroutine function will be called at the time when the wrapper is called. Wrapper args will be passed to it.\n    This is useful for callback chains, as callback functions are called with the previous callback result.\n    \"\"\"\n", "function_signature": "def deferred_f_from_coro_f(coro_f):"}}
{"prompt": "def maybeDeferred_coro(f, *args, **kw):\n    \"\"\" Copy of defer.maybeDeferred that also converts coroutines to Deferreds. \"\"\"\n", "metadata": {"task_id": "scrapy/48", "ground_truth": "    try:\n        result = f(*args, **kw)\n    except:  # noqa: E722\n        return defer.fail(failure.Failure(captureVars=defer.Deferred.debug))\n\n    if isinstance(result, defer.Deferred):\n        return result\n    elif asyncio.isfuture(result) or inspect.isawaitable(result):\n        return deferred_from_coro(result)\n    elif isinstance(result, failure.Failure):\n        return defer.fail(result)\n    else:\n        return defer.succeed(result)", "fpath_tuple": ["scrapy", "scrapy", "utils", "defer.py"], "context_start_lineno": 153, "line_no": 155, "id": 93, "target_function_prompt": "def maybeDeferred_coro(f, *args, **kw):\n    \"\"\" Copy of defer.maybeDeferred that also converts coroutines to Deferreds. \"\"\"\n", "function_signature": "def maybeDeferred_coro(f, *args, **kw):"}}
{"prompt": "def get_crawler(spidercls=None, settings_dict=None):\n    \"\"\"Return an unconfigured Crawler object. If settings_dict is given, it\n    will be used to populate the crawler settings with a project level\n    priority.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/49", "ground_truth": "    from scrapy.crawler import CrawlerRunner\n    from scrapy.spiders import Spider\n\n    runner = CrawlerRunner(settings_dict)\n    return runner.create_crawler(spidercls or Spider)", "fpath_tuple": ["scrapy", "scrapy", "utils", "test.py"], "context_start_lineno": 56, "line_no": 61, "id": 94, "target_function_prompt": "def get_crawler(spidercls=None, settings_dict=None):\n    \"\"\"Return an unconfigured Crawler object. If settings_dict is given, it\n    will be used to populate the crawler settings with a project level\n    priority.\n    \"\"\"\n", "function_signature": "def get_crawler(spidercls=None, settings_dict=None):"}}
{"prompt": "def get_testenv():\n    \"\"\"Return a OS environment dict suitable to fork processes that need to import\n    this installation of Scrapy, instead of a system installed one.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/50", "ground_truth": "    env = os.environ.copy()\n    env['PYTHONPATH'] = get_pythonpath()\n    return env", "fpath_tuple": ["scrapy", "scrapy", "utils", "test.py"], "context_start_lineno": 75, "line_no": 79, "id": 96, "target_function_prompt": "def get_testenv():\n    \"\"\"Return a OS environment dict suitable to fork processes that need to import\n    this installation of Scrapy, instead of a system installed one.\n    \"\"\"\n", "function_signature": "def get_testenv():"}}
{"prompt": "def mock_google_cloud_storage():\n    \"\"\"Creates autospec mocks for google-cloud-storage Client, Bucket and Blob\n    classes and set their proper return values.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/51", "ground_truth": "    from google.cloud.storage import Client, Bucket, Blob\n    client_mock = mock.create_autospec(Client)\n\n    bucket_mock = mock.create_autospec(Bucket)\n    client_mock.get_bucket.return_value = bucket_mock\n\n    blob_mock = mock.create_autospec(Blob)\n    bucket_mock.blob.return_value = blob_mock\n\n    return (client_mock, bucket_mock, blob_mock)", "fpath_tuple": ["scrapy", "scrapy", "utils", "test.py"], "context_start_lineno": 98, "line_no": 102, "id": 97, "target_function_prompt": "def mock_google_cloud_storage():\n    \"\"\"Creates autospec mocks for google-cloud-storage Client, Bucket and Blob\n    classes and set their proper return values.\n    \"\"\"\n", "function_signature": "def mock_google_cloud_storage():"}}
{"prompt": "def is_botocore():\n    \"\"\" Returns True if botocore is available, otherwise raises NotConfigured. Never returns False.\n\n    Previously, when boto was supported in addition to botocore, this returned False if boto was available\n    but botocore wasn't.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/52", "ground_truth": "    message = (\n        'is_botocore() is deprecated and always returns True or raises an Exception, '\n        'so it cannot be used for checking if boto is available instead of botocore. '\n        'You can use scrapy.utils.boto.is_botocore_available() to check if botocore '\n        'is available.'\n    )\n    warnings.warn(message, ScrapyDeprecationWarning, stacklevel=2)\n    try:\n        import botocore  # noqa: F401\n        return True\n    except ImportError:\n        raise NotConfigured('missing botocore library')", "fpath_tuple": ["scrapy", "scrapy", "utils", "boto.py"], "context_start_lineno": 6, "line_no": 12, "id": 98, "target_function_prompt": "def is_botocore():\n    \"\"\" Returns True if botocore is available, otherwise raises NotConfigured. Never returns False.\n\n    Previously, when boto was supported in addition to botocore, this returned False if boto was available\n    but botocore wasn't.\n    \"\"\"\n", "function_signature": "def is_botocore():"}}
{"prompt": "def format_live_refs(ignore=NoneType):\n    \"\"\"Return a tabular representation of tracked objects\"\"\"\n", "metadata": {"task_id": "scrapy/53", "ground_truth": "    s = \"Live References\\n\\n\"\n    now = time()\n    for cls, wdict in sorted(live_refs.items(),\n                             key=lambda x: x[0].__name__):\n        if not wdict:\n            continue\n        if issubclass(cls, ignore):\n            continue\n        oldest = min(wdict.values())\n        s += f\"{cls.__name__:<30} {len(wdict):6}   oldest: {int(now - oldest)}s ago\\n\"\n    return s", "fpath_tuple": ["scrapy", "scrapy", "utils", "trackref.py"], "context_start_lineno": 33, "line_no": 35, "id": 99, "target_function_prompt": "def format_live_refs(ignore=NoneType):\n    \"\"\"Return a tabular representation of tracked objects\"\"\"\n", "function_signature": "def format_live_refs(ignore=NoneType):"}}
{"prompt": "def get_oldest(class_name):\n    \"\"\"Get the oldest object for a specific class name\"\"\"\n", "metadata": {"task_id": "scrapy/54", "ground_truth": "    for cls, wdict in live_refs.items():\n        if cls.__name__ == class_name:\n            if not wdict:\n                break\n            return min(wdict.items(), key=itemgetter(1))[0]", "fpath_tuple": ["scrapy", "scrapy", "utils", "trackref.py"], "context_start_lineno": 53, "line_no": 55, "id": 100, "target_function_prompt": "def get_oldest(class_name):\n    \"\"\"Get the oldest object for a specific class name\"\"\"\n", "function_signature": "def get_oldest(class_name):"}}
{"prompt": "def iter_all(class_name):\n    \"\"\"Iterate over all objects of the same class by its class name\"\"\"\n", "metadata": {"task_id": "scrapy/55", "ground_truth": "    for cls, wdict in live_refs.items():\n        if cls.__name__ == class_name:\n            return wdict.keys()", "fpath_tuple": ["scrapy", "scrapy", "utils", "trackref.py"], "context_start_lineno": 62, "line_no": 64, "id": 101, "target_function_prompt": "def iter_all(class_name):\n    \"\"\"Iterate over all objects of the same class by its class name\"\"\"\n", "function_signature": "def iter_all(class_name):"}}
{"prompt": "def failure_to_exc_info(failure):\n    \"\"\"Extract exc_info from Failure instances\"\"\"\n", "metadata": {"task_id": "scrapy/56", "ground_truth": "    if isinstance(failure, Failure):\n        return (failure.type, failure.value, failure.getTracebackObject())", "fpath_tuple": ["scrapy", "scrapy", "utils", "log.py"], "context_start_lineno": 17, "line_no": 19, "id": 102, "target_function_prompt": "def failure_to_exc_info(failure):\n    \"\"\"Extract exc_info from Failure instances\"\"\"\n", "function_signature": "def failure_to_exc_info(failure):"}}
{"prompt": "def logformatter_adapter(logkws):\n    \"\"\"\n    Helper that takes the dictionary output from the methods in LogFormatter\n    and adapts it into a tuple of positional arguments for logger.log calls,\n    handling backward compatibility as well.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/57", "ground_truth": "    if not {'level', 'msg', 'args'} <= set(logkws):\n        warnings.warn('Missing keys in LogFormatter method',\n                      ScrapyDeprecationWarning)\n\n    if 'format' in logkws:\n        warnings.warn('`format` key in LogFormatter methods has been '\n                      'deprecated, use `msg` instead',\n                      ScrapyDeprecationWarning)\n\n    level = logkws.get('level', logging.INFO)\n    message = logkws.get('format', logkws.get('msg'))\n    # NOTE: This also handles 'args' being an empty dict, that case doesn't\n    # play well in logger.log calls\n    args = logkws if not logkws.get('args') else logkws['args']\n\n    return (level, message, args)", "fpath_tuple": ["scrapy", "scrapy", "utils", "log.py"], "context_start_lineno": 196, "line_no": 202, "id": 104, "target_function_prompt": "def logformatter_adapter(logkws):\n    \"\"\"\n    Helper that takes the dictionary output from the methods in LogFormatter\n    and adapts it into a tuple of positional arguments for logger.log calls,\n    handling backward compatibility as well.\n    \"\"\"\n", "function_signature": "def logformatter_adapter(logkws):"}}
{"prompt": "def url_is_from_any_domain(url, domains):\n    \"\"\"Return True if the url belongs to any of the given domains\"\"\"\n", "metadata": {"task_id": "scrapy/58", "ground_truth": "    host = parse_url(url).netloc.lower()\n    if not host:\n        return False\n    domains = [d.lower() for d in domains]\n    return any((host == d) or (host.endswith(f'.{d}')) for d in domains)", "fpath_tuple": ["scrapy", "scrapy", "utils", "url.py"], "context_start_lineno": 18, "line_no": 20, "id": 105, "target_function_prompt": "def url_is_from_any_domain(url, domains):\n    \"\"\"Return True if the url belongs to any of the given domains\"\"\"\n", "function_signature": "def url_is_from_any_domain(url, domains):"}}
{"prompt": "def parse_url(url, encoding=None):\n    \"\"\"Return urlparsed url from the given argument (which could be an already\n    parsed url)\n    \"\"\"\n", "metadata": {"task_id": "scrapy/59", "ground_truth": "    if isinstance(url, ParseResult):\n        return url\n    return urlparse(to_unicode(url, encoding))", "fpath_tuple": ["scrapy", "scrapy", "utils", "url.py"], "context_start_lineno": 36, "line_no": 40, "id": 106, "target_function_prompt": "def parse_url(url, encoding=None):\n    \"\"\"Return urlparsed url from the given argument (which could be an already\n    parsed url)\n    \"\"\"\n", "function_signature": "def parse_url(url, encoding=None):"}}
{"prompt": "def escape_ajax(url):\n    \"\"\"\n    Return the crawleable url according to:\n    https://developers.google.com/webmasters/ajax-crawling/docs/getting-started\n\n    >>> escape_ajax(\"www.example.com/ajax.html#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?k1=v1&k2=v2#!key=value\")\n    'www.example.com/ajax.html?k1=v1&k2=v2&_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html#!\")\n    'www.example.com/ajax.html?_escaped_fragment_='\n\n    URLs that are not \"AJAX crawlable\" (according to Google) returned as-is:\n\n    >>> escape_ajax(\"www.example.com/ajax.html#key=value\")\n    'www.example.com/ajax.html#key=value'\n    >>> escape_ajax(\"www.example.com/ajax.html#\")\n    'www.example.com/ajax.html#'\n    >>> escape_ajax(\"www.example.com/ajax.html\")\n    'www.example.com/ajax.html'\n    \"\"\"\n", "metadata": {"task_id": "scrapy/60", "ground_truth": "    defrag, frag = urldefrag(url)\n    if not frag.startswith('!'):\n        return url\n    return add_or_replace_parameter(defrag, '_escaped_fragment_', frag[1:])", "fpath_tuple": ["scrapy", "scrapy", "utils", "url.py"], "context_start_lineno": 45, "line_no": 68, "id": 107, "target_function_prompt": "def escape_ajax(url):\n    \"\"\"\n    Return the crawleable url according to:\n    https://developers.google.com/webmasters/ajax-crawling/docs/getting-started\n\n    >>> escape_ajax(\"www.example.com/ajax.html#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?k1=v1&k2=v2#!key=value\")\n    'www.example.com/ajax.html?k1=v1&k2=v2&_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html?#!key=value\")\n    'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'\n    >>> escape_ajax(\"www.example.com/ajax.html#!\")\n    'www.example.com/ajax.html?_escaped_fragment_='\n\n    URLs that are not \"AJAX crawlable\" (according to Google) returned as-is:\n\n    >>> escape_ajax(\"www.example.com/ajax.html#key=value\")\n    'www.example.com/ajax.html#key=value'\n    >>> escape_ajax(\"www.example.com/ajax.html#\")\n    'www.example.com/ajax.html#'\n    >>> escape_ajax(\"www.example.com/ajax.html\")\n    'www.example.com/ajax.html'\n    \"\"\"\n", "function_signature": "def escape_ajax(url):"}}
{"prompt": "def add_http_if_no_scheme(url):\n    \"\"\"Add http as the default scheme if it is missing from the url.\"\"\"\n", "metadata": {"task_id": "scrapy/61", "ground_truth": "    match = re.match(r\"^\\w+://\", url, flags=re.I)\n    if not match:\n        parts = urlparse(url)\n        scheme = \"http:\" if parts.netloc else \"http://\"\n        url = scheme + url\n\n    return url", "fpath_tuple": ["scrapy", "scrapy", "utils", "url.py"], "context_start_lineno": 74, "line_no": 76, "id": 108, "target_function_prompt": "def add_http_if_no_scheme(url):\n    \"\"\"Add http as the default scheme if it is missing from the url.\"\"\"\n", "function_signature": "def add_http_if_no_scheme(url):"}}
{"prompt": "def guess_scheme(url):\n    \"\"\"Add an URL scheme if missing: file:// for filepath-like input or\n    http:// otherwise.\"\"\"\n", "metadata": {"task_id": "scrapy/62", "ground_truth": "    if _is_filesystem_path(url):\n        return any_to_uri(url)\n    return add_http_if_no_scheme(url)", "fpath_tuple": ["scrapy", "scrapy", "utils", "url.py"], "context_start_lineno": 127, "line_no": 130, "id": 109, "target_function_prompt": "def guess_scheme(url):\n    \"\"\"Add an URL scheme if missing: file:// for filepath-like input or\n    http:// otherwise.\"\"\"\n", "function_signature": "def guess_scheme(url):"}}
{"prompt": "def strip_url(url, strip_credentials=True, strip_default_port=True, origin_only=False, strip_fragment=True):\n    \"\"\"Strip URL string from some of its components:\n\n    - ``strip_credentials`` removes \"user:password@\"\n    - ``strip_default_port`` removes \":80\" (resp. \":443\", \":21\")\n    from http:// (resp. https://, ftp://) URLs\n    - ``origin_only`` replaces path component with \"/\", also dropping\n    query and fragment components ; it also strips credentials\n    - ``strip_fragment`` drops any #fragment component\n    \"\"\"\n", "metadata": {"task_id": "scrapy/63", "ground_truth": "\n    parsed_url = urlparse(url)\n    netloc = parsed_url.netloc\n    if (strip_credentials or origin_only) and (parsed_url.username or parsed_url.password):\n        netloc = netloc.split('@')[-1]\n    if strip_default_port and parsed_url.port:\n        if (parsed_url.scheme, parsed_url.port) in (('http', 80),\n                                                    ('https', 443),\n                                                    ('ftp', 21)):\n            netloc = netloc.replace(f':{parsed_url.port}', '')\n    return urlunparse((\n        parsed_url.scheme,\n        netloc,\n        '/' if origin_only else parsed_url.path,\n        '' if origin_only else parsed_url.params,\n        '' if origin_only else parsed_url.query,\n        '' if strip_fragment else parsed_url.fragment\n    ))", "fpath_tuple": ["scrapy", "scrapy", "utils", "url.py"], "context_start_lineno": 135, "line_no": 146, "id": 110, "target_function_prompt": "def strip_url(url, strip_credentials=True, strip_default_port=True, origin_only=False, strip_fragment=True):\n    \"\"\"Strip URL string from some of its components:\n\n    - ``strip_credentials`` removes \"user:password@\"\n    - ``strip_default_port`` removes \":80\" (resp. \":443\", \":21\")\n    from http:// (resp. https://, ftp://) URLs\n    - ``origin_only`` replaces path component with \"/\", also dropping\n    query and fragment components ; it also strips credentials\n    - ``strip_fragment`` drops any #fragment component\n    \"\"\"\n", "function_signature": "def strip_url(url, strip_credentials=True, strip_default_port=True, origin_only=False, strip_fragment=True):"}}
{"prompt": "def arg_to_iter(arg):\n    \"\"\"Convert an argument to an iterable. The argument can be a None, single\n    value, or an iterable.\n\n    Exception: if arg is a dict, [arg] will be returned\n    \"\"\"\n", "metadata": {"task_id": "scrapy/64", "ground_truth": "    if arg is None:\n        return []\n    elif not isinstance(arg, _ITERABLE_SINGLE_VALUES) and hasattr(arg, '__iter__'):\n        return arg\n    else:\n        return [arg]", "fpath_tuple": ["scrapy", "scrapy", "utils", "misc.py"], "context_start_lineno": 23, "line_no": 29, "id": 111, "target_function_prompt": "def arg_to_iter(arg):\n    \"\"\"Convert an argument to an iterable. The argument can be a None, single\n    value, or an iterable.\n\n    Exception: if arg is a dict, [arg] will be returned\n    \"\"\"\n", "function_signature": "def arg_to_iter(arg):"}}
{"prompt": "def load_object(path):\n    \"\"\"Load an object given its absolute object path, and return it.\n\n    The object can be the import path of a class, function, variable or an\n    instance, e.g. 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'.\n\n    If ``path`` is not a string, but is a callable object, such as a class or\n    a function, then return it as is.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/65", "ground_truth": "\n    if not isinstance(path, str):\n        if callable(path):\n            return path\n        else:\n            raise TypeError(\"Unexpected argument type, expected string \"\n                            \"or object, got: %s\" % type(path))\n\n    try:\n        dot = path.rindex('.')\n    except ValueError:\n        raise ValueError(f\"Error loading object '{path}': not a full path\")\n\n    module, name = path[:dot], path[dot + 1:]\n    mod = import_module(module)\n\n    try:\n        obj = getattr(mod, name)\n    except AttributeError:\n        raise NameError(f\"Module '{module}' doesn't define any object named '{name}'\")\n\n    return obj", "fpath_tuple": ["scrapy", "scrapy", "utils", "misc.py"], "context_start_lineno": 37, "line_no": 46, "id": 112, "target_function_prompt": "def load_object(path):\n    \"\"\"Load an object given its absolute object path, and return it.\n\n    The object can be the import path of a class, function, variable or an\n    instance, e.g. 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'.\n\n    If ``path`` is not a string, but is a callable object, such as a class or\n    a function, then return it as is.\n    \"\"\"\n", "function_signature": "def load_object(path):"}}
{"prompt": "def extract_regex(regex, text, encoding='utf-8'):\n    \"\"\"Extract a list of unicode strings from the given text/encoding using the following policies:\n\n    * if the regex contains a named group called \"extract\" that will be returned\n    * if the regex contains multiple numbered groups, all those will be returned (flattened)\n    * if the regex doesn't contain any group the entire regex matching is returned\n    \"\"\"\n", "metadata": {"task_id": "scrapy/66", "ground_truth": "    warnings.warn(\n        \"scrapy.utils.misc.extract_regex has moved to parsel.utils.extract_regex.\",\n        ScrapyDeprecationWarning,\n        stacklevel=2\n    )\n\n    if isinstance(regex, str):\n        regex = re.compile(regex, re.UNICODE)\n\n    try:\n        strings = [regex.search(text).group('extract')]   # named group\n    except Exception:\n        strings = regex.findall(text)    # full regex or numbered groups\n    strings = flatten(strings)\n\n    if isinstance(text, str):\n        return [replace_entities(s, keep=['lt', 'amp']) for s in strings]\n    else:\n        return [replace_entities(to_unicode(s, encoding), keep=['lt', 'amp'])\n                for s in strings]", "fpath_tuple": ["scrapy", "scrapy", "utils", "misc.py"], "context_start_lineno": 92, "line_no": 99, "id": 114, "target_function_prompt": "def extract_regex(regex, text, encoding='utf-8'):\n    \"\"\"Extract a list of unicode strings from the given text/encoding using the following policies:\n\n    * if the regex contains a named group called \"extract\" that will be returned\n    * if the regex contains multiple numbered groups, all those will be returned (flattened)\n    * if the regex doesn't contain any group the entire regex matching is returned\n    \"\"\"\n", "function_signature": "def extract_regex(regex, text, encoding='utf-8'):"}}
{"prompt": "def rel_has_nofollow(rel):\n    \"\"\"Return True if link rel attribute has nofollow type\"\"\"\n", "metadata": {"task_id": "scrapy/67", "ground_truth": "    return rel is not None and 'nofollow' in rel.split()", "fpath_tuple": ["scrapy", "scrapy", "utils", "misc.py"], "context_start_lineno": 138, "line_no": 140, "id": 115, "target_function_prompt": "def rel_has_nofollow(rel):\n    \"\"\"Return True if link rel attribute has nofollow type\"\"\"\n", "function_signature": "def rel_has_nofollow(rel):"}}
{"prompt": "def _parse(url):\n    \"\"\" Return tuple of (scheme, netloc, host, port, path),\n    all in bytes except for port which is int.\n    Assume url is from Request.url, which was passed via safe_url_string\n    and is ascii-only.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/68", "ground_truth": "    url = url.strip()\n    parsed = urlparse(url)\n    return _parsed_url_args(parsed)", "fpath_tuple": ["scrapy", "scrapy", "core", "downloader", "webclient.py"], "context_start_lineno": 27, "line_no": 33, "id": 116, "target_function_prompt": "def _parse(url):\n    \"\"\" Return tuple of (scheme, netloc, host, port, path),\n    all in bytes except for port which is int.\n    Assume url is from Request.url, which was passed via safe_url_string\n    and is ascii-only.\n    \"\"\"\n", "function_signature": "def _parse(url):"}}
{"prompt": "def request_to_dict(request, spider=None):\n    \"\"\"Convert Request object to a dict.\n\n    If a spider is given, it will try to find out the name of the spider method\n    used in the callback and store that as the callback.\n    \"\"\"\n", "metadata": {"task_id": "scrapy/69", "ground_truth": "    cb = request.callback\n    if callable(cb):\n        cb = _find_method(spider, cb)\n    eb = request.errback\n    if callable(eb):\n        eb = _find_method(spider, eb)\n    d = {\n        'url': to_unicode(request.url),  # urls should be safe (safe_string_url)\n        'callback': cb,\n        'errback': eb,\n        'method': request.method,\n        'headers': dict(request.headers),\n        'body': request.body,\n        'cookies': request.cookies,\n        'meta': request.meta,\n        '_encoding': request._encoding,\n        'priority': request.priority,\n        'dont_filter': request.dont_filter,\n        'flags': request.flags,\n        'cb_kwargs': request.cb_kwargs,\n    }\n    if type(request) is not Request:\n        d['_class'] = request.__module__ + '.' + request.__class__.__name__\n    return d", "fpath_tuple": ["scrapy", "scrapy", "utils", "reqser.py"], "context_start_lineno": 10, "line_no": 16, "id": 118, "target_function_prompt": "def request_to_dict(request, spider=None):\n    \"\"\"Convert Request object to a dict.\n\n    If a spider is given, it will try to find out the name of the spider method\n    used in the callback and store that as the callback.\n    \"\"\"\n", "function_signature": "def request_to_dict(request, spider=None):"}}
{"prompt": "def curl_to_request_kwargs(curl_command, ignore_unknown_options=True):\n    \"\"\"Convert a cURL command syntax to Request kwargs.\n\n    :param str curl_command: string containing the curl command\n    :param bool ignore_unknown_options: If true, only a warning is emitted when\n    cURL options are unknown. Otherwise\n    raises an error. (default: True)\n    :return: dictionary of Request kwargs\n    \"\"\"\n", "metadata": {"task_id": "scrapy/70", "ground_truth": "\n    curl_args = split(curl_command)\n\n    if curl_args[0] != 'curl':\n        raise ValueError('A curl command must start with \"curl\"')\n\n    parsed_args, argv = curl_parser.parse_known_args(curl_args[1:])\n\n    if argv:\n        msg = f'Unrecognized options: {\", \".join(argv)}'\n        if ignore_unknown_options:\n            warnings.warn(msg)\n        else:\n            raise ValueError(msg)\n\n    url = parsed_args.url\n\n    # curl automatically prepends 'http' if the scheme is missing, but Request\n    # needs the scheme to work\n    parsed_url = urlparse(url)\n    if not parsed_url.scheme:\n        url = 'http://' + url\n\n    method = parsed_args.method or 'GET'\n\n    result = {'method': method.upper(), 'url': url}\n\n    headers, cookies = _parse_headers_and_cookies(parsed_args)\n\n    if headers:\n        result['headers'] = headers\n    if cookies:\n        result['cookies'] = cookies\n    if parsed_args.data:\n        result['body'] = parsed_args.data\n        if not parsed_args.method:\n            # if the \"data\" is specified but the \"method\" is not specified,\n            # the default method is 'POST'\n            result['method'] = 'POST'\n\n    return result", "fpath_tuple": ["scrapy", "scrapy", "utils", "curl.py"], "context_start_lineno": 56, "line_no": 65, "id": 119, "target_function_prompt": "def curl_to_request_kwargs(curl_command, ignore_unknown_options=True):\n    \"\"\"Convert a cURL command syntax to Request kwargs.\n\n    :param str curl_command: string containing the curl command\n    :param bool ignore_unknown_options: If true, only a warning is emitted when\n    cURL options are unknown. Otherwise\n    raises an error. (default: True)\n    :return: dictionary of Request kwargs\n    \"\"\"\n", "function_signature": "def curl_to_request_kwargs(curl_command, ignore_unknown_options=True):"}}
{"prompt": "def deprecated(use_instead=None):\n    \"\"\"This is a decorator which can be used to mark functions\n    as deprecated. It will result in a warning being emitted\n    when the function is used.\"\"\"\n", "metadata": {"task_id": "scrapy/71", "ground_truth": "\n    def deco(func):\n        @wraps(func)\n        def wrapped(*args, **kwargs):\n            message = f\"Call to deprecated function {func.__name__}.\"\n            if use_instead:\n                message += f\" Use {use_instead} instead.\"\n            warnings.warn(message, category=ScrapyDeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        return wrapped\n\n    if callable(use_instead):\n        deco = deco(use_instead)\n        use_instead = None\n    return deco", "fpath_tuple": ["scrapy", "scrapy", "utils", "decorators.py"], "context_start_lineno": 8, "line_no": 12, "id": 120, "target_function_prompt": "def deprecated(use_instead=None):\n    \"\"\"This is a decorator which can be used to mark functions\n    as deprecated. It will result in a warning being emitted\n    when the function is used.\"\"\"\n", "function_signature": "def deprecated(use_instead=None):"}}
{"prompt": "def defers(func):\n    \"\"\"Decorator to make sure a function always returns a deferred\"\"\"\n", "metadata": {"task_id": "scrapy/72", "ground_truth": "    @wraps(func)\n    def wrapped(*a, **kw):\n        return defer.maybeDeferred(func, *a, **kw)\n    return wrapped", "fpath_tuple": ["scrapy", "scrapy", "utils", "decorators.py"], "context_start_lineno": 29, "line_no": 31, "id": 121, "target_function_prompt": "def defers(func):\n    \"\"\"Decorator to make sure a function always returns a deferred\"\"\"\n", "function_signature": "def defers(func):"}}
{"prompt": "def potential_domain_matches(domain):\n    \"\"\"Potential domain matches for a cookie\n\n    >>> potential_domain_matches('www.example.com')\n    ['www.example.com', 'example.com', '.www.example.com', '.example.com']\n\n    \"\"\"\n", "metadata": {"task_id": "scrapy/73", "ground_truth": "    matches = [domain]\n    try:\n        start = domain.index('.') + 1\n        end = domain.rindex('.')\n        while start < end:\n            matches.append(domain[start:])\n            start = domain.index('.', start) + 1\n    except ValueError:\n        pass\n    return matches + ['.' + d for d in matches]", "fpath_tuple": ["scrapy", "scrapy", "http", "cookies.py"], "context_start_lineno": 89, "line_no": 96, "id": 122, "target_function_prompt": "def potential_domain_matches(domain):\n    \"\"\"Potential domain matches for a cookie\n\n    >>> potential_domain_matches('www.example.com')\n    ['www.example.com', 'example.com', '.www.example.com', '.example.com']\n\n    \"\"\"\n", "function_signature": "def potential_domain_matches(domain):"}}
{"prompt": "def _expand_path(path):\n    \"\"\"Expand both environment variables and user home in the given path.\"\"\"\n", "metadata": {"task_id": "cookiecutter/0", "ground_truth": "    path = os.path.expandvars(path)\n    path = os.path.expanduser(path)\n    return path", "fpath_tuple": ["cookiecutter", "cookiecutter", "config.py"], "context_start_lineno": 28, "line_no": 30, "id": 123, "target_function_prompt": "def _expand_path(path):\n    \"\"\"Expand both environment variables and user home in the given path.\"\"\"\n", "function_signature": "def _expand_path(path):"}}
{"prompt": "def merge_configs(default, overwrite):\n    \"\"\"Recursively update a dict with the key/value pair of another.\n\n    Dict values that are dictionaries themselves will be updated, whilst\n    preserving existing keys.\n    \"\"\"\n", "metadata": {"task_id": "cookiecutter/1", "ground_truth": "    new_config = copy.deepcopy(default)\n\n    for k, v in overwrite.items():\n        # Make sure to preserve existing items in\n        # nested dicts, for example `abbreviations`\n        if isinstance(v, dict):\n            new_config[k] = merge_configs(default.get(k, {}), v)\n        else:\n            new_config[k] = v\n\n    return new_config", "fpath_tuple": ["cookiecutter", "cookiecutter", "config.py"], "context_start_lineno": 35, "line_no": 41, "id": 124, "target_function_prompt": "def merge_configs(default, overwrite):\n    \"\"\"Recursively update a dict with the key/value pair of another.\n\n    Dict values that are dictionaries themselves will be updated, whilst\n    preserving existing keys.\n    \"\"\"\n", "function_signature": "def merge_configs(default, overwrite):"}}
{"prompt": "def get_user_config(config_file=None, default_config=False):\n    \"\"\"Return the user config as a dict.\n\n    If ``default_config`` is True, ignore ``config_file`` and return default\n    values for the config parameters.\n\n    If a path to a ``config_file`` is given, that is different from the default\n    location, load the user config from that.\n\n    Otherwise look up the config file path in the ``COOKIECUTTER_CONFIG``\n    environment variable. If set, load the config from this path. This will\n    raise an error if the specified path is not valid.\n\n    If the environment variable is not set, try the default config file path\n    before falling back to the default config values.\n    \"\"\"\n", "metadata": {"task_id": "cookiecutter/2", "ground_truth": "    # Do NOT load a config. Return defaults instead.\n    if default_config:\n        logger.debug(\"Force ignoring user config with default_config switch.\")\n        return copy.copy(DEFAULT_CONFIG)\n\n    # Load the given config file\n    if config_file and config_file is not USER_CONFIG_PATH:\n        logger.debug(\"Loading custom config from %s.\", config_file)\n        return get_config(config_file)\n\n    try:\n        # Does the user set up a config environment variable?\n        env_config_file = os.environ['COOKIECUTTER_CONFIG']\n    except KeyError:\n        # Load an optional user config if it exists\n        # otherwise return the defaults\n        if os.path.exists(USER_CONFIG_PATH):\n            logger.debug(\"Loading config from %s.\", USER_CONFIG_PATH)\n            return get_config(USER_CONFIG_PATH)\n        else:\n            logger.debug(\"User config not found. Loading default config.\")\n            return copy.copy(DEFAULT_CONFIG)\n    else:\n        # There is a config environment variable. Try to load it.\n        # Do not check for existence, so invalid file paths raise an error.\n        logger.debug(\"User config not found or not specified. Loading default config.\")\n        return get_config(env_config_file)", "fpath_tuple": ["cookiecutter", "cookiecutter", "config.py"], "context_start_lineno": 81, "line_no": 97, "id": 125, "target_function_prompt": "def get_user_config(config_file=None, default_config=False):\n    \"\"\"Return the user config as a dict.\n\n    If ``default_config`` is True, ignore ``config_file`` and return default\n    values for the config parameters.\n\n    If a path to a ``config_file`` is given, that is different from the default\n    location, load the user config from that.\n\n    Otherwise look up the config file path in the ``COOKIECUTTER_CONFIG``\n    environment variable. If set, load the config from this path. This will\n    raise an error if the specified path is not valid.\n\n    If the environment variable is not set, try the default config file path\n    before falling back to the default config values.\n    \"\"\"\n", "function_signature": "def get_user_config(config_file=None, default_config=False):"}}
{"prompt": "def process_json(user_value):\n    \"\"\"Load user-supplied value as a JSON dict.\n\n    :param str user_value: User-supplied value to load as a JSON dict\n    \"\"\"\n", "metadata": {"task_id": "cookiecutter/3", "ground_truth": "    try:\n        user_dict = json.loads(user_value, object_pairs_hook=OrderedDict)\n    except Exception:\n        # Leave it up to click to ask the user again\n        raise click.UsageError('Unable to decode to JSON.')\n\n    if not isinstance(user_dict, dict):\n        # Leave it up to click to ask the user again\n        raise click.UsageError('Requires JSON dict.')\n\n    return user_dict", "fpath_tuple": ["cookiecutter", "cookiecutter", "prompt.py"], "context_start_lineno": 80, "line_no": 85, "id": 127, "target_function_prompt": "def process_json(user_value):\n    \"\"\"Load user-supplied value as a JSON dict.\n\n    :param str user_value: User-supplied value to load as a JSON dict\n    \"\"\"\n", "function_signature": "def process_json(user_value):"}}
{"prompt": "def is_repo_url(value):\n    \"\"\"Return True if value is a repository URL.\"\"\"\n", "metadata": {"task_id": "cookiecutter/4", "ground_truth": "    return bool(REPO_REGEX.match(value))", "fpath_tuple": ["cookiecutter", "cookiecutter", "repository.py"], "context_start_lineno": 20, "line_no": 22, "id": 129, "target_function_prompt": "def is_repo_url(value):\n    \"\"\"Return True if value is a repository URL.\"\"\"\n", "function_signature": "def is_repo_url(value):"}}
{"prompt": "def is_zip_file(value):\n    \"\"\"Return True if value is a zip file.\"\"\"\n", "metadata": {"task_id": "cookiecutter/5", "ground_truth": "    return value.lower().endswith('.zip')", "fpath_tuple": ["cookiecutter", "cookiecutter", "repository.py"], "context_start_lineno": 25, "line_no": 27, "id": 130, "target_function_prompt": "def is_zip_file(value):\n    \"\"\"Return True if value is a zip file.\"\"\"\n", "function_signature": "def is_zip_file(value):"}}
{"prompt": "def expand_abbreviations(template, abbreviations):\n    \"\"\"Expand abbreviations in a template name.\n\n    :param template: The project template name.\n    :param abbreviations: Abbreviation definitions.\n    \"\"\"\n", "metadata": {"task_id": "cookiecutter/6", "ground_truth": "    if template in abbreviations:\n        return abbreviations[template]\n\n    # Split on colon. If there is no colon, rest will be empty\n    # and prefix will be the whole template\n    prefix, sep, rest = template.partition(':')\n    if prefix in abbreviations:\n        return abbreviations[prefix].format(rest)\n\n    return template", "fpath_tuple": ["cookiecutter", "cookiecutter", "repository.py"], "context_start_lineno": 30, "line_no": 36, "id": 131, "target_function_prompt": "def expand_abbreviations(template, abbreviations):\n    \"\"\"Expand abbreviations in a template name.\n\n    :param template: The project template name.\n    :param abbreviations: Abbreviation definitions.\n    \"\"\"\n", "function_signature": "def expand_abbreviations(template, abbreviations):"}}
{"prompt": "def _transform(path: str, code: str, target: CompilationTarget) -> Tuple[str, List[str]]:\n    \"\"\"Applies all transformation for passed target.\"\"\"\n", "metadata": {"task_id": "py-backwards/0", "ground_truth": "    debug((lambda: 'Compiling \"{}\"'.format(path)))\n    dependencies = []\n    tree = ast.parse(code, path)\n    debug((lambda: 'Initial ast:\\n{}'.format(dump(tree))))\n    for transformer in transformers:\n        if (transformer.target < target):\n            debug((lambda: 'Skip transformer \"{}\"'.format(transformer.__name__)))\n            continue\n        debug((lambda: 'Use transformer \"{}\"'.format(transformer.__name__)))\n        working_tree = deepcopy(tree)\n        try:\n            result = transformer.transform(working_tree)\n        except:\n            raise TransformationError(\n                path, transformer, dump(tree), format_exc())\n        if (not result.tree_changed):\n            debug((lambda: 'Tree not changed'))\n            continue\n        tree = working_tree\n        debug((lambda: 'Tree changed:\\n{}'.format(dump(tree))))\n        dependencies.extend(result.dependencies)\n        try:\n            code = unparse(tree)\n            debug((lambda: 'Code changed:\\n{}'.format(code)))\n        except:\n            raise TransformationError(\n                path, transformer, dump(tree), format_exc())\n    return (fix_code(code), dependencies)", "fpath_tuple": ["py-backwards", "py_backwards", "compiler.py"], "context_start_lineno": 35, "line_no": 37, "id": 134, "target_function_prompt": "def _transform(path: str, code: str, target: CompilationTarget) -> Tuple[str, List[str]]:\n    \"\"\"Applies all transformation for passed target.\"\"\"\n", "function_signature": "def _transform(path: str, code: str, target: CompilationTarget) -> Tuple[str, List[str]]:"}}
{"prompt": "def find_variables(tree: ast.AST) -> Iterable[str]:\n    \"\"\"Finds variables and remove `let` calls.\"\"\"\n", "metadata": {"task_id": "py-backwards/1", "ground_truth": "    for node in find(tree, ast.Call):\n        if isinstance(node.func, ast.Name) and node.func.id == 'let':\n            parent, index = get_non_exp_parent_and_index(tree, node)\n            parent.body.pop(index)  # type: ignore\n            yield node.args[0].id", "fpath_tuple": ["py-backwards", "py_backwards", "utils", "snippet.py"], "context_start_lineno": 9, "line_no": 11, "id": 135, "target_function_prompt": "def find_variables(tree: ast.AST) -> Iterable[str]:\n    \"\"\"Finds variables and remove `let` calls.\"\"\"\n", "function_signature": "def find_variables(tree: ast.AST) -> Iterable[str]:"}}
{"prompt": "def _format_line(line: str, n: int, padding: int) -> str:\n    \"\"\"Format single line of code.\"\"\"\n", "metadata": {"task_id": "py-backwards/2", "ground_truth": "    return '  {dim}{n}{reset}: {line}'.format(dim=Style.DIM, n=str((n + 1)).zfill(padding), line=line, reset=Style.RESET_ALL)", "fpath_tuple": ["py-backwards", "py_backwards", "messages.py"], "context_start_lineno": 8, "line_no": 10, "id": 136, "target_function_prompt": "def _format_line(line: str, n: int, padding: int) -> str:\n    \"\"\"Format single line of code.\"\"\"\n", "function_signature": "def _format_line(line: str, n: int, padding: int) -> str:"}}
{"prompt": "def _get_lines_with_highlighted_error(e: CompilationError) -> Iterable[str]:\n    \"\"\"Format code with highlighted syntax error.\"\"\"\n", "metadata": {"task_id": "py-backwards/3", "ground_truth": "    error_line = (e.lineno - 1)\n    lines = e.code.split('\\n')\n    padding = len(str(len(lines)))\n    from_line = (error_line - const.SYNTAX_ERROR_OFFSET)\n    if (from_line < 0):\n        from_line = 0\n    if (from_line < error_line):\n        for n in range(from_line, error_line):\n            (yield _format_line(lines[n], n, padding))\n    (yield '  {dim}{n}{reset}: {bright}{line}{reset}'.format(dim=Style.DIM, n=str((error_line + 1)).zfill(padding), line=lines[error_line], reset=Style.RESET_ALL, bright=Style.BRIGHT))\n    (yield '  {padding}{bright}^{reset}'.format(padding=(' ' * ((padding + e.offset) + 1)), bright=Style.BRIGHT, reset=Style.RESET_ALL))\n    to_line = (error_line + const.SYNTAX_ERROR_OFFSET)\n    if (to_line > len(lines)):\n        to_line = len(lines)\n    for n in range((error_line + 1), to_line):\n        (yield _format_line(lines[n], n, padding))", "fpath_tuple": ["py-backwards", "py_backwards", "messages.py"], "context_start_lineno": 13, "line_no": 15, "id": 137, "target_function_prompt": "def _get_lines_with_highlighted_error(e: CompilationError) -> Iterable[str]:\n    \"\"\"Format code with highlighted syntax error.\"\"\"\n", "function_signature": "def _get_lines_with_highlighted_error(e: CompilationError) -> Iterable[str]:"}}
{"prompt": "def find(tree: ast.AST, type_: Type[T]) -> Iterable[T]:\n    \"\"\"Finds all nodes with type T.\"\"\"\n", "metadata": {"task_id": "py-backwards/4", "ground_truth": "    for node in ast.walk(tree):\n        if isinstance(node, type_):\n            yield node", "fpath_tuple": ["py-backwards", "py_backwards", "utils", "tree.py"], "context_start_lineno": 40, "line_no": 42, "id": 139, "target_function_prompt": "def find(tree: ast.AST, type_: Type[T]) -> Iterable[T]:\n    \"\"\"Finds all nodes with type T.\"\"\"\n", "function_signature": "def find(tree: ast.AST, type_: Type[T]) -> Iterable[T]:"}}
{"prompt": "def bump_version(\n        version: str,\n        position: int = 2,\n        pre_release: Optional[str] = None\n) -> str:\n    \"\"\"Increase the version number from a version number string.\n\n    *New in version 0.3*\n\n    Args:\n    version (str): The version number to be bumped.\n    position (int, optional): The position (starting with zero) of the\n    version number component to be increased.  Defaults to: ``2``\n    pre_release (str, Optional): A value of ``a`` or ``alpha`` will\n    create or increase an alpha version number.  A value of ``b`` or\n    ``beta`` will create or increase a beta version number.\n\n    Raises:\n    ValueError: if the given ``version`` is an invalid version number.\n    ValueError: if the given ``position`` does not exist.\n    ValueError: if the given ``prerelease`` is not in:\n    ``a, alpha, b, beta``\n    ValueError: if trying to 'major' part, of a version number, to\n    a pre-release version.\n\n    :rtype:\n    :obj:`str`\n\n    * The increased version number.\n\n    Examples:\n    >>> from flutils.packages import bump_version\n    >>> bump_version('1.2.2')\n    '1.2.3'\n    >>> bump_version('1.2.3', position=1)\n    '1.3'\n    >>> bump_version('1.3.4', position=0)\n    '2.0'\n    >>> bump_version('1.2.3', prerelease='a')\n    '1.2.4a0'\n    >>> bump_version('1.2.4a0', pre_release='a')\n    '1.2.4a1'\n    >>> bump_version('1.2.4a1', pre_release='b')\n    '1.2.4b0'\n    >>> bump_version('1.2.4a1')\n    '1.2.4'\n    >>> bump_version('1.2.4b0')\n    '1.2.4'\n    >>> bump_version('2.1.3', position=1, pre_release='a')\n    '2.2a0'\n    >>> bump_version('1.2b0', position=2)\n    '1.2.1'\n\n    \"\"\"\n", "metadata": {"task_id": "flutils/0", "ground_truth": "    ver_info = _build_version_info(version)\n    position = _build_version_bump_position(position)\n    bump_type = _build_version_bump_type(position, pre_release)\n    # noinspection PyUnusedLocal\n    hold: List[Union[int, str]] = []\n    if bump_type == _BUMP_VERSION_MAJOR:\n        hold = [ver_info.major.num + 1, 0]\n    elif bump_type in _BUMP_VERSION_MINORS:\n        if bump_type == _BUMP_VERSION_MINOR:\n            if ver_info.minor.pre_txt:\n                hold = [ver_info.major.num, ver_info.minor.num]\n            else:\n                hold = [ver_info.major.num, ver_info.minor.num + 1]\n        else:\n            if bump_type == _BUMP_VERSION_MINOR_ALPHA:\n                if ver_info.minor.pre_txt == 'a':\n                    part = '%sa%s' % (\n                        ver_info.minor.num,\n                        ver_info.minor.pre_num + 1\n                    )\n                else:\n                    part = '{}a0'.format(ver_info.minor.num + 1)\n            else:\n                if ver_info.minor.pre_txt == 'a':\n                    part = '{}b0'.format(ver_info.minor.num)\n                elif ver_info.minor.pre_txt == 'b':\n                    part = '%sb%s' % (\n                        ver_info.minor.num,\n                        ver_info.minor.pre_num + 1\n                    )\n                else:\n                    part = '{}b0'.format(ver_info.minor.num + 1)\n            hold = [ver_info.major.num, part]\n    else:\n        if bump_type == _BUMP_VERSION_PATCH:\n            if ver_info.patch.pre_txt:\n                hold = [\n                    ver_info.major.num,\n                    ver_info.minor.num,\n                    ver_info.patch.num\n                ]\n            else:\n                hold = [\n                    ver_info.major.num,\n                    ver_info.minor.num,\n                    ver_info.patch.num + 1\n                ]\n        else:\n            if bump_type == _BUMP_VERSION_PATCH_ALPHA:\n                if ver_info.patch.pre_txt == 'a':\n                    part = '%sa%s' % (\n                        ver_info.patch.num,\n                        ver_info.patch.pre_num + 1\n                    )\n                else:\n                    part = '{}a0'.format(ver_info.patch.num + 1)\n            else:\n                if ver_info.patch.pre_txt == 'a':\n                    part = '{}b0'.format(ver_info.patch.num)\n\n                elif ver_info.patch.pre_txt == 'b':\n                    part = '%sb%s' % (\n                        ver_info.patch.num,\n                        ver_info.patch.pre_num + 1\n                    )\n                else:\n                    part = '{}b0'.format(ver_info.patch.num + 1)\n            hold = [ver_info.major.num, ver_info.minor.num, part]\n    out = '.'.join(map(str, hold))\n    return out", "fpath_tuple": ["flutils", "flutils", "packages.py"], "context_start_lineno": 168, "line_no": 222, "id": 140, "target_function_prompt": "def bump_version(\n        version: str,\n        position: int = 2,\n        pre_release: Optional[str] = None\n) -> str:\n    \"\"\"Increase the version number from a version number string.\n\n    *New in version 0.3*\n\n    Args:\n    version (str): The version number to be bumped.\n    position (int, optional): The position (starting with zero) of the\n    version number component to be increased.  Defaults to: ``2``\n    pre_release (str, Optional): A value of ``a`` or ``alpha`` will\n    create or increase an alpha version number.  A value of ``b`` or\n    ``beta`` will create or increase a beta version number.\n\n    Raises:\n    ValueError: if the given ``version`` is an invalid version number.\n    ValueError: if the given ``position`` does not exist.\n    ValueError: if the given ``prerelease`` is not in:\n    ``a, alpha, b, beta``\n    ValueError: if trying to 'major' part, of a version number, to\n    a pre-release version.\n\n    :rtype:\n    :obj:`str`\n\n    * The increased version number.\n\n    Examples:\n    >>> from flutils.packages import bump_version\n    >>> bump_version('1.2.2')\n    '1.2.3'\n    >>> bump_version('1.2.3', position=1)\n    '1.3'\n    >>> bump_version('1.3.4', position=0)\n    '2.0'\n    >>> bump_version('1.2.3', prerelease='a')\n    '1.2.4a0'\n    >>> bump_version('1.2.4a0', pre_release='a')\n    '1.2.4a1'\n    >>> bump_version('1.2.4a1', pre_release='b')\n    '1.2.4b0'\n    >>> bump_version('1.2.4a1')\n    '1.2.4'\n    >>> bump_version('1.2.4b0')\n    '1.2.4'\n    >>> bump_version('2.1.3', position=1, pre_release='a')\n    '2.2a0'\n    >>> bump_version('1.2b0', position=2)\n    '1.2.1'\n\n    \"\"\"\n", "function_signature": "def bump_version(\n        version: str,\n        position: int = 2,\n        pre_release: Optional[str] = None\n) -> str:"}}
{"prompt": "def to_namedtuple(obj: _AllowedTypes) -> Union[NamedTuple, Tuple, List]:\n    \"\"\"Convert particular objects into a namedtuple.\n\n    Args:\n    obj: The object to be converted (or have it's contents converted) to\n    a :obj:`NamedTuple <collections.namedtuple>`.\n\n    If the given type is of :obj:`list` or :obj:`tuple`, each item will be\n    recursively converted to a :obj:`NamedTuple <collections.namedtuple>`\n    provided the items can be converted. Items that cannot be converted\n    will still exist in the returned object.\n\n    If the given type is of :obj:`list` the return value will be a new\n    :obj:`list`.  This means the items are not changed in the given\n    ``obj``.\n\n    If the given type is of :obj:`Mapping <collections.abc.Mapping>`\n    (:obj:`dict`), keys that can be proper identifiers will become attributes\n    on the returned :obj:`NamedTuple <collections.namedtuple>`.  Additionally,\n    the attributes of the returned :obj:`NamedTuple <collections.namedtuple>`\n    are sorted alphabetically.\n\n    If the given type is of :obj:`OrderedDict <collections.OrderedDict>`,\n    the attributes of the returned :obj:`NamedTuple <collections.namedtuple>`\n    keep the same order as the given\n    :obj:`OrderedDict <collections.OrderedDict>` keys.\n\n    If the given type is of :obj:`SimpleNamespace <types.SimpleNamespace>`,\n    The attributes are sorted alphabetically in the returned\n    :obj:`NamedTuple <collections.NamedTuple>`.\n\n    Any identifier (key or attribute name) that starts with an underscore\n    cannot be used as a :obj:`NamedTuple <collections.namedtuple>` attribute.\n\n    All values are recursively converted.  This means a dictionary that\n    contains another dictionary, as one of it's values, will be converted\n    to a :obj:`NamedTuple <collections.namedtuple>` with the attribute's\n    value also converted to a :obj:`NamedTuple <collections.namedtuple>`.\n\n    :rtype:\n    :obj:`list`\n\n    A list with any of it's values converted to a\n    :obj:`NamedTuple <collections.namedtuple>`.\n\n    :obj:`tuple`\n\n    A tuple with any of it's values converted to a\n    :obj:`NamedTuple <collections.namedtuple>`.\n\n    :obj:`NamedTuple <collections.namedtuple>`.\n\n    Example:\n    >>> from flutils.namedtupleutils import to_namedtuple\n    >>> dic = {'a': 1, 'b': 2}\n    >>> to_namedtuple(dic)\n    NamedTuple(a=1, b=2)\n    \"\"\"\n", "metadata": {"task_id": "flutils/1", "ground_truth": "    return _to_namedtuple(obj)", "fpath_tuple": ["flutils", "flutils", "namedtupleutils.py"], "context_start_lineno": 31, "line_no": 89, "id": 141, "target_function_prompt": "def to_namedtuple(obj: _AllowedTypes) -> Union[NamedTuple, Tuple, List]:\n    \"\"\"Convert particular objects into a namedtuple.\n\n    Args:\n    obj: The object to be converted (or have it's contents converted) to\n    a :obj:`NamedTuple <collections.namedtuple>`.\n\n    If the given type is of :obj:`list` or :obj:`tuple`, each item will be\n    recursively converted to a :obj:`NamedTuple <collections.namedtuple>`\n    provided the items can be converted. Items that cannot be converted\n    will still exist in the returned object.\n\n    If the given type is of :obj:`list` the return value will be a new\n    :obj:`list`.  This means the items are not changed in the given\n    ``obj``.\n\n    If the given type is of :obj:`Mapping <collections.abc.Mapping>`\n    (:obj:`dict`), keys that can be proper identifiers will become attributes\n    on the returned :obj:`NamedTuple <collections.namedtuple>`.  Additionally,\n    the attributes of the returned :obj:`NamedTuple <collections.namedtuple>`\n    are sorted alphabetically.\n\n    If the given type is of :obj:`OrderedDict <collections.OrderedDict>`,\n    the attributes of the returned :obj:`NamedTuple <collections.namedtuple>`\n    keep the same order as the given\n    :obj:`OrderedDict <collections.OrderedDict>` keys.\n\n    If the given type is of :obj:`SimpleNamespace <types.SimpleNamespace>`,\n    The attributes are sorted alphabetically in the returned\n    :obj:`NamedTuple <collections.NamedTuple>`.\n\n    Any identifier (key or attribute name) that starts with an underscore\n    cannot be used as a :obj:`NamedTuple <collections.namedtuple>` attribute.\n\n    All values are recursively converted.  This means a dictionary that\n    contains another dictionary, as one of it's values, will be converted\n    to a :obj:`NamedTuple <collections.namedtuple>` with the attribute's\n    value also converted to a :obj:`NamedTuple <collections.namedtuple>`.\n\n    :rtype:\n    :obj:`list`\n\n    A list with any of it's values converted to a\n    :obj:`NamedTuple <collections.namedtuple>`.\n\n    :obj:`tuple`\n\n    A tuple with any of it's values converted to a\n    :obj:`NamedTuple <collections.namedtuple>`.\n\n    :obj:`NamedTuple <collections.namedtuple>`.\n\n    Example:\n    >>> from flutils.namedtupleutils import to_namedtuple\n    >>> dic = {'a': 1, 'b': 2}\n    >>> to_namedtuple(dic)\n    NamedTuple(a=1, b=2)\n    \"\"\"\n", "function_signature": "def to_namedtuple(obj: _AllowedTypes) -> Union[NamedTuple, Tuple, List]:"}}
{"prompt": "def _expand_attr_map_item(\n        foreign_name: str\n) -> _AttrMapping:\n    \"\"\"Used with map() to expand foreign-names into a named tuple.\n\n    See the :term:`foreign-name` documentation for the format of this string.\n\n    The tuple contains three parts:\n\n    - attr_name: If applicable, the attribute identifier that will be\n    set on the cherry-picking module.\n    - mod_name: The fullname of the module to be cherry-picked.\n    - mod_attr_name: If applicable the attribute identifier on the\n    cherry-picked module that will be bound to the ``attr_name``.\n    An empty str value indicates that the entire module will be used.\n    \"\"\"\n", "metadata": {"task_id": "flutils/2", "ground_truth": "    if not isinstance(foreign_name, str):\n        raise AttributeError(\n            '__attr_map__ must be a tuple containing strings.'\n        )\n    mod, _, attr_name = foreign_name.partition(',')\n    mod_name, _, mod_attr_name = mod.strip().partition(':')\n    attr_name = _validate_attr_identifier(attr_name, foreign_name)\n    mod_name = mod_name.strip()\n    mod_attr_name = _validate_attr_identifier(mod_attr_name, foreign_name)\n    if attr_name == '':\n        if mod_attr_name != '':\n            attr_name = mod_attr_name\n        else:\n            attr_name = mod_name.split('.')[-1]\n    return _AttrMapping(\n        attr_name,\n        mod_name,\n        mod_attr_name,\n        foreign_name\n    )", "fpath_tuple": ["flutils", "flutils", "moduleutils.py"], "context_start_lineno": 99, "line_no": 115, "id": 142, "target_function_prompt": "def _expand_attr_map_item(\n        foreign_name: str\n) -> _AttrMapping:\n    \"\"\"Used with map() to expand foreign-names into a named tuple.\n\n    See the :term:`foreign-name` documentation for the format of this string.\n\n    The tuple contains three parts:\n\n    - attr_name: If applicable, the attribute identifier that will be\n    set on the cherry-picking module.\n    - mod_name: The fullname of the module to be cherry-picked.\n    - mod_attr_name: If applicable the attribute identifier on the\n    cherry-picked module that will be bound to the ``attr_name``.\n    An empty str value indicates that the entire module will be used.\n    \"\"\"\n", "function_signature": "def _expand_attr_map_item(\n        foreign_name: str\n) -> _AttrMapping:"}}
{"prompt": "def _expand_attr_map(\n        attr_map: Tuple[str, ...]\n) -> Generator[_AttrMapping, None, None]:\n    \"\"\"Generator that expands the given attr_map and yields an _AttrMapping\n    named tuple.\n\n    An attr_map is a tuple with each row containing a :term:`foreign-name`\n    which is a specially formatted string.\n    \"\"\"\n", "metadata": {"task_id": "flutils/3", "ground_truth": "    hold: Set = set()\n    for attr_mapping in map(_expand_attr_map_item, attr_map):\n        # Do not yield duplicates\n        if attr_mapping not in hold:\n            hold.add(attr_mapping)\n            yield attr_mapping", "fpath_tuple": ["flutils", "flutils", "moduleutils.py"], "context_start_lineno": 137, "line_no": 146, "id": 143, "target_function_prompt": "def _expand_attr_map(\n        attr_map: Tuple[str, ...]\n) -> Generator[_AttrMapping, None, None]:\n    \"\"\"Generator that expands the given attr_map and yields an _AttrMapping\n    named tuple.\n\n    An attr_map is a tuple with each row containing a :term:`foreign-name`\n    which is a specially formatted string.\n    \"\"\"\n", "function_signature": "def _expand_attr_map(\n        attr_map: Tuple[str, ...]\n) -> Generator[_AttrMapping, None, None]:"}}
{"prompt": "def encode(\n        text: _STR,\n        errors: _STR = 'strict'\n) -> Tuple[bytes, int]:\n    \"\"\"Convert the given ``text`` of base64 characters into the base64\n    decoded bytes.\n\n    Args:\n    text (str): The string input.  The given string input can span\n    across many lines and be indented any number of spaces.\n    errors (str): Not used.  This argument exists to meet the\n    interface requirements.  Any value given to this argument\n    is ignored.\n\n    Returns:\n    bytes: The given ``text`` converted into base64 bytes.\n    int: The length of the returned bytes.\n    \"\"\"\n", "metadata": {"task_id": "flutils/4", "ground_truth": "    # Convert the given 'text', that are of type UserString into a str.\n    text_input = str(text)\n\n    # Cleanup whitespace.\n    text_str = text_input.strip()\n    text_str = '\\n'.join(\n        filter(\n            lambda x: len(x) > 0,\n            map(lambda x: x.strip(), text_str.strip().splitlines())\n        )\n    )\n\n    # Convert the cleaned text into utf8 bytes\n    text_bytes = text_str.encode('utf-8')\n    try:\n        out = base64.decodebytes(text_bytes)\n    except Error as e:\n        raise UnicodeEncodeError(\n            'b64',\n            text_input,\n            0,\n            len(text),\n            (\n                f'{text_str!r} is not a proper bas64 character string: '\n                f'{e}'\n            )\n        )\n    return out, len(text)", "fpath_tuple": ["flutils", "flutils", "codecs", "b64.py"], "context_start_lineno": 16, "line_no": 34, "id": 144, "target_function_prompt": "def encode(\n        text: _STR,\n        errors: _STR = 'strict'\n) -> Tuple[bytes, int]:\n    \"\"\"Convert the given ``text`` of base64 characters into the base64\n    decoded bytes.\n\n    Args:\n    text (str): The string input.  The given string input can span\n    across many lines and be indented any number of spaces.\n    errors (str): Not used.  This argument exists to meet the\n    interface requirements.  Any value given to this argument\n    is ignored.\n\n    Returns:\n    bytes: The given ``text`` converted into base64 bytes.\n    int: The length of the returned bytes.\n    \"\"\"\n", "function_signature": "def encode(\n        text: _STR,\n        errors: _STR = 'strict'\n) -> Tuple[bytes, int]:"}}
{"prompt": "def decode(\n        data: _ByteString,\n        errors: _STR = 'strict'\n) -> Tuple[str, int]:\n    \"\"\"Convert the given ``data`` into base64 Characters.\n\n    Args:\n    data (bytes or bytearray or memoryview): Bytes to be converted\n    to a string of base64 characters.\n    errors (str or :obj:`~UserString`): Not used.  This argument exists\n    to meet the interface requirements.  Any value given to this\n    argument is ignored.\n\n    Returns:\n    str: of base64 Characters\n    int: the number of the given ``data`` bytes consumed.\n    \"\"\"\n", "metadata": {"task_id": "flutils/5", "ground_truth": "    # Convert memoryview and bytearray objects to bytes.\n    data_bytes = bytes(data)\n\n    # Encode the 'data_bytes' into base64 bytes.\n    encoded_bytes = base64.b64encode(data_bytes)\n\n    # Decode the 'base64_bytes' as utf8 into a string.\n    encoded_str = encoded_bytes.decode('utf-8')\n\n    return encoded_str, len(data)", "fpath_tuple": ["flutils", "flutils", "codecs", "b64.py"], "context_start_lineno": 65, "line_no": 82, "id": 145, "target_function_prompt": "def decode(\n        data: _ByteString,\n        errors: _STR = 'strict'\n) -> Tuple[str, int]:\n    \"\"\"Convert the given ``data`` into base64 Characters.\n\n    Args:\n    data (bytes or bytearray or memoryview): Bytes to be converted\n    to a string of base64 characters.\n    errors (str or :obj:`~UserString`): Not used.  This argument exists\n    to meet the interface requirements.  Any value given to this\n    argument is ignored.\n\n    Returns:\n    str: of base64 Characters\n    int: the number of the given ``data`` bytes consumed.\n    \"\"\"\n", "function_signature": "def decode(\n        data: _ByteString,\n        errors: _STR = 'strict'\n) -> Tuple[str, int]:"}}
{"prompt": "def len_without_ansi(seq: Sequence) -> int:\n    \"\"\"Return the character length of the given\n    :obj:`Sequence <typing.Sequence>` without counting any ANSI codes.\n\n    *New in version 0.6*\n\n    Args:\n    seq (:obj:`Sequence <typing.Sequence>`): A string or a list/tuple\n    of strings.\n\n    :rtype:\n    :obj:`int`\n\n    Example:\n    >>> from flutils.txtutils import len_without_ansi\n    >>> text = '\\\\x1b[38;5;209mfoobar\\\\x1b[0m'\n    >>> len_without_ansi(text)\n    6\n    \"\"\"\n", "metadata": {"task_id": "flutils/6", "ground_truth": "    if hasattr(seq, 'capitalize'):\n        _text: str = cast(str, seq)\n        seq = [c for c in _ANSI_RE.split(_text) if c]\n    seq = [c for c in chain(*map(_ANSI_RE.split, seq)) if c]\n    seq = cast(Sequence[str], seq)\n    out = 0\n    for text in seq:\n        if hasattr(text, 'capitalize'):\n            if text.startswith('\\x1b[') and text.endswith('m'):\n                continue\n            else:\n                out += len(text)\n    return out", "fpath_tuple": ["flutils", "flutils", "txtutils.py"], "context_start_lineno": 24, "line_no": 43, "id": 146, "target_function_prompt": "def len_without_ansi(seq: Sequence) -> int:\n    \"\"\"Return the character length of the given\n    :obj:`Sequence <typing.Sequence>` without counting any ANSI codes.\n\n    *New in version 0.6*\n\n    Args:\n    seq (:obj:`Sequence <typing.Sequence>`): A string or a list/tuple\n    of strings.\n\n    :rtype:\n    :obj:`int`\n\n    Example:\n    >>> from flutils.txtutils import len_without_ansi\n    >>> text = '\\\\x1b[38;5;209mfoobar\\\\x1b[0m'\n    >>> len_without_ansi(text)\n    6\n    \"\"\"\n", "function_signature": "def len_without_ansi(seq: Sequence) -> int:"}}
{"prompt": "def as_escaped_unicode_literal(\n        text: str\n) -> str:\n    \"\"\"Convert the given ``text``  into a string of escaped Unicode\n    hexadecimal.\n\n    Args:\n    text (:obj:`str`): The string to convert.\n\n    :rtype:\n    :obj:`str`\n\n    A string with each character of the given ``text`` converted\n    into an escaped Python literal.\n\n    Example:\n    >>> from flutils.strutils import as_escaped_unicode_literal\n    >>> t = '1.\u2605 \ud83d\uded1'\n    >>> as_literal(t)\n    '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\u2605\\\\\\\\x20\\\\\\\\U0001f6d1'\n    \"\"\"\n", "metadata": {"task_id": "flutils/7", "ground_truth": "    out = ''\n    for c in text:\n        c_hex = hex(ord(c))[2:]\n        c_len = len(c_hex)\n        if c_len in (1, 2):\n            out += '\\\\x{:0>2}'.format(c_hex)\n        elif c_len in (3, 4):\n            out += '\\\\u{:0>4}'.format(c_hex)\n        else:\n            out += '\\\\U{:0>8}'.format(c_hex)\n    return out", "fpath_tuple": ["flutils", "flutils", "strutils.py"], "context_start_lineno": 12, "line_no": 33, "id": 147, "target_function_prompt": "def as_escaped_unicode_literal(\n        text: str\n) -> str:\n    \"\"\"Convert the given ``text``  into a string of escaped Unicode\n    hexadecimal.\n\n    Args:\n    text (:obj:`str`): The string to convert.\n\n    :rtype:\n    :obj:`str`\n\n    A string with each character of the given ``text`` converted\n    into an escaped Python literal.\n\n    Example:\n    >>> from flutils.strutils import as_escaped_unicode_literal\n    >>> t = '1.\u2605 \ud83d\uded1'\n    >>> as_literal(t)\n    '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\u2605\\\\\\\\x20\\\\\\\\U0001f6d1'\n    \"\"\"\n", "function_signature": "def as_escaped_unicode_literal(\n        text: str\n) -> str:"}}
{"prompt": "def as_escaped_utf8_literal(\n        text: str,\n) -> str:\n    \"\"\"Convert the given ``text`` into a string of escaped UTF8 hexadecimal.\n\n    Args:\n    text (:obj:`str`): The string to convert.\n\n    :rtype:\n    :obj:`str`\n\n    A string with each character of the given ``text`` converted\n    into an escaped UTF8 hexadecimal.\n\n    Example:\n    >>> from flutils.strutils import as_literal_utf8\n    >>> t = '1.\u2605 \ud83d\uded1'\n    >>> as_escaped_utf8_literal(t)\n    '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\xe2\\\\\\\\x98\\\\\\\\x85\\\\\\\\x20\\\\\\\\xf0\\\\\\\\x9f\\\\\\\\x9b\n    \\\\\\\\x91'\n    \"\"\"\n", "metadata": {"task_id": "flutils/8", "ground_truth": "    out = ''\n    text_bytes = text.encode('utf8')\n    for c in text_bytes:\n        out += '\\\\%s' % hex(c)[1:]\n    return out", "fpath_tuple": ["flutils", "flutils", "strutils.py"], "context_start_lineno": 46, "line_no": 67, "id": 148, "target_function_prompt": "def as_escaped_utf8_literal(\n        text: str,\n) -> str:\n    \"\"\"Convert the given ``text`` into a string of escaped UTF8 hexadecimal.\n\n    Args:\n    text (:obj:`str`): The string to convert.\n\n    :rtype:\n    :obj:`str`\n\n    A string with each character of the given ``text`` converted\n    into an escaped UTF8 hexadecimal.\n\n    Example:\n    >>> from flutils.strutils import as_literal_utf8\n    >>> t = '1.\u2605 \ud83d\uded1'\n    >>> as_escaped_utf8_literal(t)\n    '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\xe2\\\\\\\\x98\\\\\\\\x85\\\\\\\\x20\\\\\\\\xf0\\\\\\\\x9f\\\\\\\\x9b\n    \\\\\\\\x91'\n    \"\"\"\n", "function_signature": "def as_escaped_utf8_literal(\n        text: str,\n) -> str:"}}
{"prompt": "def camel_to_underscore(\n        text: str\n) -> str:\n    \"\"\"Convert a camel-cased string to a string containing words separated\n    with underscores.\n\n    Args:\n    text (str): The camel-cased string to convert.\n\n    :rtype: :obj:`str`\n\n    Example:\n    >>> from flutils.strutils import camel_to_underscore\n    >>> camel_to_underscore('FooBar')\n    'foo_bar'\n    \"\"\"\n", "metadata": {"task_id": "flutils/9", "ground_truth": "    return _CAMEL_TO_UNDERSCORE_RE.sub(r'_\\1', text).lower()", "fpath_tuple": ["flutils", "flutils", "strutils.py"], "context_start_lineno": 80, "line_no": 96, "id": 149, "target_function_prompt": "def camel_to_underscore(\n        text: str\n) -> str:\n    \"\"\"Convert a camel-cased string to a string containing words separated\n    with underscores.\n\n    Args:\n    text (str): The camel-cased string to convert.\n\n    :rtype: :obj:`str`\n\n    Example:\n    >>> from flutils.strutils import camel_to_underscore\n    >>> camel_to_underscore('FooBar')\n    'foo_bar'\n    \"\"\"\n", "function_signature": "def camel_to_underscore(\n        text: str\n) -> str:"}}
{"prompt": "def convert_escaped_unicode_literal(\n        text: str\n) -> str:\n    \"\"\"Convert any escaped Unicode literal hexadecimal character(s) to the\n    proper character(s).\n\n    This function will convert a string, that may contain escaped Unicode\n    literal hexadecimal characters, into a string with the proper characters.\n\n    Args:\n    text (:obj:`str`): The string that may have escaped Unicode\n    hexadecimal.\n\n    :rtype:\n    :obj:`str`\n\n    A string with each escaped Unicode hexadecimal character converted\n    into the proper character.\n\n\n    The following Unicode literal formats are supported::\n\n    \\\\x31\n    \\\\u0031\n    \\\\U00000031\n\n    Examples:\n\n    Basic usage::\n\n    >>> from flutils.strutils import convert_escaped_unicode_literal\n    >>> a = '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\u2605\\\\\\\\x20\\\\\\\\U0001f6d1'\n    >>> convert_escaped_unicode_literal(a)\n    '1.\u2605 \ud83d\uded1'\n\n    This function is intended for cases when the value of an environment\n    variable contains escaped Unicode literal characters that need to be\n    converted to proper characters::\n\n    $ export TEST='\\\\x31\\\\x2e\\\\u2605\\\\x20\\\\U0001f6d1'\n    $ python\n\n    ::\n\n    >>> import os\n    >>> from flutils.strutils import convert_escaped_unicode_literal\n    >>> a = os.getenv('TEST')\n    >>> a\n    '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\u2605\\\\\\\\x20\\\\\\\\U0001f6d1'\n    >>> convert_escaped_unicode_literal(a)\n    '1.\u2605 \ud83d\uded1'\n\n    \"\"\"\n", "metadata": {"task_id": "flutils/10", "ground_truth": "    text_bytes = text.encode()\n    return text_bytes.decode('unicode_escape')", "fpath_tuple": ["flutils", "flutils", "strutils.py"], "context_start_lineno": 99, "line_no": 152, "id": 150, "target_function_prompt": "def convert_escaped_unicode_literal(\n        text: str\n) -> str:\n    \"\"\"Convert any escaped Unicode literal hexadecimal character(s) to the\n    proper character(s).\n\n    This function will convert a string, that may contain escaped Unicode\n    literal hexadecimal characters, into a string with the proper characters.\n\n    Args:\n    text (:obj:`str`): The string that may have escaped Unicode\n    hexadecimal.\n\n    :rtype:\n    :obj:`str`\n\n    A string with each escaped Unicode hexadecimal character converted\n    into the proper character.\n\n\n    The following Unicode literal formats are supported::\n\n    \\\\x31\n    \\\\u0031\n    \\\\U00000031\n\n    Examples:\n\n    Basic usage::\n\n    >>> from flutils.strutils import convert_escaped_unicode_literal\n    >>> a = '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\u2605\\\\\\\\x20\\\\\\\\U0001f6d1'\n    >>> convert_escaped_unicode_literal(a)\n    '1.\u2605 \ud83d\uded1'\n\n    This function is intended for cases when the value of an environment\n    variable contains escaped Unicode literal characters that need to be\n    converted to proper characters::\n\n    $ export TEST='\\\\x31\\\\x2e\\\\u2605\\\\x20\\\\U0001f6d1'\n    $ python\n\n    ::\n\n    >>> import os\n    >>> from flutils.strutils import convert_escaped_unicode_literal\n    >>> a = os.getenv('TEST')\n    >>> a\n    '\\\\\\\\x31\\\\\\\\x2e\\\\\\\\u2605\\\\\\\\x20\\\\\\\\U0001f6d1'\n    >>> convert_escaped_unicode_literal(a)\n    '1.\u2605 \ud83d\uded1'\n\n    \"\"\"\n", "function_signature": "def convert_escaped_unicode_literal(\n        text: str\n) -> str:"}}
{"prompt": "def convert_escaped_utf8_literal(\n        text: str\n) -> str:\n    \"\"\"Convert any escaped UTF-8 hexadecimal character bytes into the proper\n    string characters(s).\n\n    This function will convert a string, that may contain escaped UTF-8\n    literal hexadecimal bytes, into a string with the proper characters.\n\n    Args:\n    text (:obj:`str`): The string that may have escaped UTF8 hexadecimal.\n\n    Raises:\n    UnicodeDecodeError: if any of the escaped hexadecimal characters\n    are not proper UTF8 bytes.\n\n    :rtype:\n    :obj:`str`\n\n    A string with each escaped UTF8 hexadecimal character converted\n    into the proper character.\n\n    Examples:\n\n    Basic usage:\n\n    >>> from flutils.strutils import convert_raw_utf8_escape\n    >>> a = 'test\\\\\\\\xc2\\\\\\\\xa9'\n    >>> convert_escaped_utf8_literal(a)\n    'test\u00a9'\n\n    This function is intended for cases when the value of an environment\n    variable contains escaped UTF-8 literal characters (bytes) that need\n    to be converted to proper characters::\n\n    $ export TEST='test\\\\\\\\xc2\\\\\\\\xa9'\n    $ python\n\n    ::\n\n    >>> import os\n    >>> from flutils.strutils import convert_raw_utf8_escape\n    >>> a = os.getenv('TEST')\n    >>> a\n    'test\\\\\\\\xc2\\\\\\\\xa9'\n    >>> convert_escaped_utf8_literal(a)\n    'test\u00a9'\n    \"\"\"\n", "metadata": {"task_id": "flutils/11", "ground_truth": "    from flutils.codecs import register_codecs  # pylint:disable=C0415\n    register_codecs()\n    text_bytes = text.encode('utf-8')\n    text = text_bytes.decode('raw_utf8_escape')\n    return text", "fpath_tuple": ["flutils", "flutils", "strutils.py"], "context_start_lineno": 156, "line_no": 204, "id": 151, "target_function_prompt": "def convert_escaped_utf8_literal(\n        text: str\n) -> str:\n    \"\"\"Convert any escaped UTF-8 hexadecimal character bytes into the proper\n    string characters(s).\n\n    This function will convert a string, that may contain escaped UTF-8\n    literal hexadecimal bytes, into a string with the proper characters.\n\n    Args:\n    text (:obj:`str`): The string that may have escaped UTF8 hexadecimal.\n\n    Raises:\n    UnicodeDecodeError: if any of the escaped hexadecimal characters\n    are not proper UTF8 bytes.\n\n    :rtype:\n    :obj:`str`\n\n    A string with each escaped UTF8 hexadecimal character converted\n    into the proper character.\n\n    Examples:\n\n    Basic usage:\n\n    >>> from flutils.strutils import convert_raw_utf8_escape\n    >>> a = 'test\\\\\\\\xc2\\\\\\\\xa9'\n    >>> convert_escaped_utf8_literal(a)\n    'test\u00a9'\n\n    This function is intended for cases when the value of an environment\n    variable contains escaped UTF-8 literal characters (bytes) that need\n    to be converted to proper characters::\n\n    $ export TEST='test\\\\\\\\xc2\\\\\\\\xa9'\n    $ python\n\n    ::\n\n    >>> import os\n    >>> from flutils.strutils import convert_raw_utf8_escape\n    >>> a = os.getenv('TEST')\n    >>> a\n    'test\\\\\\\\xc2\\\\\\\\xa9'\n    >>> convert_escaped_utf8_literal(a)\n    'test\u00a9'\n    \"\"\"\n", "function_signature": "def convert_escaped_utf8_literal(\n        text: str\n) -> str:"}}
{"prompt": "def underscore_to_camel(\n        text: str,\n        lower_first: bool = True\n) -> str:\n    \"\"\"Convert a string with words separated by underscores to a camel-cased\n    string.\n\n    Args:\n    text (:obj:`str`): The camel-cased string to convert.\n    lower_first (:obj:`bool`, optional): Lowercase the first character.\n    Defaults to :obj:`True`.\n\n    :rtype: :obj:`str`\n\n    Examples:\n    >>> from flutils.strutils import underscore_to_camel\n    >>> underscore_to_camel('foo_bar')\n    'fooBar'\n    >>> underscore_to_camel('_one__two___',lower_first=False)\n    'OneTwo'\n    \"\"\"\n", "metadata": {"task_id": "flutils/12", "ground_truth": "    out = ''.join([x.capitalize() or '' for x in text.split('_')])\n    if lower_first is True:\n        return out[:1].lower() + out[1:]\n    return out", "fpath_tuple": ["flutils", "flutils", "strutils.py"], "context_start_lineno": 211, "line_no": 232, "id": 152, "target_function_prompt": "def underscore_to_camel(\n        text: str,\n        lower_first: bool = True\n) -> str:\n    \"\"\"Convert a string with words separated by underscores to a camel-cased\n    string.\n\n    Args:\n    text (:obj:`str`): The camel-cased string to convert.\n    lower_first (:obj:`bool`, optional): Lowercase the first character.\n    Defaults to :obj:`True`.\n\n    :rtype: :obj:`str`\n\n    Examples:\n    >>> from flutils.strutils import underscore_to_camel\n    >>> underscore_to_camel('foo_bar')\n    'fooBar'\n    >>> underscore_to_camel('_one__two___',lower_first=False)\n    'OneTwo'\n    \"\"\"\n", "function_signature": "def underscore_to_camel(\n        text: str,\n        lower_first: bool = True\n) -> str:"}}
{"prompt": "def get_os_group(name: _STR_OR_INT_OR_NONE = None) -> grp.struct_group:\n    \"\"\"Get an operating system group object.\n\n    Args:\n    name (:obj:`str` or :obj:`int`, optional): The \"group name\" or ``gid``.\n    Defaults to the current users's group.\n\n    Raises:\n    OSError: If the given ``name`` does not exist as a \"group\n    name\" for this operating system.\n    OSError: If the given ``name`` is a ``gid`` and it does not\n    exist.\n\n    :rtype:\n    :obj:`struct_group <grp>`\n\n    * A tuple like object.\n\n    Example:\n    >>> from flutils.pathutils import get_os_group\n    >>> get_os_group('bar')\n    grp.struct_group(gr_name='bar', gr_passwd='*', gr_gid=2001,\n    gr_mem=['foo'])\n    \"\"\"\n", "metadata": {"task_id": "flutils/13", "ground_truth": "    if name is None:\n        name = get_os_user().pw_gid\n        name = cast(int, name)\n    if isinstance(name, int):\n        try:\n            return grp.getgrgid(name)\n        except KeyError:\n            raise OSError(\n                'The given gid: %r, is not a valid gid for this operating '\n                'system.' % name\n            )\n    try:\n        return grp.getgrnam(name)\n    except KeyError:\n        raise OSError(\n            'The given name: %r, is not a valid \"group name\" '\n            'for this operating system.' % name\n        )", "fpath_tuple": ["flutils", "flutils", "pathutils.py"], "context_start_lineno": 416, "line_no": 440, "id": 156, "target_function_prompt": "def get_os_group(name: _STR_OR_INT_OR_NONE = None) -> grp.struct_group:\n    \"\"\"Get an operating system group object.\n\n    Args:\n    name (:obj:`str` or :obj:`int`, optional): The \"group name\" or ``gid``.\n    Defaults to the current users's group.\n\n    Raises:\n    OSError: If the given ``name`` does not exist as a \"group\n    name\" for this operating system.\n    OSError: If the given ``name`` is a ``gid`` and it does not\n    exist.\n\n    :rtype:\n    :obj:`struct_group <grp>`\n\n    * A tuple like object.\n\n    Example:\n    >>> from flutils.pathutils import get_os_group\n    >>> get_os_group('bar')\n    grp.struct_group(gr_name='bar', gr_passwd='*', gr_gid=2001,\n    gr_mem=['foo'])\n    \"\"\"\n", "function_signature": "def get_os_group(name: _STR_OR_INT_OR_NONE = None) -> grp.struct_group:"}}
{"prompt": "def get_os_user(name: _STR_OR_INT_OR_NONE = None) -> pwd.struct_passwd:\n    \"\"\"Return an user object representing an operating system user.\n\n    Args:\n    name (:obj:`str` or :obj:`int`, optional): The \"login name\" or\n    ``uid``.  Defaults to the current user's \"login name\".\n    Raises:\n    OSError: If the given ``name`` does not exist as a \"login\n    name\" for this operating system.\n    OSError: If the given ``name`` is an ``uid`` and it does not\n    exist.\n\n    :rtype:\n    :obj:`struct_passwd <pwd>`\n\n    * A tuple like object.\n\n    Example:\n    >>> from flutils.pathutils import get_os_user\n    >>> get_os_user('foo')\n    pwd.struct_passwd(pw_name='foo', pw_passwd='********', pw_uid=1001,\n    pw_gid=2001, pw_gecos='Foo Bar', pw_dir='/home/foo',\n    pw_shell='/usr/local/bin/bash')\n    \"\"\"\n", "metadata": {"task_id": "flutils/14", "ground_truth": "    if isinstance(name, int):\n        try:\n            return pwd.getpwuid(name)\n        except KeyError:\n            raise OSError(\n                'The given uid: %r, is not a valid uid for this operating '\n                'system.' % name\n            )\n    if name is None:\n        name = getpass.getuser()\n    try:\n        return pwd.getpwnam(name)\n    except KeyError:\n        raise OSError(\n            'The given name: %r, is not a valid \"login name\" '\n            'for this operating system.' % name\n        )", "fpath_tuple": ["flutils", "flutils", "pathutils.py"], "context_start_lineno": 460, "line_no": 484, "id": 157, "target_function_prompt": "def get_os_user(name: _STR_OR_INT_OR_NONE = None) -> pwd.struct_passwd:\n    \"\"\"Return an user object representing an operating system user.\n\n    Args:\n    name (:obj:`str` or :obj:`int`, optional): The \"login name\" or\n    ``uid``.  Defaults to the current user's \"login name\".\n    Raises:\n    OSError: If the given ``name`` does not exist as a \"login\n    name\" for this operating system.\n    OSError: If the given ``name`` is an ``uid`` and it does not\n    exist.\n\n    :rtype:\n    :obj:`struct_passwd <pwd>`\n\n    * A tuple like object.\n\n    Example:\n    >>> from flutils.pathutils import get_os_user\n    >>> get_os_user('foo')\n    pwd.struct_passwd(pw_name='foo', pw_passwd='********', pw_uid=1001,\n    pw_gid=2001, pw_gecos='Foo Bar', pw_dir='/home/foo',\n    pw_shell='/usr/local/bin/bash')\n    \"\"\"\n", "function_signature": "def get_os_user(name: _STR_OR_INT_OR_NONE = None) -> pwd.struct_passwd:"}}
{"prompt": "def encode(\n        text: _Str,\n        errors: _Str = 'strict'\n) -> Tuple[bytes, int]:\n    \"\"\"Convert a :obj:`str`, that may contain escaped utf8 hexadecimal, to\n    bytes of escaped utf8 hexadecimal.\n\n    Args:\n    text (str or :obj:`~UserString`): The string input.\n    errors (str or :obj:`~UserString`): The error checking level.\n\n    Returns:\n    bytes: The given ``text`` converted into escaped utf8 bytes.\n    int: The number of given ``text`` characters consumed\n\n    Raises:\n    UnicodeEncodeError: if the given ``text`` contains escaped\n    utf8 hexadecimal that references invalid utf8 bytes.\n    \"\"\"\n", "metadata": {"task_id": "flutils/15", "ground_truth": "\n    # Convert the given 'text', that are of type UserString into a str.\n    # if isinstance(text, UserString):\n    #     text_input = str(text)\n    # else:\n\n    text_input = str(text)\n\n    # Convert the given 'errors', that are of type UserString into a str.\n    errors_input = str(errors)\n\n    # Convert the string into utf-8 bytes\n    text_bytes_utf8 = text_input.encode('utf-8')\n    text_bytes_utf8 = cast(bytes, text_bytes_utf8)\n\n    # Convert the utf8 bytes into a string of latin-1 characters.\n    # This basically maps the exact utf8 bytes to the string. Also,\n    # this converts any escaped hexadecimal sequences \\\\xHH into\n    # \\xHH bytes.\n    text_str_latin1 = text_bytes_utf8.decode('unicode_escape')\n\n    # Convert the string of latin-1 characters (which are actually\n    # utf8 characters) into bytes.\n    text_bytes_utf8 = text_str_latin1.encode('latin1')\n\n    # Convert the utf8 bytes into a string.\n    try:\n        text_str = text_bytes_utf8.decode('utf-8', errors=errors_input)\n    except UnicodeDecodeError as e:\n        raise UnicodeEncodeError(\n            'eutf8h',\n            str(text_input),\n            e.start,\n            e.end,\n            e.reason,\n        )\n\n    # Convert each character into a string of escaped utf8 hexadecimal.\n    out_str: str = reduce(lambda a, b: f'{a}{b}', _each_utf8_hex(text_str))\n\n    out_bytes = out_str.encode('utf-8')\n\n    return out_bytes, len(text)", "fpath_tuple": ["flutils", "flutils", "codecs", "raw_utf8_escape.py"], "context_start_lineno": 26, "line_no": 45, "id": 159, "target_function_prompt": "def encode(\n        text: _Str,\n        errors: _Str = 'strict'\n) -> Tuple[bytes, int]:\n    \"\"\"Convert a :obj:`str`, that may contain escaped utf8 hexadecimal, to\n    bytes of escaped utf8 hexadecimal.\n\n    Args:\n    text (str or :obj:`~UserString`): The string input.\n    errors (str or :obj:`~UserString`): The error checking level.\n\n    Returns:\n    bytes: The given ``text`` converted into escaped utf8 bytes.\n    int: The number of given ``text`` characters consumed\n\n    Raises:\n    UnicodeEncodeError: if the given ``text`` contains escaped\n    utf8 hexadecimal that references invalid utf8 bytes.\n    \"\"\"\n", "function_signature": "def encode(\n        text: _Str,\n        errors: _Str = 'strict'\n) -> Tuple[bytes, int]:"}}
{"prompt": "def decode(\n        data: _ByteString,\n        errors: _Str = 'strict'\n) -> Tuple[str, int]:\n    \"\"\"Convert a bytes type of escaped utf8 hexadecimal to a string.\n\n    Args:\n    data (bytes or bytearray or memoryview): The escaped utf8\n    hexadecimal bytes.\n    errors (str or :obj:`~UserString`): The error checking level.\n\n    Returns:\n    str: The given ``data`` (of escaped utf8 hexadecimal bytes)\n    converted into a :obj:`str`.\n    int: The number of the given ``data`` bytes consumed.\n\n    Raises:\n    UnicodeDecodeError: if the given ``data`` contains escaped\n    utf8 hexadecimal that references invalid utf8 bytes.\n\n\n    \"\"\"\n", "metadata": {"task_id": "flutils/16", "ground_truth": "    # Convert memoryview and bytearray objects to bytes.\n    data_bytes = bytes(data)\n\n    # Convert the given 'errors', that are of type UserString into a str.\n    errors_input = str(errors)\n\n    # Convert the utf8 bytes into a string of latin-1 characters.\n    # This basically maps the exact utf8 bytes to the string. Also,\n    # this converts any escaped hexadecimal sequences \\\\xHH into\n    # \\xHH bytes.\n    text_str_latin1 = data_bytes.decode('unicode_escape')\n\n    # Convert the string of latin-1 characters (which are actually\n    # utf8 characters) into bytes.\n    text_bytes_utf8 = text_str_latin1.encode('latin1')\n\n    # Convert the utf8 bytes into a string.\n    try:\n        out = text_bytes_utf8.decode('utf-8', errors=errors_input)\n    except UnicodeDecodeError as e:\n        raise UnicodeDecodeError(\n            'eutf8h',\n            data_bytes,\n            e.start,\n            e.end,\n            e.reason\n        )\n    return out, len(data)", "fpath_tuple": ["flutils", "flutils", "codecs", "raw_utf8_escape.py"], "context_start_lineno": 90, "line_no": 112, "id": 160, "target_function_prompt": "def decode(\n        data: _ByteString,\n        errors: _Str = 'strict'\n) -> Tuple[str, int]:\n    \"\"\"Convert a bytes type of escaped utf8 hexadecimal to a string.\n\n    Args:\n    data (bytes or bytearray or memoryview): The escaped utf8\n    hexadecimal bytes.\n    errors (str or :obj:`~UserString`): The error checking level.\n\n    Returns:\n    str: The given ``data`` (of escaped utf8 hexadecimal bytes)\n    converted into a :obj:`str`.\n    int: The number of the given ``data`` bytes consumed.\n\n    Raises:\n    UnicodeDecodeError: if the given ``data`` contains escaped\n    utf8 hexadecimal that references invalid utf8 bytes.\n\n\n    \"\"\"\n", "function_signature": "def decode(\n        data: _ByteString,\n        errors: _Str = 'strict'\n) -> Tuple[str, int]:"}}
{"prompt": "def has_any_attrs(obj: _Any, *attrs: str) -> bool:\n    \"\"\"Check if the given ``obj`` has **ANY** of the given ``*attrs``.\n\n    Args:\n    obj (:obj:`Any <typing.Any>`): The object to check.\n    *attrs (:obj:`str`): The names of the attributes to check.\n\n    :rtype:\n    :obj:`bool`\n\n    * :obj:`True` if any of the given ``*attrs`` exist on the given\n    ``obj``;\n    * :obj:`False` otherwise.\n\n    Example:\n    >>> from flutils.objutils import has_any_attrs\n    >>> has_any_attrs(dict(),'get','keys','items','values','something')\n    True\n    \"\"\"\n", "metadata": {"task_id": "flutils/17", "ground_truth": "    for attr in attrs:\n        if hasattr(obj, attr) is True:\n            return True\n    return False", "fpath_tuple": ["flutils", "flutils", "objutils.py"], "context_start_lineno": 35, "line_no": 54, "id": 161, "target_function_prompt": "def has_any_attrs(obj: _Any, *attrs: str) -> bool:\n    \"\"\"Check if the given ``obj`` has **ANY** of the given ``*attrs``.\n\n    Args:\n    obj (:obj:`Any <typing.Any>`): The object to check.\n    *attrs (:obj:`str`): The names of the attributes to check.\n\n    :rtype:\n    :obj:`bool`\n\n    * :obj:`True` if any of the given ``*attrs`` exist on the given\n    ``obj``;\n    * :obj:`False` otherwise.\n\n    Example:\n    >>> from flutils.objutils import has_any_attrs\n    >>> has_any_attrs(dict(),'get','keys','items','values','something')\n    True\n    \"\"\"\n", "function_signature": "def has_any_attrs(obj: _Any, *attrs: str) -> bool:"}}
{"prompt": "def has_any_callables(obj: _Any, *attrs: str) -> bool:\n    \"\"\"Check if the given ``obj`` has **ANY** of the given ``attrs`` and are\n    callable.\n\n    Args:\n    obj (:obj:`Any <typing.Any>`): The object to check.\n    *attrs (:obj:`str`): The names of the attributes to check.\n\n    :rtype:\n    :obj:`bool`\n\n    * :obj:`True` if ANY of the given ``*attrs`` exist on the given ``obj``\n    and ANY are callable;\n    * :obj:`False` otherwise.\n\n    Example:\n    >>> from flutils.objutils import has_any_callables\n    >>> has_any_callables(dict(),'get','keys','items','values','foo')\n    True\n    \"\"\"\n", "metadata": {"task_id": "flutils/18", "ground_truth": "    if has_any_attrs(obj, *attrs) is True:\n        for attr in attrs:\n            if callable(getattr(obj, attr)) is True:\n                return True\n    return False", "fpath_tuple": ["flutils", "flutils", "objutils.py"], "context_start_lineno": 60, "line_no": 80, "id": 162, "target_function_prompt": "def has_any_callables(obj: _Any, *attrs: str) -> bool:\n    \"\"\"Check if the given ``obj`` has **ANY** of the given ``attrs`` and are\n    callable.\n\n    Args:\n    obj (:obj:`Any <typing.Any>`): The object to check.\n    *attrs (:obj:`str`): The names of the attributes to check.\n\n    :rtype:\n    :obj:`bool`\n\n    * :obj:`True` if ANY of the given ``*attrs`` exist on the given ``obj``\n    and ANY are callable;\n    * :obj:`False` otherwise.\n\n    Example:\n    >>> from flutils.objutils import has_any_callables\n    >>> has_any_callables(dict(),'get','keys','items','values','foo')\n    True\n    \"\"\"\n", "function_signature": "def has_any_callables(obj: _Any, *attrs: str) -> bool:"}}
{"prompt": "def is_list_like(\n        obj: _Any\n) -> bool:\n    \"\"\"Check that given ``obj`` acts like a list and is iterable.\n\n    List-like objects are instances of:\n\n    - :obj:`UserList <collections.UserList>`\n    - :obj:`Iterator <collections.abc.Iterator>`\n    - :obj:`KeysView <collections.abc.KeysView>`\n    - :obj:`ValuesView <collections.abc.ValuesView>`\n    - :obj:`deque <collections.deque>`\n    - :obj:`frozenset`\n    - :obj:`list`\n    - :obj:`set`\n    - :obj:`tuple`\n\n    List-like objects are **NOT** instances of:\n\n    - :obj:`None`\n    - :obj:`bool`\n    - :obj:`bytes`\n    - :obj:`ChainMap <collections.ChainMap>`\n    - :obj:`Counter <collections.Counter>`\n    - :obj:`OrderedDict <collections.OrderedDict>`\n    - :obj:`UserDict <collections.UserDict>`\n    - :obj:`UserString <collections.UserString>`\n    - :obj:`defaultdict <collections.defaultdict>`\n    - :obj:`Decimal <decimal.Decimal>`\n    - :obj:`dict`\n    - :obj:`float`\n    - :obj:`int`\n    - :obj:`str`\n    - etc...\n\n    Args:\n    obj (:obj:`Any <typing.Any>`): The object to check.\n\n    :rtype:\n    :obj:`bool`\n\n    * :obj:`True` if the given ``obj`` is list-like; :\n    * :obj:`False` otherwise.\n\n    Examples:\n    >>> from flutils.objutils import is_list_like\n    >>> is_list_like([1, 2, 3])\n    True\n    >>> is_list_like(reversed([1, 2, 4]))\n    True\n    >>> is_list_like('hello')\n    False\n    >>> is_list_like(sorted('hello'))\n    True\n    \"\"\"\n", "metadata": {"task_id": "flutils/19", "ground_truth": "    if is_subclass_of_any(obj, *_LIST_LIKE):\n        return True\n    return False", "fpath_tuple": ["flutils", "flutils", "objutils.py"], "context_start_lineno": 145, "line_no": 200, "id": 163, "target_function_prompt": "def is_list_like(\n        obj: _Any\n) -> bool:\n    \"\"\"Check that given ``obj`` acts like a list and is iterable.\n\n    List-like objects are instances of:\n\n    - :obj:`UserList <collections.UserList>`\n    - :obj:`Iterator <collections.abc.Iterator>`\n    - :obj:`KeysView <collections.abc.KeysView>`\n    - :obj:`ValuesView <collections.abc.ValuesView>`\n    - :obj:`deque <collections.deque>`\n    - :obj:`frozenset`\n    - :obj:`list`\n    - :obj:`set`\n    - :obj:`tuple`\n\n    List-like objects are **NOT** instances of:\n\n    - :obj:`None`\n    - :obj:`bool`\n    - :obj:`bytes`\n    - :obj:`ChainMap <collections.ChainMap>`\n    - :obj:`Counter <collections.Counter>`\n    - :obj:`OrderedDict <collections.OrderedDict>`\n    - :obj:`UserDict <collections.UserDict>`\n    - :obj:`UserString <collections.UserString>`\n    - :obj:`defaultdict <collections.defaultdict>`\n    - :obj:`Decimal <decimal.Decimal>`\n    - :obj:`dict`\n    - :obj:`float`\n    - :obj:`int`\n    - :obj:`str`\n    - etc...\n\n    Args:\n    obj (:obj:`Any <typing.Any>`): The object to check.\n\n    :rtype:\n    :obj:`bool`\n\n    * :obj:`True` if the given ``obj`` is list-like; :\n    * :obj:`False` otherwise.\n\n    Examples:\n    >>> from flutils.objutils import is_list_like\n    >>> is_list_like([1, 2, 3])\n    True\n    >>> is_list_like(reversed([1, 2, 4]))\n    True\n    >>> is_list_like('hello')\n    False\n    >>> is_list_like(sorted('hello'))\n    True\n    \"\"\"\n", "function_signature": "def is_list_like(\n        obj: _Any\n) -> bool:"}}
{"prompt": "def is_subclass_of_any(obj: _Any, *classes: _Any) -> bool:\n    \"\"\"Check if the given ``obj`` is a subclass of any of the given\n    ``*classes``.\n\n    Args:\n    obj (:obj:`Any <typing.Any>`): The object to check.\n    *classes (:obj:`Any <typing.Any>`): The classes to check against.\n\n    :rtype:\n    :obj:`bool`\n\n    * :obj:`True` if the given ``obj`` is an instance of ANY given\n    ``*classes``;\n    * :obj:`False` otherwise.\n\n    Example:\n    >>> from flutils.objutils import is_subclass_of_any\n    >>> from collections import ValuesView, KeysView, UserList\n    >>> obj = dict(a=1, b=2)\n    >>> is_subclass_of_any(obj.keys(),ValuesView,KeysView,UserList)\n    True\n    \"\"\"\n", "metadata": {"task_id": "flutils/20", "ground_truth": "    for cls in classes:\n        if issubclass(obj.__class__, cls):\n            return True\n    return False", "fpath_tuple": ["flutils", "flutils", "objutils.py"], "context_start_lineno": 205, "line_no": 227, "id": 164, "target_function_prompt": "def is_subclass_of_any(obj: _Any, *classes: _Any) -> bool:\n    \"\"\"Check if the given ``obj`` is a subclass of any of the given\n    ``*classes``.\n\n    Args:\n    obj (:obj:`Any <typing.Any>`): The object to check.\n    *classes (:obj:`Any <typing.Any>`): The classes to check against.\n\n    :rtype:\n    :obj:`bool`\n\n    * :obj:`True` if the given ``obj`` is an instance of ANY given\n    ``*classes``;\n    * :obj:`False` otherwise.\n\n    Example:\n    >>> from flutils.objutils import is_subclass_of_any\n    >>> from collections import ValuesView, KeysView, UserList\n    >>> obj = dict(a=1, b=2)\n    >>> is_subclass_of_any(obj.keys(),ValuesView,KeysView,UserList)\n    True\n    \"\"\"\n", "function_signature": "def is_subclass_of_any(obj: _Any, *classes: _Any) -> bool:"}}
{"prompt": "def aes_cbc_decrypt(data, key, iv):\n    \"\"\"\n    Decrypt with aes in CBC mode\n\n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {int[]} iv          16-Byte IV\n    @returns {int[]}           decrypted data\n    \"\"\"\n", "metadata": {"task_id": "youtube-dl/0", "ground_truth": "    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n\n    decrypted_data = []\n    previous_cipher_block = iv\n    for i in range(block_count):\n        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]\n        block += [0] * (BLOCK_SIZE_BYTES - len(block))\n\n        decrypted_block = aes_decrypt(block, expanded_key)\n        decrypted_data += xor(decrypted_block, previous_cipher_block)\n        previous_cipher_block = block\n    decrypted_data = decrypted_data[:len(data)]\n\n    return decrypted_data", "fpath_tuple": ["youtube-dl", "youtube_dl", "aes.py"], "context_start_lineno": 36, "line_no": 45, "id": 165, "target_function_prompt": "def aes_cbc_decrypt(data, key, iv):\n    \"\"\"\n    Decrypt with aes in CBC mode\n\n    @param {int[]} data        cipher\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {int[]} iv          16-Byte IV\n    @returns {int[]}           decrypted data\n    \"\"\"\n", "function_signature": "def aes_cbc_decrypt(data, key, iv):"}}
{"prompt": "def aes_cbc_encrypt(data, key, iv):\n    \"\"\"\n    Encrypt with aes in CBC mode. Using PKCS#7 padding\n\n    @param {int[]} data        cleartext\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {int[]} iv          16-Byte IV\n    @returns {int[]}           encrypted data\n    \"\"\"\n", "metadata": {"task_id": "youtube-dl/1", "ground_truth": "    expanded_key = key_expansion(key)\n    block_count = int(ceil(float(len(data)) / BLOCK_SIZE_BYTES))\n\n    encrypted_data = []\n    previous_cipher_block = iv\n    for i in range(block_count):\n        block = data[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES]\n        remaining_length = BLOCK_SIZE_BYTES - len(block)\n        block += [remaining_length] * remaining_length\n        mixed_block = xor(block, previous_cipher_block)\n\n        encrypted_block = aes_encrypt(mixed_block, expanded_key)\n        encrypted_data += encrypted_block\n\n        previous_cipher_block = encrypted_block\n\n    return encrypted_data", "fpath_tuple": ["youtube-dl", "youtube_dl", "aes.py"], "context_start_lineno": 62, "line_no": 71, "id": 166, "target_function_prompt": "def aes_cbc_encrypt(data, key, iv):\n    \"\"\"\n    Encrypt with aes in CBC mode. Using PKCS#7 padding\n\n    @param {int[]} data        cleartext\n    @param {int[]} key         16/24/32-Byte cipher key\n    @param {int[]} iv          16-Byte IV\n    @returns {int[]}           encrypted data\n    \"\"\"\n", "function_signature": "def aes_cbc_encrypt(data, key, iv):"}}
{"prompt": "def key_expansion(data):\n    \"\"\"\n    Generate key schedule\n\n    @param {int[]} data  16/24/32-Byte cipher key\n    @returns {int[]}     176/208/240-Byte expanded key\n    \"\"\"\n", "metadata": {"task_id": "youtube-dl/2", "ground_truth": "    data = data[:]  # copy\n    rcon_iteration = 1\n    key_size_bytes = len(data)\n    expanded_key_size_bytes = (key_size_bytes // 4 + 7) * BLOCK_SIZE_BYTES\n\n    while len(data) < expanded_key_size_bytes:\n        temp = data[-4:]\n        temp = key_schedule_core(temp, rcon_iteration)\n        rcon_iteration += 1\n        data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        for _ in range(3):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        if key_size_bytes == 32:\n            temp = data[-4:]\n            temp = sub_bytes(temp)\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n\n        for _ in range(3 if key_size_bytes == 32 else 2 if key_size_bytes == 24 else 0):\n            temp = data[-4:]\n            data += xor(temp, data[-key_size_bytes: 4 - key_size_bytes])\n    data = data[:expanded_key_size_bytes]\n\n    return data", "fpath_tuple": ["youtube-dl", "youtube_dl", "aes.py"], "context_start_lineno": 90, "line_no": 97, "id": 167, "target_function_prompt": "def key_expansion(data):\n    \"\"\"\n    Generate key schedule\n\n    @param {int[]} data  16/24/32-Byte cipher key\n    @returns {int[]}     176/208/240-Byte expanded key\n    \"\"\"\n", "function_signature": "def key_expansion(data):"}}
{"prompt": "def aes_encrypt(data, expanded_key):\n    \"\"\"\n    Encrypt one block with aes\n\n    @param {int[]} data          16-Byte state\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte cipher\n    \"\"\"\n", "metadata": {"task_id": "youtube-dl/3", "ground_truth": "    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n    for i in range(1, rounds + 1):\n        data = sub_bytes(data)\n        data = shift_rows(data)\n        if i != rounds:\n            data = mix_columns(data)\n        data = xor(data, expanded_key[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES])\n\n    return data", "fpath_tuple": ["youtube-dl", "youtube_dl", "aes.py"], "context_start_lineno": 125, "line_no": 133, "id": 168, "target_function_prompt": "def aes_encrypt(data, expanded_key):\n    \"\"\"\n    Encrypt one block with aes\n\n    @param {int[]} data          16-Byte state\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte cipher\n    \"\"\"\n", "function_signature": "def aes_encrypt(data, expanded_key):"}}
{"prompt": "def aes_decrypt(data, expanded_key):\n    \"\"\"\n    Decrypt one block with aes\n\n    @param {int[]} data          16-Byte cipher\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte state\n    \"\"\"\n", "metadata": {"task_id": "youtube-dl/4", "ground_truth": "    rounds = len(expanded_key) // BLOCK_SIZE_BYTES - 1\n\n    for i in range(rounds, 0, -1):\n        data = xor(data, expanded_key[i * BLOCK_SIZE_BYTES: (i + 1) * BLOCK_SIZE_BYTES])\n        if i != rounds:\n            data = mix_columns_inv(data)\n        data = shift_rows_inv(data)\n        data = sub_bytes_inv(data)\n    data = xor(data, expanded_key[:BLOCK_SIZE_BYTES])\n\n    return data", "fpath_tuple": ["youtube-dl", "youtube_dl", "aes.py"], "context_start_lineno": 146, "line_no": 154, "id": 169, "target_function_prompt": "def aes_decrypt(data, expanded_key):\n    \"\"\"\n    Decrypt one block with aes\n\n    @param {int[]} data          16-Byte cipher\n    @param {int[]} expanded_key  176/208/240-Byte expanded key\n    @returns {int[]}             16-Byte state\n    \"\"\"\n", "function_signature": "def aes_decrypt(data, expanded_key):"}}
{"prompt": "def aes_decrypt_text(data, password, key_size_bytes):\n    \"\"\"\n    Decrypt text\n    - The first 8 Bytes of decoded 'data' are the 8 high Bytes of the counter\n    - The cipher key is retrieved by encrypting the first 16 Byte of 'password'\n    with the first 'key_size_bytes' Bytes from 'password' (if necessary filled with 0's)\n    - Mode of operation is 'counter'\n\n    @param {str} data                    Base64 encoded string\n    @param {str,unicode} password        Password (will be encoded with utf-8)\n    @param {int} key_size_bytes          Possible values: 16 for 128-Bit, 24 for 192-Bit or 32 for 256-Bit\n    @returns {str}                       Decrypted data\n    \"\"\"\n", "metadata": {"task_id": "youtube-dl/5", "ground_truth": "    NONCE_LENGTH_BYTES = 8\n\n    data = bytes_to_intlist(compat_b64decode(data))\n    password = bytes_to_intlist(password.encode('utf-8'))\n\n    key = password[:key_size_bytes] + [0] * (key_size_bytes - len(password))\n    key = aes_encrypt(key[:BLOCK_SIZE_BYTES], key_expansion(key)) * (key_size_bytes // BLOCK_SIZE_BYTES)\n\n    nonce = data[:NONCE_LENGTH_BYTES]\n    cipher = data[NONCE_LENGTH_BYTES:]\n\n    class Counter(object):\n        __value = nonce + [0] * (BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES)\n\n        def next_value(self):\n            temp = self.__value\n            self.__value = inc(self.__value)\n            return temp\n\n    decrypted_data = aes_ctr_decrypt(cipher, key, Counter())\n    plaintext = intlist_to_bytes(decrypted_data)\n\n    return plaintext", "fpath_tuple": ["youtube-dl", "youtube_dl", "aes.py"], "context_start_lineno": 167, "line_no": 180, "id": 170, "target_function_prompt": "def aes_decrypt_text(data, password, key_size_bytes):\n    \"\"\"\n    Decrypt text\n    - The first 8 Bytes of decoded 'data' are the 8 high Bytes of the counter\n    - The cipher key is retrieved by encrypting the first 16 Byte of 'password'\n    with the first 'key_size_bytes' Bytes from 'password' (if necessary filled with 0's)\n    - Mode of operation is 'counter'\n\n    @param {str} data                    Base64 encoded string\n    @param {str,unicode} password        Password (will be encoded with utf-8)\n    @param {int} key_size_bytes          Possible values: 16 for 128-Bit, 24 for 192-Bit or 32 for 256-Bit\n    @returns {str}                       Decrypted data\n    \"\"\"\n", "function_signature": "def aes_decrypt_text(data, password, key_size_bytes):"}}
{"prompt": "def build_fragments_list(boot_info):\n    \"\"\" Return a list of (segment, fragment) for each fragment in the video \"\"\"\n", "metadata": {"task_id": "youtube-dl/6", "ground_truth": "    res = []\n    segment_run_table = boot_info['segments'][0]\n    fragment_run_entry_table = boot_info['fragments'][0]['fragments']\n    first_frag_number = fragment_run_entry_table[0]['first']\n    fragments_counter = itertools.count(first_frag_number)\n    for segment, fragments_count in segment_run_table['segment_run']:\n        # In some live HDS streams (for example Rai), `fragments_count` is\n        # abnormal and causing out-of-memory errors. It's OK to change the\n        # number of fragments for live streams as they are updated periodically\n        if fragments_count == 4294967295 and boot_info['live']:\n            fragments_count = 2\n        for _ in range(fragments_count):\n            res.append((segment, next(fragments_counter)))\n\n    if boot_info['live']:\n        res = res[-2:]\n\n    return res", "fpath_tuple": ["youtube-dl", "youtube_dl", "downloader", "f4m.py"], "context_start_lineno": 187, "line_no": 189, "id": 171, "target_function_prompt": "def build_fragments_list(boot_info):\n    \"\"\" Return a list of (segment, fragment) for each fragment in the video \"\"\"\n", "function_signature": "def build_fragments_list(boot_info):"}}
{"prompt": "def checker(func: Callable) -> Callable:\n    \"\"\"\n    A decorator that will convert AssertionErrors into\n    CiVerificationError.\n\n    :param func: A function that will raise AssertionError\n    :return: The given function wrapped to raise a CiVerificationError on AssertionError\n    \"\"\"\n", "metadata": {"task_id": "python-semantic-release/0", "ground_truth": "\n    def func_wrapper(*args, **kwargs):\n        try:\n            func(*args, **kwargs)\n            return True\n        except AssertionError:\n            raise CiVerificationError(\n                \"The verification check for the environment did not pass.\"\n            )\n\n    return func_wrapper", "fpath_tuple": ["python-semantic-release", "semantic_release", "ci_checks.py"], "context_start_lineno": 8, "line_no": 16, "id": 180, "target_function_prompt": "def checker(func: Callable) -> Callable:\n    \"\"\"\n    A decorator that will convert AssertionErrors into\n    CiVerificationError.\n\n    :param func: A function that will raise AssertionError\n    :return: The given function wrapped to raise a CiVerificationError on AssertionError\n    \"\"\"\n", "function_signature": "def checker(func: Callable) -> Callable:"}}
{"prompt": "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n", "metadata": {"task_id": "pytutils/0", "ground_truth": "    scheme, netloc, path, query_string, fragment = urlparse.urlsplit(url)\n\n    query_params = urlparse.parse_qs(query_string)\n    query_params.update(**params)\n\n    new_query_string = urlencode(query_params, doseq=doseq)\n\n    new_url = urlparse.urlunsplit([scheme, netloc, path, new_query_string, fragment])\n    return new_url", "fpath_tuple": ["pytutils", "pytutils", "urls.py"], "context_start_lineno": 8, "line_no": 22, "id": 181, "target_function_prompt": "def update_query_params(url, params, doseq=True):\n    \"\"\"\n    Update and/or insert query parameters in a URL.\n\n    >>> update_query_params('http://example.com?foo=bar&biz=baz', dict(foo='stuff'))\n    'http://example.com?...foo=stuff...'\n\n    :param url: URL\n    :type url: str\n    :param kwargs: Query parameters\n    :type kwargs: dict\n    :return: Modified URL\n    :rtype: str\n    \"\"\"\n", "function_signature": "def update_query_params(url, params, doseq=True):"}}
{"prompt": "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n", "metadata": {"task_id": "pytutils/1", "ground_truth": "    if isinstance(s, allowed_types):\n        return s\n    else:\n        return s.encode(encoding=encoding, errors=errors)", "fpath_tuple": ["pytutils", "pytutils", "pythree.py"], "context_start_lineno": 3, "line_no": 12, "id": 182, "target_function_prompt": "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):\n    \"\"\"\n    Ensure string is encoded as byteslike; convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/byteslike\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Encoded string as str\n    \"\"\"\n", "function_signature": "def ensure_encoded_bytes(s, encoding='utf-8', errors='strict', allowed_types=(bytes, bytearray, memoryview)):"}}
{"prompt": "def ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n", "metadata": {"task_id": "pytutils/2", "ground_truth": "    if not isinstance(s, allowed_types):\n        return s.decode(encoding=encoding, errors=errors)\n    else:\n        return s", "fpath_tuple": ["pytutils", "pytutils", "pythree.py"], "context_start_lineno": 18, "line_no": 30, "id": 183, "target_function_prompt": "def ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):\n    \"\"\"\n    Ensure string is decoded (eg unicode); convert using specified parameters if we have to.\n\n    :param str|bytes|bytesarray|memoryview s: string/bytes\n    :param str encoding: Decode using this encoding\n    :param str errors: How to handle errors\n    :return bytes|bytesarray|memoryview: Decoded string as bytes\n\n    :return: Encoded string\n    :rtype: bytes\n    \"\"\"\n", "function_signature": "def ensure_decoded_text(s, encoding='utf-8', errors='strict', allowed_types=(six.text_type,)):"}}
{"prompt": "def multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n", "metadata": {"task_id": "pytutils/3", "ground_truth": "    out_queues = [queue_factory() for _ in range(count)]\n\n    def f():\n        while True:\n            x = q.get()\n            for out_q in out_queues:\n                out_q.put(x)\n\n    t = Thread(target=f)\n    t.daemon = True\n    t.start()\n    return out_queues", "fpath_tuple": ["pytutils", "pytutils", "queues.py"], "context_start_lineno": 4, "line_no": 10, "id": 184, "target_function_prompt": "def multiplex(q, count=2, queue_factory=lambda: Queue()):\n    \"\"\" Convert one queue into several. Kind of like a teeing queue.\n\n    >>> in_q = Queue()\n    >>> q1, q2, q3 = multiplex(in_q, count=3)\n    \"\"\"\n", "function_signature": "def multiplex(q, count=2, queue_factory=lambda: Queue()):"}}
{"prompt": "def merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n", "metadata": {"task_id": "pytutils/4", "ground_truth": "    out_q = Queue(**kwargs)\n    threads = [Thread(target=push, args=(q, out_q)) for q in in_qs]\n    for t in threads:\n        t.daemon = True\n        t.start()\n    return out_q", "fpath_tuple": ["pytutils", "pytutils", "queues.py"], "context_start_lineno": 30, "line_no": 36, "id": 185, "target_function_prompt": "def merge(*in_qs, **kwargs):\n    \"\"\" Merge multiple queues together\n\n    >>> q1, q2, q3 = [Queue() for _ in range(3)]\n    >>> out_q = merge(q1, q2, q3)\n    \"\"\"\n", "function_signature": "def merge(*in_qs, **kwargs):"}}
{"prompt": "def parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n", "metadata": {"task_id": "pytutils/5", "ground_truth": "    for line in lines:\n        m1 = re.match(r'\\A([A-Za-z_0-9]+)=(.*)\\Z', line)\n\n        if m1:\n            key, val = m1.group(1), m1.group(2)\n\n            m2 = re.match(r\"\\A'(.*)'\\Z\", val)\n            if m2:\n                val = m2.group(1)\n\n            m3 = re.match(r'\\A\"(.*)\"\\Z', val)\n            if m3:\n                val = re.sub(r'\\\\(.)', r'\\1', m3.group(1))\n\n            yield key, val", "fpath_tuple": ["pytutils", "pytutils", "env.py"], "context_start_lineno": 12, "line_no": 26, "id": 186, "target_function_prompt": "def parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:\n    \"\"\"\n    Parses env file content.\n\n    From honcho.\n\n    >>> lines = ['TEST=${HOME}/yeee', 'THISIS=~/a/test', 'YOLO=~/swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST']\n    >>> load_env_file(lines, write_environ=dict())\n    OrderedDict([('TEST', '.../yeee'),\n    ('THISIS', '.../a/test'),\n    ('YOLO',\n    '.../swaggins/$NONEXISTENT_VAR_THAT_DOES_NOT_EXIST')])\n\n    \"\"\"\n", "function_signature": "def parse_env_file_contents(lines: typing.Iterable[str] = None) -> typing.Generator[typing.Tuple[str, str], None, None]:"}}
{"prompt": "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n", "metadata": {"task_id": "pytutils/6", "ground_truth": "    arg = _pprint.pformat(arg)\n\n    if not pygments:\n        return arg\n    return pygments.highlight(arg, lexer, formatter)", "fpath_tuple": ["pytutils", "pytutils", "pretty.py"], "context_start_lineno": 26, "line_no": 33, "id": 188, "target_function_prompt": "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):\n    \"\"\"\n    Pretty formats with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n", "function_signature": "def pf(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER):"}}
{"prompt": "def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n", "metadata": {"task_id": "pytutils/7", "ground_truth": "    arg = _pprint.pformat(arg)\n\n    close = False\n    try:\n        if isinstance(outfile, six.string_types):\n            close = True\n            outfile = open(outfile, 'w')\n\n        if not pygments:\n            return arg\n            outfile.write(arg)\n        else:\n            pygments.highlight(arg, lexer, formatter, outfile)\n    finally:\n        if close:\n            outfile.close()", "fpath_tuple": ["pytutils", "pytutils", "pretty.py"], "context_start_lineno": 42, "line_no": 49, "id": 189, "target_function_prompt": "def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):\n    \"\"\"\n    Pretty prints with coloring.\n\n    Works in iPython, but not bpython as it does not write directly to term\n    and decodes it instead.\n    \"\"\"\n", "function_signature": "def pp(arg, lexer=__PP_LEXER_PYTHON, formatter=__PP_FORMATTER, outfile=sys.stdout):"}}
{"prompt": "def tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n", "metadata": {"task_id": "pytutils/8", "ground_truth": "    return collections.defaultdict(tree)", "fpath_tuple": ["pytutils", "pytutils", "trees.py"], "context_start_lineno": 58, "line_no": 60, "id": 190, "target_function_prompt": "def tree():\n    \"\"\"Extremely simple one-lined tree based on defaultdict.\"\"\"\n", "function_signature": "def tree():"}}
{"prompt": "def accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n", "metadata": {"task_id": "pytutils/9", "ground_truth": "    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "fpath_tuple": ["pytutils", "pytutils", "iters.py"], "context_start_lineno": 6, "line_no": 20, "id": 191, "target_function_prompt": "def accumulate(iterable, func=operator.add):\n    \"\"\"\n    Iterate over running totals, ie [a,b,c,d] -> func( func( func(a, b), c), d) with each func result yielded.\n    Func is operator.add by default.\n\n    >>> list(accumulate([1,2,3,4,5]))\n    [1, 3, 6, 10, 15]\n    >>> list(accumulate([1,2,3,4,5], operator.mul))\n    [1, 2, 6, 24, 120]\n\n    :param iterable: Iterable\n    :param func: method (default=operator.add) to call for each pair of (last call result or first item, next item)\n    :return generator: Generator\n    \"\"\"\n", "function_signature": "def accumulate(iterable, func=operator.add):"}}
{"prompt": "def dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n", "metadata": {"task_id": "pytutils/10", "ground_truth": "    gen = f(*args, **kwargs)\n    return dedupe_iter(gen)", "fpath_tuple": ["pytutils", "pytutils", "iters.py"], "context_start_lineno": 64, "line_no": 74, "id": 192, "target_function_prompt": "def dedupe(f, instance, args, kwargs):\n    \"\"\"\n    Decorator to dedupe it's output iterable automatically.\n\n    :param f: Wrapped meth\n    :param instance: wrapt provided property for decorating hydrated class instances (unused)\n    :param args: Passthrough args\n    :param kwargs: Passthrough kwargs\n    :return decorator: Decorator method that ingests iterables and dedupes them iteratively.\n    \"\"\"\n", "function_signature": "def dedupe(f, instance, args, kwargs):"}}
{"prompt": "def parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n", "metadata": {"task_id": "docstring_parser/0", "ground_truth": "    return GoogleParser().parse(text)", "fpath_tuple": ["docstring_parser", "docstring_parser", "google.py"], "context_start_lineno": 268, "line_no": 273, "id": 193, "target_function_prompt": "def parse(text: str) -> Docstring:\n    \"\"\"Parse the Google-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n", "function_signature": "def parse(text: str) -> Docstring:"}}
{"prompt": "def parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n", "metadata": {"task_id": "docstring_parser/1", "ground_truth": "    ret = Docstring()\n    if not text:\n        return ret\n\n    text = inspect.cleandoc(text)\n    match = re.search(\"^:\", text, flags=re.M)\n    if match:\n        desc_chunk = text[: match.start()]\n        meta_chunk = text[match.start() :]\n    else:\n        desc_chunk = text\n        meta_chunk = \"\"\n\n    parts = desc_chunk.split(\"\\n\", 1)\n    ret.short_description = parts[0] or None\n    if len(parts) > 1:\n        long_desc_chunk = parts[1] or \"\"\n        ret.blank_after_short_description = long_desc_chunk.startswith(\"\\n\")\n        ret.blank_after_long_description = long_desc_chunk.endswith(\"\\n\\n\")\n        ret.long_description = long_desc_chunk.strip() or None\n\n    for match in re.finditer(\n        r\"(^:.*?)(?=^:|\\Z)\", meta_chunk, flags=re.S | re.M\n    ):\n        chunk = match.group(0)\n        if not chunk:\n            continue\n        try:\n            args_chunk, desc_chunk = chunk.lstrip(\":\").split(\":\", 1)\n        except ValueError:\n            raise ParseError(\n                'Error parsing meta information near \"{}\".'.format(chunk)\n            )\n        args = args_chunk.split()\n        desc = desc_chunk.strip()\n        if \"\\n\" in desc:\n            first_line, rest = desc.split(\"\\n\", 1)\n            desc = first_line + \"\\n\" + inspect.cleandoc(rest)\n\n        ret.meta.append(_build_meta(args, desc))\n\n    return ret", "fpath_tuple": ["docstring_parser", "docstring_parser", "rest.py"], "context_start_lineno": 85, "line_no": 90, "id": 194, "target_function_prompt": "def parse(text: str) -> Docstring:\n    \"\"\"Parse the ReST-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n", "function_signature": "def parse(text: str) -> Docstring:"}}
{"prompt": "def parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n", "metadata": {"task_id": "docstring_parser/2", "ground_truth": "    return NumpydocParser().parse(text)", "fpath_tuple": ["docstring_parser", "docstring_parser", "numpydoc.py"], "context_start_lineno": 325, "line_no": 330, "id": 195, "target_function_prompt": "def parse(text: str) -> Docstring:\n    \"\"\"Parse the numpy-style docstring into its components.\n\n    :returns: parsed docstring\n    \"\"\"\n", "function_signature": "def parse(text: str) -> Docstring:"}}
{"prompt": "def Default(value: DefaultType) -> DefaultType:\n    \"\"\"\n    You shouldn't use this function directly.\n\n    It's used internally to recognize when a default value has been overwritten, even\n    if the overridden default value was truthy.\n    \"\"\"\n", "metadata": {"task_id": "fastapi/0", "ground_truth": "    return DefaultPlaceholder(value)  # type: ignore", "fpath_tuple": ["fastapi", "fastapi", "datastructures.py"], "context_start_lineno": 44, "line_no": 51, "id": 196, "target_function_prompt": "def Default(value: DefaultType) -> DefaultType:\n    \"\"\"\n    You shouldn't use this function directly.\n\n    It's used internally to recognize when a default value has been overwritten, even\n    if the overridden default value was truthy.\n    \"\"\"\n", "function_signature": "def Default(value: DefaultType) -> DefaultType:"}}
{"prompt": "def create_response_field(\n    name: str,\n    type_: Type[Any],\n    class_validators: Optional[Dict[str, Validator]] = None,\n    default: Optional[Any] = None,\n    required: Union[bool, UndefinedType] = False,\n    model_config: Type[BaseConfig] = BaseConfig,\n    field_info: Optional[FieldInfo] = None,\n    alias: Optional[str] = None,\n) -> ModelField:\n    \"\"\"\n    Create a new response field. Raises if type_ is invalid.\n    \"\"\"\n", "metadata": {"task_id": "fastapi/1", "ground_truth": "    class_validators = class_validators or {}\n    field_info = field_info or FieldInfo(None)\n\n    response_field = functools.partial(\n        ModelField,\n        name=name,\n        type_=type_,\n        class_validators=class_validators,\n        default=default,\n        required=required,\n        model_config=model_config,\n        alias=alias,\n    )\n\n    try:\n        return response_field(field_info=field_info)\n    except RuntimeError:\n        raise fastapi.exceptions.FastAPIError(\n            f\"Invalid args for response field! Hint: check that {type_} is a valid pydantic field type\"\n        )", "fpath_tuple": ["fastapi", "fastapi", "utils.py"], "context_start_lineno": 36, "line_no": 49, "id": 197, "target_function_prompt": "def create_response_field(\n    name: str,\n    type_: Type[Any],\n    class_validators: Optional[Dict[str, Validator]] = None,\n    default: Optional[Any] = None,\n    required: Union[bool, UndefinedType] = False,\n    model_config: Type[BaseConfig] = BaseConfig,\n    field_info: Optional[FieldInfo] = None,\n    alias: Optional[str] = None,\n) -> ModelField:\n    \"\"\"\n    Create a new response field. Raises if type_ is invalid.\n    \"\"\"\n", "function_signature": "def create_response_field(\n    name: str,\n    type_: Type[Any],\n    class_validators: Optional[Dict[str, Validator]] = None,\n    default: Optional[Any] = None,\n    required: Union[bool, UndefinedType] = False,\n    model_config: Type[BaseConfig] = BaseConfig,\n    field_info: Optional[FieldInfo] = None,\n    alias: Optional[str] = None,\n) -> ModelField:"}}
{"prompt": "def get_value_or_default(\n    first_item: Union[DefaultPlaceholder, DefaultType],\n    *extra_items: Union[DefaultPlaceholder, DefaultType],\n) -> Union[DefaultPlaceholder, DefaultType]:\n    \"\"\"\n    Pass items or `DefaultPlaceholder`s by descending priority.\n\n    The first one to _not_ be a `DefaultPlaceholder` will be returned.\n\n    Otherwise, the first item (a `DefaultPlaceholder`) will be returned.\n    \"\"\"\n", "metadata": {"task_id": "fastapi/2", "ground_truth": "    items = (first_item,) + extra_items\n    for item in items:\n        if not isinstance(item, DefaultPlaceholder):\n            return item\n    return first_item", "fpath_tuple": ["fastapi", "fastapi", "utils.py"], "context_start_lineno": 140, "line_no": 151, "id": 198, "target_function_prompt": "def get_value_or_default(\n    first_item: Union[DefaultPlaceholder, DefaultType],\n    *extra_items: Union[DefaultPlaceholder, DefaultType],\n) -> Union[DefaultPlaceholder, DefaultType]:\n    \"\"\"\n    Pass items or `DefaultPlaceholder`s by descending priority.\n\n    The first one to _not_ be a `DefaultPlaceholder` will be returned.\n\n    Otherwise, the first item (a `DefaultPlaceholder`) will be returned.\n    \"\"\"\n", "function_signature": "def get_value_or_default(\n    first_item: Union[DefaultPlaceholder, DefaultType],\n    *extra_items: Union[DefaultPlaceholder, DefaultType],\n) -> Union[DefaultPlaceholder, DefaultType]:"}}
{"prompt": "def _quote(str):\n    r\"\"\"Quote a string for use in a cookie header.\n    If the string does not need to be double-quoted, then just return the\n    string.  Otherwise, surround the string in doublequotes and quote\n    (with a \\) special characters.\n    \"\"\"\n", "metadata": {"task_id": "sanic/0", "ground_truth": "    if str is None or _is_legal_key(str):\n        return str\n    else:\n        return '\"' + str.translate(_Translator) + '\"'", "fpath_tuple": ["sanic", "sanic", "cookies.py"], "context_start_lineno": 24, "line_no": 30, "id": 199, "target_function_prompt": "def _quote(str):\n    r\"\"\"Quote a string for use in a cookie header.\n    If the string does not need to be double-quoted, then just return the\n    string.  Otherwise, surround the string in doublequotes and quote\n    (with a \\) special characters.\n    \"\"\"\n", "function_signature": "def _quote(str):"}}
{"prompt": "def has_message_body(status):\n    \"\"\"\n    According to the following RFC message body and length SHOULD NOT\n    be included in responses status 1XX, 204 and 304.\n    https://tools.ietf.org/html/rfc2616#section-4.4\n    https://tools.ietf.org/html/rfc2616#section-4.3\n    \"\"\"\n", "metadata": {"task_id": "sanic/1", "ground_truth": "    return status not in (204, 304) and not (100 <= status < 200)", "fpath_tuple": ["sanic", "sanic", "helpers.py"], "context_start_lineno": 102, "line_no": 109, "id": 200, "target_function_prompt": "def has_message_body(status):\n    \"\"\"\n    According to the following RFC message body and length SHOULD NOT\n    be included in responses status 1XX, 204 and 304.\n    https://tools.ietf.org/html/rfc2616#section-4.4\n    https://tools.ietf.org/html/rfc2616#section-4.3\n    \"\"\"\n", "function_signature": "def has_message_body(status):"}}
{"prompt": "def is_entity_header(header):\n    \"\"\"Checks if the given header is an Entity Header\"\"\"\n", "metadata": {"task_id": "sanic/2", "ground_truth": "    return header.lower() in _ENTITY_HEADERS", "fpath_tuple": ["sanic", "sanic", "helpers.py"], "context_start_lineno": 112, "line_no": 114, "id": 201, "target_function_prompt": "def is_entity_header(header):\n    \"\"\"Checks if the given header is an Entity Header\"\"\"\n", "function_signature": "def is_entity_header(header):"}}
{"prompt": "def is_hop_by_hop_header(header):\n    \"\"\"Checks if the given header is a Hop By Hop header\"\"\"\n", "metadata": {"task_id": "sanic/3", "ground_truth": "    return header.lower() in _HOP_BY_HOP_HEADERS", "fpath_tuple": ["sanic", "sanic", "helpers.py"], "context_start_lineno": 117, "line_no": 119, "id": 202, "target_function_prompt": "def is_hop_by_hop_header(header):\n    \"\"\"Checks if the given header is a Hop By Hop header\"\"\"\n", "function_signature": "def is_hop_by_hop_header(header):"}}
{"prompt": "def remove_entity_headers(headers, allowed=(\"content-location\", \"expires\")):\n    \"\"\"\n    Removes all the entity headers present in the headers given.\n    According to RFC 2616 Section 10.3.5,\n    Content-Location and Expires are allowed as for the\n    \"strong cache validator\".\n    https://tools.ietf.org/html/rfc2616#section-10.3.5\n\n    returns the headers without the entity headers\n    \"\"\"\n", "metadata": {"task_id": "sanic/4", "ground_truth": "    allowed = set([h.lower() for h in allowed])\n    headers = {\n        header: value\n        for header, value in headers.items()\n        if not is_entity_header(header) or header.lower() in allowed\n    }\n    return headers", "fpath_tuple": ["sanic", "sanic", "helpers.py"], "context_start_lineno": 122, "line_no": 132, "id": 203, "target_function_prompt": "def remove_entity_headers(headers, allowed=(\"content-location\", \"expires\")):\n    \"\"\"\n    Removes all the entity headers present in the headers given.\n    According to RFC 2616 Section 10.3.5,\n    Content-Location and Expires are allowed as for the\n    \"strong cache validator\".\n    https://tools.ietf.org/html/rfc2616#section-10.3.5\n\n    returns the headers without the entity headers\n    \"\"\"\n", "function_signature": "def remove_entity_headers(headers, allowed=(\"content-location\", \"expires\")):"}}
{"prompt": "def str_to_bool(val: str) -> bool:\n    \"\"\"Takes string and tries to turn it into bool as human would do.\n\n    If val is in case insensitive (\n    \"y\", \"yes\", \"yep\", \"yup\", \"t\",\n    \"true\", \"on\", \"enable\", \"enabled\", \"1\"\n    ) returns True.\n    If val is in case insensitive (\n    \"n\", \"no\", \"f\", \"false\", \"off\", \"disable\", \"disabled\", \"0\"\n    ) returns False.\n    Else Raise ValueError.\"\"\"\n", "metadata": {"task_id": "sanic/5", "ground_truth": "\n    val = val.lower()\n    if val in {\n        \"y\",\n        \"yes\",\n        \"yep\",\n        \"yup\",\n        \"t\",\n        \"true\",\n        \"on\",\n        \"enable\",\n        \"enabled\",\n        \"1\",\n    }:\n        return True\n    elif val in {\"n\", \"no\", \"f\", \"false\", \"off\", \"disable\", \"disabled\", \"0\"}:\n        return False\n    else:\n        raise ValueError(f\"Invalid truth value {val}\")", "fpath_tuple": ["sanic", "sanic", "utils.py"], "context_start_lineno": 12, "line_no": 23, "id": 204, "target_function_prompt": "def str_to_bool(val: str) -> bool:\n    \"\"\"Takes string and tries to turn it into bool as human would do.\n\n    If val is in case insensitive (\n    \"y\", \"yes\", \"yep\", \"yup\", \"t\",\n    \"true\", \"on\", \"enable\", \"enabled\", \"1\"\n    ) returns True.\n    If val is in case insensitive (\n    \"n\", \"no\", \"f\", \"false\", \"off\", \"disable\", \"disabled\", \"0\"\n    ) returns False.\n    Else Raise ValueError.\"\"\"\n", "function_signature": "def str_to_bool(val: str) -> bool:"}}
{"prompt": "def escape(text):\n    \"\"\"\n    Minimal HTML escaping, not for attribute values (unlike html.escape).\n    \"\"\"\n", "metadata": {"task_id": "sanic/6", "ground_truth": "    return f\"{text}\".replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\")", "fpath_tuple": ["sanic", "sanic", "errorpages.py"], "context_start_lineno": 328, "line_no": 332, "id": 205, "target_function_prompt": "def escape(text):\n    \"\"\"\n    Minimal HTML escaping, not for attribute values (unlike html.escape).\n    \"\"\"\n", "function_signature": "def escape(text):"}}
{"prompt": "def add_status_code(code, quiet=None):\n    \"\"\"\n    Decorator used for adding exceptions to :class:`SanicException`.\n    \"\"\"\n", "metadata": {"task_id": "sanic/7", "ground_truth": "\n    def class_decorator(cls):\n        cls.status_code = code\n        if quiet or quiet is None and code != 500:\n            cls.quiet = True\n        _sanic_exceptions[code] = cls\n        return cls\n\n    return class_decorator", "fpath_tuple": ["sanic", "sanic", "exceptions.py"], "context_start_lineno": 8, "line_no": 12, "id": 206, "target_function_prompt": "def add_status_code(code, quiet=None):\n    \"\"\"\n    Decorator used for adding exceptions to :class:`SanicException`.\n    \"\"\"\n", "function_signature": "def add_status_code(code, quiet=None):"}}
{"prompt": "def empty(\n    status=204, headers: Optional[Dict[str, str]] = None\n) -> HTTPResponse:\n    \"\"\"\n    Returns an empty response to the client.\n\n    :param status Response code.\n    :param headers Custom Headers.\n    \"\"\"\n", "metadata": {"task_id": "sanic/8", "ground_truth": "    return HTTPResponse(body=b\"\", status=status, headers=headers)", "fpath_tuple": ["sanic", "sanic", "response.py"], "context_start_lineno": 238, "line_no": 247, "id": 207, "target_function_prompt": "def empty(\n    status=204, headers: Optional[Dict[str, str]] = None\n) -> HTTPResponse:\n    \"\"\"\n    Returns an empty response to the client.\n\n    :param status Response code.\n    :param headers Custom Headers.\n    \"\"\"\n", "function_signature": "def empty(\n    status=204, headers: Optional[Dict[str, str]] = None\n) -> HTTPResponse:"}}
{"prompt": "def json(\n    body: Any,\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = \"application/json\",\n    dumps: Optional[Callable[..., str]] = None,\n    **kwargs,\n) -> HTTPResponse:\n    \"\"\"\n    Returns response object with body in json format.\n\n    :param body: Response data to be serialized.\n    :param status: Response code.\n    :param headers: Custom Headers.\n    :param kwargs: Remaining arguments that are passed to the json encoder.\n    \"\"\"\n", "metadata": {"task_id": "sanic/9", "ground_truth": "    if not dumps:\n        dumps = BaseHTTPResponse._dumps\n    return HTTPResponse(\n        dumps(body, **kwargs),\n        headers=headers,\n        status=status,\n        content_type=content_type,\n    )", "fpath_tuple": ["sanic", "sanic", "response.py"], "context_start_lineno": 250, "line_no": 266, "id": 208, "target_function_prompt": "def json(\n    body: Any,\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = \"application/json\",\n    dumps: Optional[Callable[..., str]] = None,\n    **kwargs,\n) -> HTTPResponse:\n    \"\"\"\n    Returns response object with body in json format.\n\n    :param body: Response data to be serialized.\n    :param status: Response code.\n    :param headers: Custom Headers.\n    :param kwargs: Remaining arguments that are passed to the json encoder.\n    \"\"\"\n", "function_signature": "def json(\n    body: Any,\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = \"application/json\",\n    dumps: Optional[Callable[..., str]] = None,\n    **kwargs,\n) -> HTTPResponse:"}}
{"prompt": "def text(\n    body: str,\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = \"text/plain; charset=utf-8\",\n) -> HTTPResponse:\n    \"\"\"\n    Returns response object with body in text format.\n\n    :param body: Response data to be encoded.\n    :param status: Response code.\n    :param headers: Custom Headers.\n    :param content_type: the content type (string) of the response\n    \"\"\"\n", "metadata": {"task_id": "sanic/10", "ground_truth": "    if not isinstance(body, str):\n        raise TypeError(\n            f\"Bad body type. Expected str, got {type(body).__name__})\"\n        )\n\n    return HTTPResponse(\n        body, status=status, headers=headers, content_type=content_type\n    )", "fpath_tuple": ["sanic", "sanic", "response.py"], "context_start_lineno": 276, "line_no": 290, "id": 209, "target_function_prompt": "def text(\n    body: str,\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = \"text/plain; charset=utf-8\",\n) -> HTTPResponse:\n    \"\"\"\n    Returns response object with body in text format.\n\n    :param body: Response data to be encoded.\n    :param status: Response code.\n    :param headers: Custom Headers.\n    :param content_type: the content type (string) of the response\n    \"\"\"\n", "function_signature": "def text(\n    body: str,\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = \"text/plain; charset=utf-8\",\n) -> HTTPResponse:"}}
{"prompt": "def raw(\n    body: Optional[AnyStr],\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = DEFAULT_HTTP_CONTENT_TYPE,\n) -> HTTPResponse:\n    \"\"\"\n    Returns response object without encoding the body.\n\n    :param body: Response data.\n    :param status: Response code.\n    :param headers: Custom Headers.\n    :param content_type: the content type (string) of the response.\n    \"\"\"\n", "metadata": {"task_id": "sanic/11", "ground_truth": "    return HTTPResponse(\n        body=body,\n        status=status,\n        headers=headers,\n        content_type=content_type,\n    )", "fpath_tuple": ["sanic", "sanic", "response.py"], "context_start_lineno": 300, "line_no": 314, "id": 210, "target_function_prompt": "def raw(\n    body: Optional[AnyStr],\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = DEFAULT_HTTP_CONTENT_TYPE,\n) -> HTTPResponse:\n    \"\"\"\n    Returns response object without encoding the body.\n\n    :param body: Response data.\n    :param status: Response code.\n    :param headers: Custom Headers.\n    :param content_type: the content type (string) of the response.\n    \"\"\"\n", "function_signature": "def raw(\n    body: Optional[AnyStr],\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = DEFAULT_HTTP_CONTENT_TYPE,\n) -> HTTPResponse:"}}
{"prompt": "def html(\n    body: Union[str, bytes, HTMLProtocol],\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n) -> HTTPResponse:\n    \"\"\"\n    Returns response object with body in html format.\n\n    :param body: str or bytes-ish, or an object with __html__ or _repr_html_.\n    :param status: Response code.\n    :param headers: Custom Headers.\n    \"\"\"\n", "metadata": {"task_id": "sanic/12", "ground_truth": "    if not isinstance(body, (str, bytes)):\n        if hasattr(body, \"__html__\"):\n            body = body.__html__()\n        elif hasattr(body, \"_repr_html_\"):\n            body = body._repr_html_()\n\n    return HTTPResponse(  # type: ignore\n        body,\n        status=status,\n        headers=headers,\n        content_type=\"text/html; charset=utf-8\",\n    )", "fpath_tuple": ["sanic", "sanic", "response.py"], "context_start_lineno": 322, "line_no": 334, "id": 211, "target_function_prompt": "def html(\n    body: Union[str, bytes, HTMLProtocol],\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n) -> HTTPResponse:\n    \"\"\"\n    Returns response object with body in html format.\n\n    :param body: str or bytes-ish, or an object with __html__ or _repr_html_.\n    :param status: Response code.\n    :param headers: Custom Headers.\n    \"\"\"\n", "function_signature": "def html(\n    body: Union[str, bytes, HTMLProtocol],\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n) -> HTTPResponse:"}}
{"prompt": "def stream(\n    streaming_fn: StreamingFunction,\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = \"text/plain; charset=utf-8\",\n    chunked=\"deprecated\",\n):\n    \"\"\"Accepts an coroutine `streaming_fn` which can be used to\n    write chunks to a streaming response. Returns a `StreamingHTTPResponse`.\n\n    Example usage::\n\n    @app.route(\"/\")\n    async def index(request):\n    async def streaming_fn(response):\n    await response.write('foo')\n    await response.write('bar')\n\n    return stream(streaming_fn, content_type='text/plain')\n\n    :param streaming_fn: A coroutine accepts a response and\n    writes content to that response.\n    :param mime_type: Specific mime_type.\n    :param headers: Custom Headers.\n    :param chunked: Deprecated\n    \"\"\"\n", "metadata": {"task_id": "sanic/13", "ground_truth": "    if chunked != \"deprecated\":\n        warn(\n            \"The chunked argument has been deprecated and will be \"\n            \"removed in v21.6\"\n        )\n\n    return StreamingHTTPResponse(\n        streaming_fn,\n        headers=headers,\n        content_type=content_type,\n        status=status,\n    )", "fpath_tuple": ["sanic", "sanic", "response.py"], "context_start_lineno": 458, "line_no": 484, "id": 212, "target_function_prompt": "def stream(\n    streaming_fn: StreamingFunction,\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = \"text/plain; charset=utf-8\",\n    chunked=\"deprecated\",\n):\n    \"\"\"Accepts an coroutine `streaming_fn` which can be used to\n    write chunks to a streaming response. Returns a `StreamingHTTPResponse`.\n\n    Example usage::\n\n    @app.route(\"/\")\n    async def index(request):\n    async def streaming_fn(response):\n    await response.write('foo')\n    await response.write('bar')\n\n    return stream(streaming_fn, content_type='text/plain')\n\n    :param streaming_fn: A coroutine accepts a response and\n    writes content to that response.\n    :param mime_type: Specific mime_type.\n    :param headers: Custom Headers.\n    :param chunked: Deprecated\n    \"\"\"\n", "function_signature": "def stream(\n    streaming_fn: StreamingFunction,\n    status: int = 200,\n    headers: Optional[Dict[str, str]] = None,\n    content_type: str = \"text/plain; charset=utf-8\",\n    chunked=\"deprecated\",\n):"}}
{"prompt": "def redirect(\n    to: str,\n    headers: Optional[Dict[str, str]] = None,\n    status: int = 302,\n    content_type: str = \"text/html; charset=utf-8\",\n) -> HTTPResponse:\n    \"\"\"\n    Abort execution and cause a 302 redirect (by default) by setting a\n    Location header.\n\n    :param to: path or fully qualified URL to redirect to\n    :param headers: optional dict of headers to include in the new request\n    :param status: status code (int) of the new request, defaults to 302\n    :param content_type: the content type (string) of the response\n    \"\"\"\n", "metadata": {"task_id": "sanic/14", "ground_truth": "    headers = headers or {}\n\n    # URL Quote the URL before redirecting\n    safe_to = quote_plus(to, safe=\":/%#?&=@[]!$&'()*+,;\")\n\n    # According to RFC 7231, a relative URI is now permitted.\n    headers[\"Location\"] = safe_to\n\n    return HTTPResponse(\n        status=status, headers=headers, content_type=content_type\n    )", "fpath_tuple": ["sanic", "sanic", "response.py"], "context_start_lineno": 498, "line_no": 513, "id": 213, "target_function_prompt": "def redirect(\n    to: str,\n    headers: Optional[Dict[str, str]] = None,\n    status: int = 302,\n    content_type: str = \"text/html; charset=utf-8\",\n) -> HTTPResponse:\n    \"\"\"\n    Abort execution and cause a 302 redirect (by default) by setting a\n    Location header.\n\n    :param to: path or fully qualified URL to redirect to\n    :param headers: optional dict of headers to include in the new request\n    :param status: status code (int) of the new request, defaults to 302\n    :param content_type: the content type (string) of the response\n    \"\"\"\n", "function_signature": "def redirect(\n    to: str,\n    headers: Optional[Dict[str, str]] = None,\n    status: int = 302,\n    content_type: str = \"text/html; charset=utf-8\",\n) -> HTTPResponse:"}}
{"prompt": "def parse_multipart_form(body, boundary):\n    \"\"\"\n    Parse a request body and returns fields and files\n\n    :param body: bytes request body\n    :param boundary: bytes multipart boundary\n    :return: fields (RequestParameters), files (RequestParameters)\n    \"\"\"\n", "metadata": {"task_id": "sanic/15", "ground_truth": "    files = RequestParameters()\n    fields = RequestParameters()\n\n    form_parts = body.split(boundary)\n    for form_part in form_parts[1:-1]:\n        file_name = None\n        content_type = \"text/plain\"\n        content_charset = \"utf-8\"\n        field_name = None\n        line_index = 2\n        line_end_index = 0\n        while not line_end_index == -1:\n            line_end_index = form_part.find(b\"\\r\\n\", line_index)\n            form_line = form_part[line_index:line_end_index].decode(\"utf-8\")\n            line_index = line_end_index + 2\n\n            if not form_line:\n                break\n\n            colon_index = form_line.index(\":\")\n            form_header_field = form_line[0:colon_index].lower()\n            form_header_value, form_parameters = parse_content_header(\n                form_line[colon_index + 2 :]\n            )\n\n            if form_header_field == \"content-disposition\":\n                field_name = form_parameters.get(\"name\")\n                file_name = form_parameters.get(\"filename\")\n\n                # non-ASCII filenames in RFC2231, \"filename*\" format\n                if file_name is None and form_parameters.get(\"filename*\"):\n                    encoding, _, value = email.utils.decode_rfc2231(\n                        form_parameters[\"filename*\"]\n                    )\n                    file_name = unquote(value, encoding=encoding)\n            elif form_header_field == \"content-type\":\n                content_type = form_header_value\n                content_charset = form_parameters.get(\"charset\", \"utf-8\")\n\n        if field_name:\n            post_data = form_part[line_index:-4]\n            if file_name is None:\n                value = post_data.decode(content_charset)\n                if field_name in fields:\n                    fields[field_name].append(value)\n                else:\n                    fields[field_name] = [value]\n            else:\n                form_file = File(\n                    type=content_type, name=file_name, body=post_data\n                )\n                if field_name in files:\n                    files[field_name].append(form_file)\n                else:\n                    files[field_name] = [form_file]\n        else:\n            logger.debug(\n                \"Form-data field does not have a 'name' parameter \"\n                \"in the Content-Disposition header\"\n            )\n\n    return fields, files", "fpath_tuple": ["sanic", "sanic", "request.py"], "context_start_lineno": 711, "line_no": 719, "id": 214, "target_function_prompt": "def parse_multipart_form(body, boundary):\n    \"\"\"\n    Parse a request body and returns fields and files\n\n    :param body: bytes request body\n    :param boundary: bytes multipart boundary\n    :return: fields (RequestParameters), files (RequestParameters)\n    \"\"\"\n", "function_signature": "def parse_multipart_form(body, boundary):"}}
{"prompt": "def parse_content_header(value: str) -> Tuple[str, Options]:\n    \"\"\"Parse content-type and content-disposition header values.\n\n    E.g. 'form-data; name=upload; filename=\\\"file.txt\\\"' to\n    ('form-data', {'name': 'upload', 'filename': 'file.txt'})\n\n    Mostly identical to cgi.parse_header and werkzeug.parse_options_header\n    but runs faster and handles special characters better. Unescapes quotes.\n    \"\"\"\n", "metadata": {"task_id": "sanic/16", "ground_truth": "    value = _firefox_quote_escape.sub(\"%22\", value)\n    pos = value.find(\";\")\n    if pos == -1:\n        options: Dict[str, Union[int, str]] = {}\n    else:\n        options = {\n            m.group(1).lower(): m.group(2) or m.group(3).replace(\"%22\", '\"')\n            for m in _param.finditer(value[pos:])\n        }\n        value = value[:pos]\n    return value.strip().lower(), options", "fpath_tuple": ["sanic", "sanic", "headers.py"], "context_start_lineno": 32, "line_no": 41, "id": 215, "target_function_prompt": "def parse_content_header(value: str) -> Tuple[str, Options]:\n    \"\"\"Parse content-type and content-disposition header values.\n\n    E.g. 'form-data; name=upload; filename=\\\"file.txt\\\"' to\n    ('form-data', {'name': 'upload', 'filename': 'file.txt'})\n\n    Mostly identical to cgi.parse_header and werkzeug.parse_options_header\n    but runs faster and handles special characters better. Unescapes quotes.\n    \"\"\"\n", "function_signature": "def parse_content_header(value: str) -> Tuple[str, Options]:"}}
{"prompt": "def fwd_normalize(fwd: OptionsIterable) -> Options:\n    \"\"\"Normalize and convert values extracted from forwarded headers.\"\"\"\n", "metadata": {"task_id": "sanic/17", "ground_truth": "    ret: Dict[str, Union[int, str]] = {}\n    for key, val in fwd:\n        if val is not None:\n            try:\n                if key in (\"by\", \"for\"):\n                    ret[key] = fwd_normalize_address(val)\n                elif key in (\"host\", \"proto\"):\n                    ret[key] = val.lower()\n                elif key == \"port\":\n                    ret[key] = int(val)\n                elif key == \"path\":\n                    ret[key] = unquote(val)\n                else:\n                    ret[key] = val\n            except ValueError:\n                pass\n    return ret", "fpath_tuple": ["sanic", "sanic", "headers.py"], "context_start_lineno": 138, "line_no": 140, "id": 216, "target_function_prompt": "def fwd_normalize(fwd: OptionsIterable) -> Options:\n    \"\"\"Normalize and convert values extracted from forwarded headers.\"\"\"\n", "function_signature": "def fwd_normalize(fwd: OptionsIterable) -> Options:"}}
{"prompt": "def fwd_normalize_address(addr: str) -> str:\n    \"\"\"Normalize address fields of proxy headers.\"\"\"\n", "metadata": {"task_id": "sanic/18", "ground_truth": "    if addr == \"unknown\":\n        raise ValueError()  # omit unknown value identifiers\n    if addr.startswith(\"_\"):\n        return addr  # do not lower-case obfuscated strings\n    if _ipv6_re.fullmatch(addr):\n        addr = f\"[{addr}]\"  # bracket IPv6\n    return addr.lower()", "fpath_tuple": ["sanic", "sanic", "headers.py"], "context_start_lineno": 159, "line_no": 161, "id": 217, "target_function_prompt": "def fwd_normalize_address(addr: str) -> str:\n    \"\"\"Normalize address fields of proxy headers.\"\"\"\n", "function_signature": "def fwd_normalize_address(addr: str) -> str:"}}
{"prompt": "def parse_host(host: str) -> Tuple[Optional[str], Optional[int]]:\n    \"\"\"Split host:port into hostname and port.\n    :return: None in place of missing elements\n    \"\"\"\n", "metadata": {"task_id": "sanic/19", "ground_truth": "    m = _host_re.fullmatch(host)\n    if not m:\n        return None, None\n    host, port = m.groups()\n    return host.lower(), int(port) if port is not None else None", "fpath_tuple": ["sanic", "sanic", "headers.py"], "context_start_lineno": 170, "line_no": 174, "id": 218, "target_function_prompt": "def parse_host(host: str) -> Tuple[Optional[str], Optional[int]]:\n    \"\"\"Split host:port into hostname and port.\n    :return: None in place of missing elements\n    \"\"\"\n", "function_signature": "def parse_host(host: str) -> Tuple[Optional[str], Optional[int]]:"}}
{"prompt": "def format_http1_response(status: int, headers: HeaderBytesIterable) -> bytes:\n    \"\"\"Format a HTTP/1.1 response header.\"\"\"\n", "metadata": {"task_id": "sanic/20", "ground_truth": "    # Note: benchmarks show that here bytes concat is faster than bytearray,\n    # b\"\".join() or %-formatting. %timeit any changes you make.\n    ret = _HTTP1_STATUSLINES[status]\n    for h in headers:\n        ret += b\"%b: %b\\r\\n\" % h\n    ret += b\"\\r\\n\"\n    return ret", "fpath_tuple": ["sanic", "sanic", "headers.py"], "context_start_lineno": 187, "line_no": 189, "id": 219, "target_function_prompt": "def format_http1_response(status: int, headers: HeaderBytesIterable) -> bytes:\n    \"\"\"Format a HTTP/1.1 response header.\"\"\"\n", "function_signature": "def format_http1_response(status: int, headers: HeaderBytesIterable) -> bytes:"}}
{"prompt": "def task_id_str(task_family, params):\n    \"\"\"\n    Returns a canonical string used to identify a particular task\n\n    :param task_family: The task family (class name) of the task\n    :param params: a dict mapping parameter names to their serialized values\n    :return: A unique, shortened identifier corresponding to the family and params\n    \"\"\"\n", "metadata": {"task_id": "luigi/0", "ground_truth": "    # task_id is a concatenation of task family, the first values of the first 3 parameters\n    # sorted by parameter name and a md5hash of the family/parameters as a cananocalised json.\n    param_str = json.dumps(params, separators=(',', ':'), sort_keys=True)\n    param_hash = hashlib.md5(param_str.encode('utf-8')).hexdigest()\n\n    param_summary = '_'.join(p[:TASK_ID_TRUNCATE_PARAMS]\n                             for p in (params[p] for p in sorted(params)[:TASK_ID_INCLUDE_PARAMS]))\n    param_summary = TASK_ID_INVALID_CHAR_REGEX.sub('_', param_summary)\n\n    return '{}_{}_{}'.format(task_family, param_summary, param_hash[:TASK_ID_TRUNCATE_HASH])", "fpath_tuple": ["luigi", "luigi", "task.py"], "context_start_lineno": 114, "line_no": 122, "id": 220, "target_function_prompt": "def task_id_str(task_family, params):\n    \"\"\"\n    Returns a canonical string used to identify a particular task\n\n    :param task_family: The task family (class name) of the task\n    :param params: a dict mapping parameter names to their serialized values\n    :return: A unique, shortened identifier corresponding to the family and params\n    \"\"\"\n", "function_signature": "def task_id_str(task_family, params):"}}
{"prompt": "def externalize(taskclass_or_taskobject):\n    \"\"\"\n    Returns an externalized version of a Task. You may both pass an\n    instantiated task object or a task class. Some examples:\n\n    .. code-block:: python\n\n    class RequiringTask(luigi.Task):\n    def requires(self):\n    task_object = self.clone(MyTask)\n    return externalize(task_object)\n\n    ...\n\n    Here's mostly equivalent code, but ``externalize`` is applied to a task\n    class instead.\n\n    .. code-block:: python\n\n    @luigi.util.requires(externalize(MyTask))\n    class RequiringTask(luigi.Task):\n    pass\n    ...\n\n    Of course, it may also be used directly on classes and objects (for example\n    for reexporting or other usage).\n\n    .. code-block:: python\n\n    MyTask = externalize(MyTask)\n    my_task_2 = externalize(MyTask2(param='foo'))\n\n    If you however want a task class to be external from the beginning, you're\n    better off inheriting :py:class:`ExternalTask` rather than :py:class:`Task`.\n\n    This function tries to be side-effect free by creating a copy of the class\n    or the object passed in and then modify that object. In particular this\n    code shouldn't do anything.\n\n    .. code-block:: python\n\n    externalize(MyTask)  # BAD: This does nothing (as after luigi 2.4.0)\n    \"\"\"\n", "metadata": {"task_id": "luigi/1", "ground_truth": "    copied_value = copy.copy(taskclass_or_taskobject)\n    if copied_value is taskclass_or_taskobject:\n        # Assume it's a class\n        clazz = taskclass_or_taskobject\n\n        @_task_wraps(clazz)\n        class _CopyOfClass(clazz):\n            # How to copy a class: http://stackoverflow.com/a/9541120/621449\n            _visible_in_registry = False\n        _CopyOfClass.run = None\n        return _CopyOfClass\n    else:\n        # We assume it's an object\n        copied_value.run = None\n        return copied_value", "fpath_tuple": ["luigi", "luigi", "task.py"], "context_start_lineno": 755, "line_no": 798, "id": 221, "target_function_prompt": "def externalize(taskclass_or_taskobject):\n    \"\"\"\n    Returns an externalized version of a Task. You may both pass an\n    instantiated task object or a task class. Some examples:\n\n    .. code-block:: python\n\n    class RequiringTask(luigi.Task):\n    def requires(self):\n    task_object = self.clone(MyTask)\n    return externalize(task_object)\n\n    ...\n\n    Here's mostly equivalent code, but ``externalize`` is applied to a task\n    class instead.\n\n    .. code-block:: python\n\n    @luigi.util.requires(externalize(MyTask))\n    class RequiringTask(luigi.Task):\n    pass\n    ...\n\n    Of course, it may also be used directly on classes and objects (for example\n    for reexporting or other usage).\n\n    .. code-block:: python\n\n    MyTask = externalize(MyTask)\n    my_task_2 = externalize(MyTask2(param='foo'))\n\n    If you however want a task class to be external from the beginning, you're\n    better off inheriting :py:class:`ExternalTask` rather than :py:class:`Task`.\n\n    This function tries to be side-effect free by creating a copy of the class\n    or the object passed in and then modify that object. In particular this\n    code shouldn't do anything.\n\n    .. code-block:: python\n\n    externalize(MyTask)  # BAD: This does nothing (as after luigi 2.4.0)\n    \"\"\"\n", "function_signature": "def externalize(taskclass_or_taskobject):"}}
{"prompt": "def getpaths(struct):\n    \"\"\"\n    Maps all Tasks in a structured data object to their .output().\n    \"\"\"\n", "metadata": {"task_id": "luigi/2", "ground_truth": "    if isinstance(struct, Task):\n        return struct.output()\n    elif isinstance(struct, dict):\n        return struct.__class__((k, getpaths(v)) for k, v in struct.items())\n    elif isinstance(struct, (list, tuple)):\n        return struct.__class__(getpaths(r) for r in struct)\n    else:\n        # Remaining case: assume struct is iterable...\n        try:\n            return [getpaths(r) for r in struct]\n        except TypeError:\n            raise Exception('Cannot map %s to Task/dict/list' % str(struct))", "fpath_tuple": ["luigi", "luigi", "task.py"], "context_start_lineno": 833, "line_no": 837, "id": 222, "target_function_prompt": "def getpaths(struct):\n    \"\"\"\n    Maps all Tasks in a structured data object to their .output().\n    \"\"\"\n", "function_signature": "def getpaths(struct):"}}
{"prompt": "def flatten(struct):\n    \"\"\"\n    Creates a flat list of all all items in structured output (dicts, lists, items):\n\n    .. code-block:: python\n\n    >>> sorted(flatten({'a': 'foo', 'b': 'bar'}))\n    ['bar', 'foo']\n    >>> sorted(flatten(['foo', ['bar', 'troll']]))\n    ['bar', 'foo', 'troll']\n    >>> flatten('foo')\n    ['foo']\n    >>> flatten(42)\n    [42]\n    \"\"\"\n", "metadata": {"task_id": "luigi/3", "ground_truth": "    if struct is None:\n        return []\n    flat = []\n    if isinstance(struct, dict):\n        for _, result in struct.items():\n            flat += flatten(result)\n        return flat\n    if isinstance(struct, str):\n        return [struct]\n\n    try:\n        # if iterable\n        iterator = iter(struct)\n    except TypeError:\n        return [struct]\n\n    for result in iterator:\n        flat += flatten(result)\n    return flat", "fpath_tuple": ["luigi", "luigi", "task.py"], "context_start_lineno": 851, "line_no": 866, "id": 223, "target_function_prompt": "def flatten(struct):\n    \"\"\"\n    Creates a flat list of all all items in structured output (dicts, lists, items):\n\n    .. code-block:: python\n\n    >>> sorted(flatten({'a': 'foo', 'b': 'bar'}))\n    ['bar', 'foo']\n    >>> sorted(flatten(['foo', ['bar', 'troll']]))\n    ['bar', 'foo', 'troll']\n    >>> flatten('foo')\n    ['foo']\n    >>> flatten(42)\n    [42]\n    \"\"\"\n", "function_signature": "def flatten(struct):"}}
{"prompt": "def flatten_output(task):\n    \"\"\"\n    Lists all output targets by recursively walking output-less (wrapper) tasks.\n\n    FIXME order consistently.\n    \"\"\"\n", "metadata": {"task_id": "luigi/4", "ground_truth": "    r = flatten(task.output())\n    if not r:\n        for dep in flatten(task.requires()):\n            r += flatten_output(dep)\n    return r", "fpath_tuple": ["luigi", "luigi", "task.py"], "context_start_lineno": 887, "line_no": 893, "id": 224, "target_function_prompt": "def flatten_output(task):\n    \"\"\"\n    Lists all output targets by recursively walking output-less (wrapper) tasks.\n\n    FIXME order consistently.\n    \"\"\"\n", "function_signature": "def flatten_output(task):"}}
{"prompt": "def run(*args, **kwargs):\n    \"\"\"\n    Please dont use. Instead use `luigi` binary.\n\n    Run from cmdline using argparse.\n\n    :param use_dynamic_argparse: Deprecated and ignored\n    \"\"\"\n", "metadata": {"task_id": "luigi/5", "ground_truth": "    luigi_run_result = _run(*args, **kwargs)\n    return luigi_run_result if kwargs.get('detailed_summary') else luigi_run_result.scheduling_succeeded", "fpath_tuple": ["luigi", "luigi", "interface.py"], "context_start_lineno": 185, "line_no": 193, "id": 225, "target_function_prompt": "def run(*args, **kwargs):\n    \"\"\"\n    Please dont use. Instead use `luigi` binary.\n\n    Run from cmdline using argparse.\n\n    :param use_dynamic_argparse: Deprecated and ignored\n    \"\"\"\n", "function_signature": "def run(*args, **kwargs):"}}
{"prompt": "def build(tasks, worker_scheduler_factory=None, detailed_summary=False, **env_params):\n    \"\"\"\n    Run internally, bypassing the cmdline parsing.\n\n    Useful if you have some luigi code that you want to run internally.\n    Example:\n\n    .. code-block:: python\n\n    luigi.build([MyTask1(), MyTask2()], local_scheduler=True)\n\n    One notable difference is that `build` defaults to not using\n    the identical process lock. Otherwise, `build` would only be\n    callable once from each process.\n\n    :param tasks:\n    :param worker_scheduler_factory:\n    :param env_params:\n    :return: True if there were no scheduling errors, even if tasks may fail.\n    \"\"\"\n", "metadata": {"task_id": "luigi/6", "ground_truth": "    if \"no_lock\" not in env_params:\n        env_params[\"no_lock\"] = True\n\n    luigi_run_result = _schedule_and_run(tasks, worker_scheduler_factory, override_defaults=env_params)\n    return luigi_run_result if detailed_summary else luigi_run_result.scheduling_succeeded", "fpath_tuple": ["luigi", "luigi", "interface.py"], "context_start_lineno": 213, "line_no": 233, "id": 226, "target_function_prompt": "def build(tasks, worker_scheduler_factory=None, detailed_summary=False, **env_params):\n    \"\"\"\n    Run internally, bypassing the cmdline parsing.\n\n    Useful if you have some luigi code that you want to run internally.\n    Example:\n\n    .. code-block:: python\n\n    luigi.build([MyTask1(), MyTask2()], local_scheduler=True)\n\n    One notable difference is that `build` defaults to not using\n    the identical process lock. Otherwise, `build` would only be\n    callable once from each process.\n\n    :param tasks:\n    :param worker_scheduler_factory:\n    :param env_params:\n    :return: True if there were no scheduling errors, even if tasks may fail.\n    \"\"\"\n", "function_signature": "def build(tasks, worker_scheduler_factory=None, detailed_summary=False, **env_params):"}}
{"prompt": "def get_configured_hadoop_version():\n    \"\"\"\n    CDH4 (hadoop 2+) has a slightly different syntax for interacting with hdfs\n    via the command line.\n\n    The default version is CDH4, but one can override\n    this setting with \"cdh3\" or \"apache1\" in the hadoop section of the config\n    in order to use the old syntax.\n    \"\"\"\n", "metadata": {"task_id": "luigi/7", "ground_truth": "    return hadoopcli().version.lower()", "fpath_tuple": ["luigi", "luigi", "contrib", "hdfs", "config.py"], "context_start_lineno": 56, "line_no": 65, "id": 227, "target_function_prompt": "def get_configured_hadoop_version():\n    \"\"\"\n    CDH4 (hadoop 2+) has a slightly different syntax for interacting with hdfs\n    via the command line.\n\n    The default version is CDH4, but one can override\n    this setting with \"cdh3\" or \"apache1\" in the hadoop section of the config\n    in order to use the old syntax.\n    \"\"\"\n", "function_signature": "def get_configured_hadoop_version():"}}
{"prompt": "def get_configured_hdfs_client():\n    \"\"\"\n    This is a helper that fetches the configuration value for 'client' in\n    the [hdfs] section. It will return the client that retains backwards\n    compatibility when 'client' isn't configured.\n    \"\"\"\n", "metadata": {"task_id": "luigi/8", "ground_truth": "    return hdfs().client", "fpath_tuple": ["luigi", "luigi", "contrib", "hdfs", "config.py"], "context_start_lineno": 68, "line_no": 74, "id": 228, "target_function_prompt": "def get_configured_hdfs_client():\n    \"\"\"\n    This is a helper that fetches the configuration value for 'client' in\n    the [hdfs] section. It will return the client that retains backwards\n    compatibility when 'client' isn't configured.\n    \"\"\"\n", "function_signature": "def get_configured_hdfs_client():"}}
{"prompt": "def get_authenticate_kwargs(oauth_credentials=None, http_=None):\n    \"\"\"Returns a dictionary with keyword arguments for use with discovery\n\n    Prioritizes oauth_credentials or a http client provided by the user\n    If none provided, falls back to default credentials provided by google's command line\n    utilities. If that also fails, tries using httplib2.Http()\n\n    Used by `gcs.GCSClient` and `bigquery.BigQueryClient` to initiate the API Client\n    \"\"\"\n", "metadata": {"task_id": "luigi/9", "ground_truth": "    if oauth_credentials:\n        authenticate_kwargs = {\n            \"credentials\": oauth_credentials\n        }\n    elif http_:\n        authenticate_kwargs = {\n            \"http\": http_\n        }\n    else:\n        # neither http_ or credentials provided\n        try:\n            # try default credentials\n            credentials, _ = google.auth.default()\n            authenticate_kwargs = {\n                \"credentials\": credentials\n            }\n        except google.auth.exceptions.DefaultCredentialsError:\n            # try http using httplib2\n            authenticate_kwargs = {\n                \"http\": httplib2.Http()\n            }\n\n    return authenticate_kwargs", "fpath_tuple": ["luigi", "luigi", "contrib", "gcp.py"], "context_start_lineno": 14, "line_no": 23, "id": 230, "target_function_prompt": "def get_authenticate_kwargs(oauth_credentials=None, http_=None):\n    \"\"\"Returns a dictionary with keyword arguments for use with discovery\n\n    Prioritizes oauth_credentials or a http client provided by the user\n    If none provided, falls back to default credentials provided by google's command line\n    utilities. If that also fails, tries using httplib2.Http()\n\n    Used by `gcs.GCSClient` and `bigquery.BigQueryClient` to initiate the API Client\n    \"\"\"\n", "function_signature": "def get_authenticate_kwargs(oauth_credentials=None, http_=None):"}}
{"prompt": "def get_soql_fields(soql):\n    \"\"\"\n    Gets queried columns names.\n    \"\"\"\n", "metadata": {"task_id": "luigi/10", "ground_truth": "    soql_fields = re.search('(?<=select)(?s)(.*)(?=from)', soql, re.IGNORECASE)     # get fields\n    soql_fields = re.sub(' ', '', soql_fields.group())                              # remove extra spaces\n    soql_fields = re.sub('\\t', '', soql_fields)                                     # remove tabs\n    fields = re.split(',|\\n|\\r|', soql_fields)                                      # split on commas and newlines\n    fields = [field for field in fields if field != '']                             # remove empty strings\n    return fields", "fpath_tuple": ["luigi", "luigi", "contrib", "salesforce.py"], "context_start_lineno": 38, "line_no": 42, "id": 231, "target_function_prompt": "def get_soql_fields(soql):\n    \"\"\"\n    Gets queried columns names.\n    \"\"\"\n", "function_signature": "def get_soql_fields(soql):"}}
{"prompt": "def parse_results(fields, data):\n    \"\"\"\n    Traverses ordered dictionary, calls _traverse_results() to recursively read into the dictionary depth of data\n    \"\"\"\n", "metadata": {"task_id": "luigi/11", "ground_truth": "    master = []\n\n    for record in data['records']:  # for each 'record' in response\n        row = [None] * len(fields)  # create null list the length of number of columns\n        for obj, value in record.items():  # for each obj in record\n            if not isinstance(value, (dict, list, tuple)):  # if not data structure\n                if obj in fields:\n                    row[fields.index(obj)] = ensure_utf(value)\n\n            elif isinstance(value, dict) and obj != 'attributes':  # traverse down into object\n                path = obj\n                _traverse_results(value, fields, row, path)\n\n        master.append(row)\n    return master", "fpath_tuple": ["luigi", "luigi", "contrib", "salesforce.py"], "context_start_lineno": 54, "line_no": 58, "id": 232, "target_function_prompt": "def parse_results(fields, data):\n    \"\"\"\n    Traverses ordered dictionary, calls _traverse_results() to recursively read into the dictionary depth of data\n    \"\"\"\n", "function_signature": "def parse_results(fields, data):"}}
{"prompt": "def _constrain_glob(glob, paths, limit=5):\n    \"\"\"\n    Tweaks glob into a list of more specific globs that together still cover paths and not too much extra.\n\n    Saves us minutes long listings for long dataset histories.\n\n    Specifically, in this implementation the leftmost occurrences of \"[0-9]\"\n    give rise to a few separate globs that each specialize the expression to\n    digits that actually occur in paths.\n    \"\"\"\n", "metadata": {"task_id": "luigi/12", "ground_truth": "\n    def digit_set_wildcard(chars):\n        \"\"\"\n        Makes a wildcard expression for the set, a bit readable, e.g. [1-5].\n        \"\"\"\n        chars = sorted(chars)\n        if len(chars) > 1 and ord(chars[-1]) - ord(chars[0]) == len(chars) - 1:\n            return '[%s-%s]' % (chars[0], chars[-1])\n        else:\n            return '[%s]' % ''.join(chars)\n\n    current = {glob: paths}\n    while True:\n        pos = list(current.keys())[0].find('[0-9]')\n        if pos == -1:\n            # no wildcard expressions left to specialize in the glob\n            return list(current.keys())\n        char_sets = {}\n        for g, p in current.items():\n            char_sets[g] = sorted({path[pos] for path in p})\n        if sum(len(s) for s in char_sets.values()) > limit:\n            return [g.replace('[0-9]', digit_set_wildcard(char_sets[g]), 1) for g in current]\n        for g, s in char_sets.items():\n            for c in s:\n                new_glob = g.replace('[0-9]', c, 1)\n                new_paths = list(filter(lambda p: p[pos] == c, current[g]))\n                current[new_glob] = new_paths\n            del current[g]", "fpath_tuple": ["luigi", "luigi", "tools", "range.py"], "context_start_lineno": 488, "line_no": 498, "id": 233, "target_function_prompt": "def _constrain_glob(glob, paths, limit=5):\n    \"\"\"\n    Tweaks glob into a list of more specific globs that together still cover paths and not too much extra.\n\n    Saves us minutes long listings for long dataset histories.\n\n    Specifically, in this implementation the leftmost occurrences of \"[0-9]\"\n    give rise to a few separate globs that each specialize the expression to\n    digits that actually occur in paths.\n    \"\"\"\n", "function_signature": "def _constrain_glob(glob, paths, limit=5):"}}
{"prompt": "def _get_per_location_glob(tasks, outputs, regexes):\n    \"\"\"\n    Builds a glob listing existing output paths.\n\n    Esoteric reverse engineering, but worth it given that (compared to an\n    equivalent contiguousness guarantee by naive complete() checks)\n    requests to the filesystem are cut by orders of magnitude, and users\n    don't even have to retrofit existing tasks anyhow.\n    \"\"\"\n", "metadata": {"task_id": "luigi/13", "ground_truth": "    paths = [o.path for o in outputs]\n    # naive, because some matches could be confused by numbers earlier\n    # in path, e.g. /foo/fifa2000k/bar/2000-12-31/00\n    matches = [r.search(p) for r, p in zip(regexes, paths)]\n\n    for m, p, t in zip(matches, paths, tasks):\n        if m is None:\n            raise NotImplementedError(\"Couldn't deduce datehour representation in output path %r of task %s\" % (p, t))\n\n    n_groups = len(matches[0].groups())\n    # the most common position of every group is likely\n    # to be conclusive hit or miss\n    positions = [most_common((m.start(i), m.end(i)) for m in matches)[0] for i in range(1, n_groups + 1)]\n\n    glob = list(paths[0])  # FIXME sanity check that it's the same for all paths\n    for start, end in positions:\n        glob = glob[:start] + ['[0-9]'] * (end - start) + glob[end:]\n    # chop off the last path item\n    # (wouldn't need to if `hadoop fs -ls -d` equivalent were available)\n    return ''.join(glob).rsplit('/', 1)[0]", "fpath_tuple": ["luigi", "luigi", "tools", "range.py"], "context_start_lineno": 533, "line_no": 542, "id": 234, "target_function_prompt": "def _get_per_location_glob(tasks, outputs, regexes):\n    \"\"\"\n    Builds a glob listing existing output paths.\n\n    Esoteric reverse engineering, but worth it given that (compared to an\n    equivalent contiguousness guarantee by naive complete() checks)\n    requests to the filesystem are cut by orders of magnitude, and users\n    don't even have to retrofit existing tasks anyhow.\n    \"\"\"\n", "function_signature": "def _get_per_location_glob(tasks, outputs, regexes):"}}
{"prompt": "def _list_existing(filesystem, glob, paths):\n    \"\"\"\n    Get all the paths that do in fact exist. Returns a set of all existing paths.\n\n    Takes a luigi.target.FileSystem object, a str which represents a glob and\n    a list of strings representing paths.\n    \"\"\"\n", "metadata": {"task_id": "luigi/14", "ground_truth": "    globs = _constrain_glob(glob, paths)\n    time_start = time.time()\n    listing = []\n    for g in sorted(globs):\n        logger.debug('Listing %s', g)\n        if filesystem.exists(g):\n            listing.extend(filesystem.listdir(g))\n    logger.debug('%d %s listings took %f s to return %d items',\n                 len(globs), filesystem.__class__.__name__, time.time() - time_start, len(listing))\n    return set(listing)", "fpath_tuple": ["luigi", "luigi", "tools", "range.py"], "context_start_lineno": 594, "line_no": 601, "id": 235, "target_function_prompt": "def _list_existing(filesystem, glob, paths):\n    \"\"\"\n    Get all the paths that do in fact exist. Returns a set of all existing paths.\n\n    Takes a luigi.target.FileSystem object, a str which represents a glob and\n    a list of strings representing paths.\n    \"\"\"\n", "function_signature": "def _list_existing(filesystem, glob, paths):"}}
{"prompt": "def from_utc(utcTime, fmt=None):\n    \"\"\"convert UTC time string to time.struct_time: change datetime.datetime to time, return time.struct_time type\"\"\"\n", "metadata": {"task_id": "luigi/15", "ground_truth": "    if fmt is None:\n        try_formats = [\"%Y-%m-%d %H:%M:%S.%f\", \"%Y-%m-%d %H:%M:%S\"]\n    else:\n        try_formats = [fmt]\n\n    for fmt in try_formats:\n        try:\n            time_struct = datetime.datetime.strptime(utcTime, fmt)\n        except ValueError:\n            pass\n        else:\n            date = int(time.mktime(time_struct.timetuple()))\n            return date\n    else:\n        raise ValueError(\"No UTC format matches {}\".format(utcTime))", "fpath_tuple": ["luigi", "luigi", "server.py"], "context_start_lineno": 226, "line_no": 228, "id": 236, "target_function_prompt": "def from_utc(utcTime, fmt=None):\n    \"\"\"convert UTC time string to time.struct_time: change datetime.datetime to time, return time.struct_time type\"\"\"\n", "function_signature": "def from_utc(utcTime, fmt=None):"}}
{"prompt": "def _urljoin(base, url):\n    \"\"\"\n    Join relative URLs to base URLs like urllib.parse.urljoin but support\n    arbitrary URIs (esp. 'http+unix://').\n    \"\"\"\n", "metadata": {"task_id": "luigi/16", "ground_truth": "    parsed = urlparse(base)\n    scheme = parsed.scheme\n    return urlparse(\n        urljoin(parsed._replace(scheme='http').geturl(), url)\n    )._replace(scheme=scheme).geturl()", "fpath_tuple": ["luigi", "luigi", "rpc.py"], "context_start_lineno": 52, "line_no": 57, "id": 237, "target_function_prompt": "def _urljoin(base, url):\n    \"\"\"\n    Join relative URLs to base URLs like urllib.parse.urljoin but support\n    arbitrary URIs (esp. 'http+unix://').\n    \"\"\"\n", "function_signature": "def _urljoin(base, url):"}}
{"prompt": "def find_deps(task, upstream_task_family):\n    '''\n    Finds all dependencies that start with the given task and have a path\n    to upstream_task_family\n\n    Returns all deps on all paths between task and upstream\n    '''\n", "metadata": {"task_id": "luigi/17", "ground_truth": "    return {t for t in dfs_paths(task, upstream_task_family)}", "fpath_tuple": ["luigi", "luigi", "tools", "deps.py"], "context_start_lineno": 75, "line_no": 82, "id": 238, "target_function_prompt": "def find_deps(task, upstream_task_family):\n    '''\n    Finds all dependencies that start with the given task and have a path\n    to upstream_task_family\n\n    Returns all deps on all paths between task and upstream\n    '''\n", "function_signature": "def find_deps(task, upstream_task_family):"}}
{"prompt": "def get_task_output_description(task_output):\n    '''\n    Returns a task's output as a string\n    '''\n", "metadata": {"task_id": "luigi/18", "ground_truth": "    output_description = \"n/a\"\n\n    if isinstance(task_output, RemoteTarget):\n        output_description = \"[SSH] {0}:{1}\".format(task_output._fs.remote_context.host, task_output.path)\n    elif isinstance(task_output, S3Target):\n        output_description = \"[S3] {0}\".format(task_output.path)\n    elif isinstance(task_output, FileSystemTarget):\n        output_description = \"[FileSystem] {0}\".format(task_output.path)\n    elif isinstance(task_output, PostgresTarget):\n        output_description = \"[DB] {0}:{1}\".format(task_output.host, task_output.table)\n    else:\n        output_description = \"to be determined\"\n\n    return output_description", "fpath_tuple": ["luigi", "luigi", "tools", "deps.py"], "context_start_lineno": 94, "line_no": 98, "id": 239, "target_function_prompt": "def get_task_output_description(task_output):\n    '''\n    Returns a task's output as a string\n    '''\n", "function_signature": "def get_task_output_description(task_output):"}}
{"prompt": "def get_autoconfig_client(client_cache=_AUTOCONFIG_CLIENT):\n    \"\"\"\n    Creates the client as specified in the `luigi.cfg` configuration.\n    \"\"\"\n", "metadata": {"task_id": "luigi/19", "ground_truth": "    try:\n        return client_cache.client\n    except AttributeError:\n        configured_client = hdfs_config.get_configured_hdfs_client()\n        if configured_client == \"webhdfs\":\n            client_cache.client = hdfs_webhdfs_client.WebHdfsClient()\n        elif configured_client == \"hadoopcli\":\n            client_cache.client = hdfs_hadoopcli_clients.create_hadoopcli_client()\n        else:\n            raise Exception(\"Unknown hdfs client \" + configured_client)\n        return client_cache.client", "fpath_tuple": ["luigi", "luigi", "contrib", "hdfs", "clients.py"], "context_start_lineno": 32, "line_no": 36, "id": 240, "target_function_prompt": "def get_autoconfig_client(client_cache=_AUTOCONFIG_CLIENT):\n    \"\"\"\n    Creates the client as specified in the `luigi.cfg` configuration.\n    \"\"\"\n", "function_signature": "def get_autoconfig_client(client_cache=_AUTOCONFIG_CLIENT):"}}
{"prompt": "def get_config(parser=PARSER):\n    \"\"\"Get configs singleton for parser\n    \"\"\"\n", "metadata": {"task_id": "luigi/20", "ground_truth": "    parser_class = PARSERS[parser]\n    _check_parser(parser_class, parser)\n    return parser_class.instance()", "fpath_tuple": ["luigi", "luigi", "configuration", "core.py"], "context_start_lineno": 52, "line_no": 55, "id": 241, "target_function_prompt": "def get_config(parser=PARSER):\n    \"\"\"Get configs singleton for parser\n    \"\"\"\n", "function_signature": "def get_config(parser=PARSER):"}}
{"prompt": "def _partition_tasks(worker):\n    \"\"\"\n    Takes a worker and sorts out tasks based on their status.\n    Still_pending_not_ext is only used to get upstream_failure, upstream_missing_dependency and run_by_other_worker\n    \"\"\"\n", "metadata": {"task_id": "luigi/21", "ground_truth": "    task_history = worker._add_task_history\n    pending_tasks = {task for(task, status, ext) in task_history if status == 'PENDING'}\n    set_tasks = {}\n    set_tasks[\"completed\"] = {task for (task, status, ext) in task_history if status == 'DONE' and task in pending_tasks}\n    set_tasks[\"already_done\"] = {task for (task, status, ext) in task_history\n                                 if status == 'DONE' and task not in pending_tasks and task not in set_tasks[\"completed\"]}\n    set_tasks[\"ever_failed\"] = {task for (task, status, ext) in task_history if status == 'FAILED'}\n    set_tasks[\"failed\"] = set_tasks[\"ever_failed\"] - set_tasks[\"completed\"]\n    set_tasks[\"scheduling_error\"] = {task for(task, status, ext) in task_history if status == 'UNKNOWN'}\n    set_tasks[\"still_pending_ext\"] = {task for (task, status, ext) in task_history\n                                      if status == 'PENDING' and task not in set_tasks[\"ever_failed\"] and task not in set_tasks[\"completed\"] and not ext}\n    set_tasks[\"still_pending_not_ext\"] = {task for (task, status, ext) in task_history\n                                          if status == 'PENDING' and task not in set_tasks[\"ever_failed\"] and task not in set_tasks[\"completed\"] and ext}\n    set_tasks[\"run_by_other_worker\"] = set()\n    set_tasks[\"upstream_failure\"] = set()\n    set_tasks[\"upstream_missing_dependency\"] = set()\n    set_tasks[\"upstream_run_by_other_worker\"] = set()\n    set_tasks[\"upstream_scheduling_error\"] = set()\n    set_tasks[\"not_run\"] = set()\n    return set_tasks", "fpath_tuple": ["luigi", "luigi", "execution_summary.py"], "context_start_lineno": 90, "line_no": 95, "id": 242, "target_function_prompt": "def _partition_tasks(worker):\n    \"\"\"\n    Takes a worker and sorts out tasks based on their status.\n    Still_pending_not_ext is only used to get upstream_failure, upstream_missing_dependency and run_by_other_worker\n    \"\"\"\n", "function_signature": "def _partition_tasks(worker):"}}
{"prompt": "def _get_run_by_other_worker(worker):\n    \"\"\"\n    This returns a set of the tasks that are being run by other worker\n    \"\"\"\n", "metadata": {"task_id": "luigi/22", "ground_truth": "    task_sets = _get_external_workers(worker).values()\n    return functools.reduce(lambda a, b: a | b, task_sets, set())", "fpath_tuple": ["luigi", "luigi", "execution_summary.py"], "context_start_lineno": 349, "line_no": 353, "id": 243, "target_function_prompt": "def _get_run_by_other_worker(worker):\n    \"\"\"\n    This returns a set of the tasks that are being run by other worker\n    \"\"\"\n", "function_signature": "def _get_run_by_other_worker(worker):"}}
{"prompt": "def _group_tasks_by_name_and_status(task_dict):\n    \"\"\"\n    Takes a dictionary with sets of tasks grouped by their status and\n    returns a dictionary with dictionaries with an array of tasks grouped by\n    their status and task name\n    \"\"\"\n", "metadata": {"task_id": "luigi/23", "ground_truth": "    group_status = {}\n    for task in task_dict:\n        if task.task_family not in group_status:\n            group_status[task.task_family] = []\n        group_status[task.task_family].append(task)\n    return group_status", "fpath_tuple": ["luigi", "luigi", "execution_summary.py"], "context_start_lineno": 375, "line_no": 381, "id": 244, "target_function_prompt": "def _group_tasks_by_name_and_status(task_dict):\n    \"\"\"\n    Takes a dictionary with sets of tasks grouped by their status and\n    returns a dictionary with dictionaries with an array of tasks grouped by\n    their status and task name\n    \"\"\"\n", "function_signature": "def _group_tasks_by_name_and_status(task_dict):"}}
{"prompt": "def _create_one_line_summary(status_code):\n    \"\"\"\n    Given a status_code of type LuigiStatusCode which has a tuple value, returns a one line summary\n    \"\"\"\n", "metadata": {"task_id": "luigi/24", "ground_truth": "    return \"This progress looks {0} because {1}\".format(*status_code.value)", "fpath_tuple": ["luigi", "luigi", "execution_summary.py"], "context_start_lineno": 442, "line_no": 446, "id": 245, "target_function_prompt": "def _create_one_line_summary(status_code):\n    \"\"\"\n    Given a status_code of type LuigiStatusCode which has a tuple value, returns a one line summary\n    \"\"\"\n", "function_signature": "def _create_one_line_summary(status_code):"}}
{"prompt": "def _tasks_status(set_tasks):\n    \"\"\"\n    Given a grouped set of tasks, returns a LuigiStatusCode\n    \"\"\"\n", "metadata": {"task_id": "luigi/25", "ground_truth": "    if set_tasks[\"ever_failed\"]:\n        if not set_tasks[\"failed\"]:\n            return LuigiStatusCode.SUCCESS_WITH_RETRY\n        else:\n            if set_tasks[\"scheduling_error\"]:\n                return LuigiStatusCode.FAILED_AND_SCHEDULING_FAILED\n            return LuigiStatusCode.FAILED\n    elif set_tasks[\"scheduling_error\"]:\n        return LuigiStatusCode.SCHEDULING_FAILED\n    elif set_tasks[\"not_run\"]:\n        return LuigiStatusCode.NOT_RUN\n    elif set_tasks[\"still_pending_ext\"]:\n        return LuigiStatusCode.MISSING_EXT\n    else:\n        return LuigiStatusCode.SUCCESS", "fpath_tuple": ["luigi", "luigi", "execution_summary.py"], "context_start_lineno": 449, "line_no": 453, "id": 246, "target_function_prompt": "def _tasks_status(set_tasks):\n    \"\"\"\n    Given a grouped set of tasks, returns a LuigiStatusCode\n    \"\"\"\n", "function_signature": "def _tasks_status(set_tasks):"}}
{"prompt": "def summary(worker):\n    \"\"\"\n    Given a worker, return a human readable summary of what the worker have\n    done.\n    \"\"\"\n", "metadata": {"task_id": "luigi/26", "ground_truth": "    return _summary_wrap(_summary_format(_summary_dict(worker), worker))", "fpath_tuple": ["luigi", "luigi", "execution_summary.py"], "context_start_lineno": 480, "line_no": 485, "id": 247, "target_function_prompt": "def summary(worker):\n    \"\"\"\n    Given a worker, return a human readable summary of what the worker have\n    done.\n    \"\"\"\n", "function_signature": "def summary(worker):"}}
{"prompt": "def recursively_freeze(value):\n    \"\"\"\n    Recursively walks ``Mapping``s and ``list``s and converts them to ``FrozenOrderedDict`` and ``tuples``, respectively.\n    \"\"\"\n", "metadata": {"task_id": "luigi/27", "ground_truth": "    if isinstance(value, Mapping):\n        return FrozenOrderedDict(((k, recursively_freeze(v)) for k, v in value.items()))\n    elif isinstance(value, list) or isinstance(value, tuple):\n        return tuple(recursively_freeze(v) for v in value)\n    return value", "fpath_tuple": ["luigi", "luigi", "freezing.py"], "context_start_lineno": 49, "line_no": 53, "id": 248, "target_function_prompt": "def recursively_freeze(value):\n    \"\"\"\n    Recursively walks ``Mapping``s and ``list``s and converts them to ``FrozenOrderedDict`` and ``tuples``, respectively.\n    \"\"\"\n", "function_signature": "def recursively_freeze(value):"}}
{"prompt": "def send_email(subject, message, sender, recipients, image_png=None):\n    \"\"\"\n    Decides whether to send notification. Notification is cancelled if there are\n    no recipients or if stdout is onto tty or if in debug mode.\n\n    Dispatches on config value email.method.  Default is 'smtp'.\n    \"\"\"\n", "metadata": {"task_id": "luigi/28", "ground_truth": "    notifiers = {\n        'ses': send_email_ses,\n        'sendgrid': send_email_sendgrid,\n        'smtp': send_email_smtp,\n        'sns': send_email_sns,\n    }\n\n    subject = _prefix(subject)\n    if not recipients or recipients == (None,):\n        return\n\n    if _email_disabled_reason():\n        logger.info(\"Not sending email to %r because %s\",\n                    recipients, _email_disabled_reason())\n        return\n\n    # Clean the recipients lists to allow multiple email addresses, comma\n    # separated in luigi.cfg\n    recipients_tmp = []\n    for r in recipients:\n        recipients_tmp.extend([a.strip() for a in r.split(',') if a.strip()])\n\n    # Replace original recipients with the clean list\n    recipients = recipients_tmp\n\n    logger.info(\"Sending email to %r\", recipients)\n\n    # Get appropriate sender and call it to send the notification\n    email_sender = notifiers[email().method]\n    email_sender(sender, subject, message, recipients, image_png)", "fpath_tuple": ["luigi", "luigi", "notifications.py"], "context_start_lineno": 289, "line_no": 296, "id": 249, "target_function_prompt": "def send_email(subject, message, sender, recipients, image_png=None):\n    \"\"\"\n    Decides whether to send notification. Notification is cancelled if there are\n    no recipients or if stdout is onto tty or if in debug mode.\n\n    Dispatches on config value email.method.  Default is 'smtp'.\n    \"\"\"\n", "function_signature": "def send_email(subject, message, sender, recipients, image_png=None):"}}
{"prompt": "def _prefix(subject):\n    \"\"\"\n    If the config has a special prefix for emails then this function adds\n    this prefix.\n    \"\"\"\n", "metadata": {"task_id": "luigi/29", "ground_truth": "    if email().prefix:\n        return \"{} {}\".format(email().prefix, subject)\n    else:\n        return subject", "fpath_tuple": ["luigi", "luigi", "notifications.py"], "context_start_lineno": 353, "line_no": 358, "id": 250, "target_function_prompt": "def _prefix(subject):\n    \"\"\"\n    If the config has a special prefix for emails then this function adds\n    this prefix.\n    \"\"\"\n", "function_signature": "def _prefix(subject):"}}
{"prompt": "def format_task_error(headline, task, command, formatted_exception=None):\n    \"\"\"\n    Format a message body for an error email related to a luigi.task.Task\n\n    :param headline: Summary line for the message\n    :param task: `luigi.task.Task` instance where this error occurred\n    :param formatted_exception: optional string showing traceback\n\n    :return: message body\n    \"\"\"\n", "metadata": {"task_id": "luigi/30", "ground_truth": "\n    if formatted_exception:\n        formatted_exception = wrap_traceback(formatted_exception)\n    else:\n        formatted_exception = \"\"\n\n    if email().format == 'html':\n        msg_template = textwrap.dedent('''\n        <html>\n        <body>\n        <h2>{headline}</h2>\n\n        <table style=\"border-top: 1px solid black; border-bottom: 1px solid black\">\n        <thead>\n        <tr><th>name</th><td>{name}</td></tr>\n        </thead>\n        <tbody>\n        {param_rows}\n        </tbody>\n        </table>\n        </pre>\n\n        <h2>Command line</h2>\n        <pre>\n        {command}\n        </pre>\n\n        <h2>Traceback</h2>\n        {traceback}\n        </body>\n        </html>\n        ''')\n\n        str_params = task.to_str_params()\n        params = '\\n'.join('<tr><th>{}</th><td>{}</td></tr>'.format(*items) for items in str_params.items())\n        body = msg_template.format(headline=headline, name=task.task_family, param_rows=params,\n                                   command=command, traceback=formatted_exception)\n    else:\n        msg_template = textwrap.dedent('''\\\n        {headline}\n\n        Name: {name}\n\n        Parameters:\n        {params}\n\n        Command line:\n          {command}\n\n        {traceback}\n        ''')\n\n        str_params = task.to_str_params()\n        max_width = max([0] + [len(x) for x in str_params.keys()])\n        params = '\\n'.join('  {:{width}}: {}'.format(*items, width=max_width) for items in str_params.items())\n        body = msg_template.format(headline=headline, name=task.task_family, params=params,\n                                   command=command, traceback=formatted_exception)\n\n    return body", "fpath_tuple": ["luigi", "luigi", "notifications.py"], "context_start_lineno": 364, "line_no": 374, "id": 251, "target_function_prompt": "def format_task_error(headline, task, command, formatted_exception=None):\n    \"\"\"\n    Format a message body for an error email related to a luigi.task.Task\n\n    :param headline: Summary line for the message\n    :param task: `luigi.task.Task` instance where this error occurred\n    :param formatted_exception: optional string showing traceback\n\n    :return: message body\n    \"\"\"\n", "function_signature": "def format_task_error(headline, task, command, formatted_exception=None):"}}
{"prompt": "def matches_any(name, alternates):\n    \"Return a named group pattern matching list of alternates.\"\n", "metadata": {"task_id": "thonny/0", "ground_truth": "    return \"(?P<%s>\" % name + \"|\".join(alternates) + \")\"", "fpath_tuple": ["thonny", "thonny", "token_utils.py"], "context_start_lineno": 4, "line_no": 6, "id": 254, "target_function_prompt": "def matches_any(name, alternates):\n    \"Return a named group pattern matching list of alternates.\"\n", "function_signature": "def matches_any(name, alternates):"}}
{"prompt": "def get_last_child(node, skip_incorrect=True):\n    \"\"\"Returns last focusable child expression or child statement\"\"\"\n", "metadata": {"task_id": "thonny/1", "ground_truth": "\n    def ok_node(node):\n        if node is None:\n            return None\n\n        assert isinstance(node, (ast.expr, ast.stmt))\n\n        if skip_incorrect and getattr(node, \"incorrect_range\", False):\n            return None\n\n        return node\n\n    def last_ok(nodes):\n        for i in range(len(nodes) - 1, -1, -1):\n            if ok_node(nodes[i]):\n                node = nodes[i]\n                if isinstance(node, ast.Starred):\n                    if ok_node(node.value):\n                        return node.value\n                    else:\n                        return None\n                else:\n                    return nodes[i]\n\n        return None\n\n    if isinstance(node, ast.Call):\n        # TODO: take care of Python 3.5 updates (Starred etc.)\n        if hasattr(node, \"kwargs\") and ok_node(node.kwargs):\n            return node.kwargs\n        elif hasattr(node, \"starargs\") and ok_node(node.starargs):\n            return node.starargs\n        else:\n            kw_values = list(map(lambda x: x.value, node.keywords))\n            last_ok_kw = last_ok(kw_values)\n            if last_ok_kw:\n                return last_ok_kw\n            elif last_ok(node.args):\n                return last_ok(node.args)\n            else:\n                return ok_node(node.func)\n\n    elif isinstance(node, ast.BoolOp):\n        return last_ok(node.values)\n\n    elif isinstance(node, ast.BinOp):\n        if ok_node(node.right):\n            return node.right\n        else:\n            return ok_node(node.left)\n\n    elif isinstance(node, ast.Compare):\n        return last_ok(node.comparators)\n\n    elif isinstance(node, ast.UnaryOp):\n        return ok_node(node.operand)\n\n    elif isinstance(node, (ast.Tuple, ast.List, ast.Set)):\n        return last_ok(node.elts)\n\n    elif isinstance(node, ast.Dict):\n        # TODO: actually should pairwise check last value, then last key, etc.\n        return last_ok(node.values)\n\n    elif isinstance(\n        node, (ast.Index, ast.Return, ast.Assign, ast.AugAssign, ast.Yield, ast.YieldFrom)\n    ):\n        return ok_node(node.value)\n\n    elif isinstance(node, ast.Delete):\n        return last_ok(node.targets)\n\n    elif isinstance(node, ast.Expr):\n        return ok_node(node.value)\n\n    elif isinstance(node, ast.Assert):\n        if ok_node(node.msg):\n            return node.msg\n        else:\n            return ok_node(node.test)\n\n    elif isinstance(node, ast.Slice):\n        # [:]\n        if ok_node(node.step):\n            return node.step\n        elif ok_node(node.upper):\n            return node.upper\n        else:\n            return ok_node(node.lower)\n\n    elif isinstance(node, ast.ExtSlice):\n        # [:,:]\n        for dim in reversed(node.dims):\n            result = get_last_child(dim, skip_incorrect)\n            assert result is None or isinstance(result, ast.expr)\n            if result is not None:\n                return result\n        return None\n\n    elif isinstance(node, ast.Subscript):\n        result = get_last_child(node.slice, skip_incorrect)\n        if result is not None:\n            return result\n        else:\n            return node.value\n\n    elif isinstance(node, ast.Raise):\n        if ok_node(node.cause):\n            return node.cause\n        elif ok_node(node.exc):\n            return node.exc\n\n    elif isinstance(node, (ast.For, ast.While, ast.If, ast.With)):\n        return True  # There is last child, but I don't know which it will be\n\n    # TODO: pick more cases from here:\n    \"\"\"\n    (isinstance(node, (ast.IfExp, ast.ListComp, ast.SetComp, ast.DictComp, ast.GeneratorExp))\n            # or isinstance(node, ast.FunctionDef, ast.Lambda) and len(node.args.defaults) > 0\n                and (node.dest is not None or len(node.values) > 0))\n\n            #\"TODO: Import ja ImportFrom\"\n            # TODO: what about ClassDef ???\n    \"\"\"\n\n    return None", "fpath_tuple": ["thonny", "thonny", "ast_utils.py"], "context_start_lineno": 41, "line_no": 43, "id": 255, "target_function_prompt": "def get_last_child(node, skip_incorrect=True):\n    \"\"\"Returns last focusable child expression or child statement\"\"\"\n", "function_signature": "def get_last_child(node, skip_incorrect=True):"}}
{"prompt": "def _m(*names: str) -> str:\n    \"\"\"Get module names\"\"\"\n", "metadata": {"task_id": "apimd/0", "ground_truth": "    return '.'.join(s for s in names if s)", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 30, "line_no": 32, "id": 256, "target_function_prompt": "def _m(*names: str) -> str:\n    \"\"\"Get module names\"\"\"\n", "function_signature": "def _m(*names: str) -> str:"}}
{"prompt": "def _attr(obj: object, attr: str) -> object:\n    \"\"\"Nest `getattr` function.\"\"\"\n", "metadata": {"task_id": "apimd/1", "ground_truth": "    n = obj\n    for p in attr.split('.'):\n        n = getattr(n, p, None)\n        if n is None:\n            return None\n    return n", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 35, "line_no": 37, "id": 257, "target_function_prompt": "def _attr(obj: object, attr: str) -> object:\n    \"\"\"Nest `getattr` function.\"\"\"\n", "function_signature": "def _attr(obj: object, attr: str) -> object:"}}
{"prompt": "def _defaults(args: Sequence[Optional[expr]]) -> Iterator[str]:\n    \"\"\"Literals of the table.\"\"\"\n", "metadata": {"task_id": "apimd/2", "ground_truth": "    yield from (code(unparse(a)) if a is not None else \" \" for a in args)", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 45, "line_no": 47, "id": 258, "target_function_prompt": "def _defaults(args: Sequence[Optional[expr]]) -> Iterator[str]:\n    \"\"\"Literals of the table.\"\"\"\n", "function_signature": "def _defaults(args: Sequence[Optional[expr]]) -> Iterator[str]:"}}
{"prompt": "def parent(name: str, *, level: int = 1) -> str:\n    \"\"\"Get parent name with level.\"\"\"\n", "metadata": {"task_id": "apimd/3", "ground_truth": "    return name.rsplit('.', maxsplit=level)[0]", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 50, "line_no": 52, "id": 259, "target_function_prompt": "def parent(name: str, *, level: int = 1) -> str:\n    \"\"\"Get parent name with level.\"\"\"\n", "function_signature": "def parent(name: str, *, level: int = 1) -> str:"}}
{"prompt": "def is_magic(name: str) -> bool:\n    \"\"\"Check magic name.\"\"\"\n", "metadata": {"task_id": "apimd/4", "ground_truth": "    name = name.rsplit('.', maxsplit=1)[-1]\n    return name[:2] == name[-2:] == '__'", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 55, "line_no": 57, "id": 260, "target_function_prompt": "def is_magic(name: str) -> bool:\n    \"\"\"Check magic name.\"\"\"\n", "function_signature": "def is_magic(name: str) -> bool:"}}
{"prompt": "def is_public_family(name: str) -> bool:\n    \"\"\"Check the name is come from public modules or not.\"\"\"\n", "metadata": {"task_id": "apimd/5", "ground_truth": "    for n in name.split('.'):\n        # Magic name\n        if is_magic(n):\n            continue\n        # Local or private name\n        if n.startswith('_'):\n            return False\n    return True", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 61, "line_no": 63, "id": 261, "target_function_prompt": "def is_public_family(name: str) -> bool:\n    \"\"\"Check the name is come from public modules or not.\"\"\"\n", "function_signature": "def is_public_family(name: str) -> bool:"}}
{"prompt": "def walk_body(body: Sequence[stmt]) -> Iterator[stmt]:\n    \"\"\"Traverse around body and its simple definition scope.\"\"\"\n", "metadata": {"task_id": "apimd/6", "ground_truth": "    for node in body:\n        if isinstance(node, If):\n            yield from walk_body(node.body)\n            yield from walk_body(node.orelse)\n        elif isinstance(node, Try):\n            yield from walk_body(node.body)\n            for h in node.handlers:\n                yield from walk_body(h.body)\n            yield from walk_body(node.orelse)\n            yield from walk_body(node.finalbody)\n        else:\n            yield node", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 73, "line_no": 75, "id": 262, "target_function_prompt": "def walk_body(body: Sequence[stmt]) -> Iterator[stmt]:\n    \"\"\"Traverse around body and its simple definition scope.\"\"\"\n", "function_signature": "def walk_body(body: Sequence[stmt]) -> Iterator[stmt]:"}}
{"prompt": "def code(doc: str) -> str:\n    \"\"\"Escape Markdown charters from inline code.\"\"\"\n", "metadata": {"task_id": "apimd/7", "ground_truth": "    doc = doc.replace('|', '&#124;')\n    if '&' in doc:\n        return f\"<code>{doc}</code>\"\n    elif doc:\n        return f\"`{doc}`\"\n    else:\n        return \" \"", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 89, "line_no": 91, "id": 263, "target_function_prompt": "def code(doc: str) -> str:\n    \"\"\"Escape Markdown charters from inline code.\"\"\"\n", "function_signature": "def code(doc: str) -> str:"}}
{"prompt": "def esc_underscore(doc: str) -> str:\n    \"\"\"Escape underscore in names.\"\"\"\n", "metadata": {"task_id": "apimd/8", "ground_truth": "    if doc.count('_') > 1:\n        return doc.replace('_', r\"\\_\")\n    else:\n        return doc", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 100, "line_no": 102, "id": 264, "target_function_prompt": "def esc_underscore(doc: str) -> str:\n    \"\"\"Escape underscore in names.\"\"\"\n", "function_signature": "def esc_underscore(doc: str) -> str:"}}
{"prompt": "def doctest(doc: str) -> str:\n    \"\"\"Wrap doctest as markdown Python code.\"\"\"\n", "metadata": {"task_id": "apimd/9", "ground_truth": "    keep = False\n    docs = []\n    lines = doc.splitlines()\n    for i, line in enumerate(lines):\n        signed = line.startswith(\">>> \")\n        if signed:\n            if not keep:\n                docs.append(\"```python\")\n                keep = True\n        elif keep:\n            docs.append(\"```\")\n            keep = False\n        docs.append(line)\n        if signed and i == len(lines) - 1:\n            docs.append(\"```\")\n            keep = False\n    return '\\n'.join(docs)", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 108, "line_no": 110, "id": 265, "target_function_prompt": "def doctest(doc: str) -> str:\n    \"\"\"Wrap doctest as markdown Python code.\"\"\"\n", "function_signature": "def doctest(doc: str) -> str:"}}
{"prompt": "def _table_cell(items: Iterable[str]) -> str:\n    \"\"\"Make a row of table cell.\"\"\"\n", "metadata": {"task_id": "apimd/10", "ground_truth": "    return '|' + '|'.join(f\" {t} \" for t in items) + '|'", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 129, "line_no": 131, "id": 266, "target_function_prompt": "def _table_cell(items: Iterable[str]) -> str:\n    \"\"\"Make a row of table cell.\"\"\"\n", "function_signature": "def _table_cell(items: Iterable[str]) -> str:"}}
{"prompt": "def _table_split(args: Iterable[str]) -> str:\n    \"\"\"The split line of the table.\"\"\"\n", "metadata": {"task_id": "apimd/11", "ground_truth": "    return '|' + '|'.join(\":\" + '-' * (len(a) if len(a) > 3 else 3) + \":\"\n                          for a in args) + '|'", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 134, "line_no": 136, "id": 267, "target_function_prompt": "def _table_split(args: Iterable[str]) -> str:\n    \"\"\"The split line of the table.\"\"\"\n", "function_signature": "def _table_split(args: Iterable[str]) -> str:"}}
{"prompt": "def table(*titles: str, items: Iterable[Union[str, Iterable[str]]]) -> str:\n    \"\"\"Create multi-column table with the titles.\n\n    Usage:\n    >>> table('a', 'b', [['c', 'd'], ['e', 'f']])\n    | a | b |\n    |:---:|:---:|\n    | c | d |\n    | e | f |\n    \"\"\"\n", "metadata": {"task_id": "apimd/12", "ground_truth": "    return '\\n'.join([_table_cell(titles), _table_split(titles),\n                      '\\n'.join(_table_cell([n] if isinstance(n, str) else n)\n                                for n in items)]) + '\\n\\n'", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 140, "line_no": 150, "id": 268, "target_function_prompt": "def table(*titles: str, items: Iterable[Union[str, Iterable[str]]]) -> str:\n    \"\"\"Create multi-column table with the titles.\n\n    Usage:\n    >>> table('a', 'b', [['c', 'd'], ['e', 'f']])\n    | a | b |\n    |:---:|:---:|\n    | c | d |\n    | e | f |\n    \"\"\"\n", "function_signature": "def table(*titles: str, items: Iterable[Union[str, Iterable[str]]]) -> str:"}}
{"prompt": "def _type_name(obj: object) -> str:\n    \"\"\"Get type name.\"\"\"\n", "metadata": {"task_id": "apimd/13", "ground_truth": "    return type(obj).__qualname__", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 155, "line_no": 157, "id": 269, "target_function_prompt": "def _type_name(obj: object) -> str:\n    \"\"\"Get type name.\"\"\"\n", "function_signature": "def _type_name(obj: object) -> str:"}}
{"prompt": "def _e_type(*elements: Sequence[Optional[expr]]) -> str:\n    \"\"\"Get element type if type is constants.\"\"\"\n", "metadata": {"task_id": "apimd/14", "ground_truth": "    if not elements:\n        return \"\"\n    ts = []\n    for element in elements:\n        if not element:\n            return \"\"\n        t = \"\"\n        for e in element:\n            if not isinstance(e, Constant):\n                return \"\"\n            nw_t = _type_name(e.value)\n            if t and t != nw_t:\n                t = \"Any\"\n                break\n            t = nw_t\n        ts.append(t)\n    return '[' + \", \".join(ts) + ']'", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 160, "line_no": 162, "id": 270, "target_function_prompt": "def _e_type(*elements: Sequence[Optional[expr]]) -> str:\n    \"\"\"Get element type if type is constants.\"\"\"\n", "function_signature": "def _e_type(*elements: Sequence[Optional[expr]]) -> str:"}}
{"prompt": "def const_type(node: expr) -> str:\n    \"\"\"Constant type inference.\"\"\"\n", "metadata": {"task_id": "apimd/15", "ground_truth": "    if isinstance(node, Constant):\n        return _type_name(node.value)\n    elif isinstance(node, (Tuple, List, Set)):\n        return _type_name(node).lower() + _e_type(node.elts)\n    elif isinstance(node, Dict):\n        return 'dict' + _e_type(node.keys, node.values)\n    elif isinstance(node, Call) and isinstance(node.func, (Name, Attribute)):\n        func = unparse(node.func)\n        if func in chain({'bool', 'int', 'float', 'complex', 'str'},\n                         PEP585.keys(), PEP585.values()):\n            return func\n    return ANY", "fpath_tuple": ["apimd", "apimd", "parser.py"], "context_start_lineno": 181, "line_no": 183, "id": 271, "target_function_prompt": "def const_type(node: expr) -> str:\n    \"\"\"Constant type inference.\"\"\"\n", "function_signature": "def const_type(node: expr) -> str:"}}
{"prompt": "def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    encoding to use.\n    \"\"\"\n", "metadata": {"task_id": "tornado/0", "ground_truth": "    if s is None:\n        return s\n    return url_unescape(s, encoding=None, plus=False)", "fpath_tuple": ["tornado", "tornado", "routing.py"], "context_start_lineno": 707, "line_no": 714, "id": 277, "target_function_prompt": "def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    encoding to use.\n    \"\"\"\n", "function_signature": "def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:"}}
{"prompt": "def is_coroutine_function(func: Any) -> bool:\n    \"\"\"Return whether *func* is a coroutine function, i.e. a function\n    wrapped with `~.gen.coroutine`.\n\n    .. versionadded:: 4.5\n    \"\"\"\n", "metadata": {"task_id": "tornado/1", "ground_truth": "    return getattr(func, \"__tornado_coroutine__\", False)", "fpath_tuple": ["tornado", "tornado", "gen.py"], "context_start_lineno": 272, "line_no": 278, "id": 278, "target_function_prompt": "def is_coroutine_function(func: Any) -> bool:\n    \"\"\"Return whether *func* is a coroutine function, i.e. a function\n    wrapped with `~.gen.coroutine`.\n\n    .. versionadded:: 4.5\n    \"\"\"\n", "function_signature": "def is_coroutine_function(func: Any) -> bool:"}}
{"prompt": "def multi(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Runs multiple asynchronous operations in parallel.\n\n    ``children`` may either be a list or a dict whose values are\n    yieldable objects. ``multi()`` returns a new yieldable\n    object that resolves to a parallel structure containing their\n    results. If ``children`` is a list, the result is a list of\n    results in the same order; if it is a dict, the result is a dict\n    with the same keys.\n\n    That is, ``results = yield multi(list_of_futures)`` is equivalent\n    to::\n\n    results = []\n    for future in list_of_futures:\n    results.append(yield future)\n\n    If any children raise exceptions, ``multi()`` will raise the first\n    one. All others will be logged, unless they are of types\n    contained in the ``quiet_exceptions`` argument.\n\n    In a ``yield``-based coroutine, it is not normally necessary to\n    call this function directly, since the coroutine runner will\n    do it automatically when a list or dict is yielded. However,\n    it is necessary in ``await``-based coroutines, or to pass\n    the ``quiet_exceptions`` argument.\n\n    This function is available under the names ``multi()`` and ``Multi()``\n    for historical reasons.\n\n    Cancelling a `.Future` returned by ``multi()`` does not cancel its\n    children. `asyncio.gather` is similar to ``multi()``, but it does\n    cancel its children.\n\n    .. versionchanged:: 4.2\n    If multiple yieldables fail, any exceptions after the first\n    (which is raised) will be logged. Added the ``quiet_exceptions``\n    argument to suppress this logging for selected exception types.\n\n    .. versionchanged:: 4.3\n    Replaced the class ``Multi`` and the function ``multi_future``\n    with a unified function ``multi``. Added support for yieldables\n    other than ``YieldPoint`` and `.Future`.\n\n    \"\"\"\n", "metadata": {"task_id": "tornado/2", "ground_truth": "    return multi_future(children, quiet_exceptions=quiet_exceptions)", "fpath_tuple": ["tornado", "tornado", "gen.py"], "context_start_lineno": 433, "line_no": 481, "id": 279, "target_function_prompt": "def multi(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Runs multiple asynchronous operations in parallel.\n\n    ``children`` may either be a list or a dict whose values are\n    yieldable objects. ``multi()`` returns a new yieldable\n    object that resolves to a parallel structure containing their\n    results. If ``children`` is a list, the result is a list of\n    results in the same order; if it is a dict, the result is a dict\n    with the same keys.\n\n    That is, ``results = yield multi(list_of_futures)`` is equivalent\n    to::\n\n    results = []\n    for future in list_of_futures:\n    results.append(yield future)\n\n    If any children raise exceptions, ``multi()`` will raise the first\n    one. All others will be logged, unless they are of types\n    contained in the ``quiet_exceptions`` argument.\n\n    In a ``yield``-based coroutine, it is not normally necessary to\n    call this function directly, since the coroutine runner will\n    do it automatically when a list or dict is yielded. However,\n    it is necessary in ``await``-based coroutines, or to pass\n    the ``quiet_exceptions`` argument.\n\n    This function is available under the names ``multi()`` and ``Multi()``\n    for historical reasons.\n\n    Cancelling a `.Future` returned by ``multi()`` does not cancel its\n    children. `asyncio.gather` is similar to ``multi()``, but it does\n    cancel its children.\n\n    .. versionchanged:: 4.2\n    If multiple yieldables fail, any exceptions after the first\n    (which is raised) will be logged. Added the ``quiet_exceptions``\n    argument to suppress this logging for selected exception types.\n\n    .. versionchanged:: 4.3\n    Replaced the class ``Multi`` and the function ``multi_future``\n    with a unified function ``multi``. Added support for yieldables\n    other than ``YieldPoint`` and `.Future`.\n\n    \"\"\"\n", "function_signature": "def multi(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":"}}
{"prompt": "def multi_future(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Wait for multiple asynchronous futures in parallel.\n\n    Since Tornado 6.0, this function is exactly the same as `multi`.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.2\n    If multiple ``Futures`` fail, any exceptions after the first (which is\n    raised) will be logged. Added the ``quiet_exceptions``\n    argument to suppress this logging for selected exception types.\n\n    .. deprecated:: 4.3\n    Use `multi` instead.\n    \"\"\"\n", "metadata": {"task_id": "tornado/3", "ground_truth": "    if isinstance(children, dict):\n        keys = list(children.keys())  # type: Optional[List]\n        children_seq = children.values()  # type: Iterable\n    else:\n        keys = None\n        children_seq = children\n    children_futs = list(map(convert_yielded, children_seq))\n    assert all(is_future(i) or isinstance(i, _NullFuture) for i in children_futs)\n    unfinished_children = set(children_futs)\n\n    future = _create_future()\n    if not children_futs:\n        future_set_result_unless_cancelled(future, {} if keys is not None else [])\n\n    def callback(fut: Future) -> None:\n        unfinished_children.remove(fut)\n        if not unfinished_children:\n            result_list = []\n            for f in children_futs:\n                try:\n                    result_list.append(f.result())\n                except Exception as e:\n                    if future.done():\n                        if not isinstance(e, quiet_exceptions):\n                            app_log.error(\n                                \"Multiple exceptions in yield list\", exc_info=True\n                            )\n                    else:\n                        future_set_exc_info(future, sys.exc_info())\n            if not future.done():\n                if keys is not None:\n                    future_set_result_unless_cancelled(\n                        future, dict(zip(keys, result_list))\n                    )\n                else:\n                    future_set_result_unless_cancelled(future, result_list)\n\n    listening = set()  # type: Set[Future]\n    for f in children_futs:\n        if f not in listening:\n            listening.add(f)\n            future_add_done_callback(f, callback)\n    return future", "fpath_tuple": ["tornado", "tornado", "gen.py"], "context_start_lineno": 487, "line_no": 505, "id": 280, "target_function_prompt": "def multi_future(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Wait for multiple asynchronous futures in parallel.\n\n    Since Tornado 6.0, this function is exactly the same as `multi`.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.2\n    If multiple ``Futures`` fail, any exceptions after the first (which is\n    raised) will be logged. Added the ``quiet_exceptions``\n    argument to suppress this logging for selected exception types.\n\n    .. deprecated:: 4.3\n    Use `multi` instead.\n    \"\"\"\n", "function_signature": "def multi_future(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":"}}
{"prompt": "def maybe_future(x: Any) -> Future:\n    \"\"\"Converts ``x`` into a `.Future`.\n\n    If ``x`` is already a `.Future`, it is simply returned; otherwise\n    it is wrapped in a new `.Future`.  This is suitable for use as\n    ``result = yield gen.maybe_future(f())`` when you don't know whether\n    ``f()`` returns a `.Future` or not.\n\n    .. deprecated:: 4.3\n    This function only handles ``Futures``, not other yieldable objects.\n    Instead of `maybe_future`, check for the non-future result types\n    you expect (often just ``None``), and ``yield`` anything unknown.\n    \"\"\"\n", "metadata": {"task_id": "tornado/4", "ground_truth": "    if is_future(x):\n        return x\n    else:\n        fut = _create_future()\n        fut.set_result(x)\n        return fut", "fpath_tuple": ["tornado", "tornado", "gen.py"], "context_start_lineno": 550, "line_no": 563, "id": 281, "target_function_prompt": "def maybe_future(x: Any) -> Future:\n    \"\"\"Converts ``x`` into a `.Future`.\n\n    If ``x`` is already a `.Future`, it is simply returned; otherwise\n    it is wrapped in a new `.Future`.  This is suitable for use as\n    ``result = yield gen.maybe_future(f())`` when you don't know whether\n    ``f()`` returns a `.Future` or not.\n\n    .. deprecated:: 4.3\n    This function only handles ``Futures``, not other yieldable objects.\n    Instead of `maybe_future`, check for the non-future result types\n    you expect (often just ``None``), and ``yield`` anything unknown.\n    \"\"\"\n", "function_signature": "def maybe_future(x: Any) -> Future:"}}
{"prompt": "def with_timeout(\n    timeout: Union[float, datetime.timedelta],\n    future: _Yieldable,\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> Future:\n    \"\"\"Wraps a `.Future` (or other yieldable object) in a timeout.\n\n    Raises `tornado.util.TimeoutError` if the input future does not\n    complete before ``timeout``, which may be specified in any form\n    allowed by `.IOLoop.add_timeout` (i.e. a `datetime.timedelta` or\n    an absolute time relative to `.IOLoop.time`)\n\n    If the wrapped `.Future` fails after it has timed out, the exception\n    will be logged unless it is either of a type contained in\n    ``quiet_exceptions`` (which may be an exception type or a sequence of\n    types), or an ``asyncio.CancelledError``.\n\n    The wrapped `.Future` is not canceled when the timeout expires,\n    permitting it to be reused. `asyncio.wait_for` is similar to this\n    function but it does cancel the wrapped `.Future` on timeout.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.1\n    Added the ``quiet_exceptions`` argument and the logging of unhandled\n    exceptions.\n\n    .. versionchanged:: 4.4\n    Added support for yieldable objects other than `.Future`.\n\n    .. versionchanged:: 6.0.3\n    ``asyncio.CancelledError`` is now always considered \"quiet\".\n\n    \"\"\"\n", "metadata": {"task_id": "tornado/5", "ground_truth": "    # It's tempting to optimize this by cancelling the input future on timeout\n    # instead of creating a new one, but A) we can't know if we are the only\n    # one waiting on the input future, so cancelling it might disrupt other\n    # callers and B) concurrent futures can only be cancelled while they are\n    # in the queue, so cancellation cannot reliably bound our waiting time.\n    future_converted = convert_yielded(future)\n    result = _create_future()\n    chain_future(future_converted, result)\n    io_loop = IOLoop.current()\n\n    def error_callback(future: Future) -> None:\n        try:\n            future.result()\n        except asyncio.CancelledError:\n            pass\n        except Exception as e:\n            if not isinstance(e, quiet_exceptions):\n                app_log.error(\n                    \"Exception in Future %r after timeout\", future, exc_info=True\n                )\n\n    def timeout_callback() -> None:\n        if not result.done():\n            result.set_exception(TimeoutError(\"Timeout\"))\n        # In case the wrapped future goes on to fail, log it.\n        future_add_done_callback(future_converted, error_callback)\n\n    timeout_handle = io_loop.add_timeout(timeout, timeout_callback)\n    if isinstance(future_converted, Future):\n        # We know this future will resolve on the IOLoop, so we don't\n        # need the extra thread-safety of IOLoop.add_future (and we also\n        # don't care about StackContext here.\n        future_add_done_callback(\n            future_converted, lambda future: io_loop.remove_timeout(timeout_handle)\n        )\n    else:\n        # concurrent.futures.Futures may resolve on any thread, so we\n        # need to route them back to the IOLoop.\n        io_loop.add_future(\n            future_converted, lambda future: io_loop.remove_timeout(timeout_handle)\n        )\n    return result", "fpath_tuple": ["tornado", "tornado", "gen.py"], "context_start_lineno": 571, "line_no": 605, "id": 282, "target_function_prompt": "def with_timeout(\n    timeout: Union[float, datetime.timedelta],\n    future: _Yieldable,\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> Future:\n    \"\"\"Wraps a `.Future` (or other yieldable object) in a timeout.\n\n    Raises `tornado.util.TimeoutError` if the input future does not\n    complete before ``timeout``, which may be specified in any form\n    allowed by `.IOLoop.add_timeout` (i.e. a `datetime.timedelta` or\n    an absolute time relative to `.IOLoop.time`)\n\n    If the wrapped `.Future` fails after it has timed out, the exception\n    will be logged unless it is either of a type contained in\n    ``quiet_exceptions`` (which may be an exception type or a sequence of\n    types), or an ``asyncio.CancelledError``.\n\n    The wrapped `.Future` is not canceled when the timeout expires,\n    permitting it to be reused. `asyncio.wait_for` is similar to this\n    function but it does cancel the wrapped `.Future` on timeout.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.1\n    Added the ``quiet_exceptions`` argument and the logging of unhandled\n    exceptions.\n\n    .. versionchanged:: 4.4\n    Added support for yieldable objects other than `.Future`.\n\n    .. versionchanged:: 6.0.3\n    ``asyncio.CancelledError`` is now always considered \"quiet\".\n\n    \"\"\"\n", "function_signature": "def with_timeout(\n    timeout: Union[float, datetime.timedelta],\n    future: _Yieldable,\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> Future:"}}
{"prompt": "def convert_yielded(yielded: _Yieldable) -> Future:\n    \"\"\"Convert a yielded object into a `.Future`.\n\n    The default implementation accepts lists, dictionaries, and\n    Futures. This has the side effect of starting any coroutines that\n    did not start themselves, similar to `asyncio.ensure_future`.\n\n    If the `~functools.singledispatch` library is available, this function\n    may be extended to support additional types. For example::\n\n    @convert_yielded.register(asyncio.Future)\n    def _(asyncio_future):\n    return tornado.platform.asyncio.to_tornado_future(asyncio_future)\n\n    .. versionadded:: 4.1\n\n    \"\"\"\n", "metadata": {"task_id": "tornado/6", "ground_truth": "    if yielded is None or yielded is moment:\n        return moment\n    elif yielded is _null_future:\n        return _null_future\n    elif isinstance(yielded, (list, dict)):\n        return multi(yielded)  # type: ignore\n    elif is_future(yielded):\n        return typing.cast(Future, yielded)\n    elif isawaitable(yielded):\n        return _wrap_awaitable(yielded)  # type: ignore\n    else:\n        raise BadYieldError(\"yielded unknown object %r\" % (yielded,))", "fpath_tuple": ["tornado", "tornado", "gen.py"], "context_start_lineno": 840, "line_no": 857, "id": 283, "target_function_prompt": "def convert_yielded(yielded: _Yieldable) -> Future:\n    \"\"\"Convert a yielded object into a `.Future`.\n\n    The default implementation accepts lists, dictionaries, and\n    Futures. This has the side effect of starting any coroutines that\n    did not start themselves, similar to `asyncio.ensure_future`.\n\n    If the `~functools.singledispatch` library is available, this function\n    may be extended to support additional types. For example::\n\n    @convert_yielded.register(asyncio.Future)\n    def _(asyncio_future):\n    return tornado.platform.asyncio.to_tornado_future(asyncio_future)\n\n    .. versionadded:: 4.1\n\n    \"\"\"\n", "function_signature": "def convert_yielded(yielded: _Yieldable) -> Future:"}}
{"prompt": "def bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n    \"\"\"Binds a server socket to an available port on localhost.\n\n    Returns a tuple (socket, port).\n\n    .. versionchanged:: 4.4\n    Always binds to ``127.0.0.1`` without resolving the name\n    ``localhost``.\n    \"\"\"\n", "metadata": {"task_id": "tornado/7", "ground_truth": "    sock = netutil.bind_sockets(\n        0, \"127.0.0.1\", family=socket.AF_INET, reuse_port=reuse_port\n    )[0]\n    port = sock.getsockname()[1]\n    return sock, port", "fpath_tuple": ["tornado", "tornado", "testing.py"], "context_start_lineno": 51, "line_no": 60, "id": 284, "target_function_prompt": "def bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n    \"\"\"Binds a server socket to an available port on localhost.\n\n    Returns a tuple (socket, port).\n\n    .. versionchanged:: 4.4\n    Always binds to ``127.0.0.1`` without resolving the name\n    ``localhost``.\n    \"\"\"\n", "function_signature": "def bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:"}}
{"prompt": "def get_async_test_timeout() -> float:\n    \"\"\"Get the global timeout setting for async tests.\n\n    Returns a float, the timeout in seconds.\n\n    .. versionadded:: 3.1\n    \"\"\"\n", "metadata": {"task_id": "tornado/8", "ground_truth": "    env = os.environ.get(\"ASYNC_TEST_TIMEOUT\")\n    if env is not None:\n        try:\n            return float(env)\n        except ValueError:\n            pass\n    return 5", "fpath_tuple": ["tornado", "tornado", "testing.py"], "context_start_lineno": 67, "line_no": 74, "id": 285, "target_function_prompt": "def get_async_test_timeout() -> float:\n    \"\"\"Get the global timeout setting for async tests.\n\n    Returns a float, the timeout in seconds.\n\n    .. versionadded:: 3.1\n    \"\"\"\n", "function_signature": "def get_async_test_timeout() -> float:"}}
{"prompt": "def gen_test(  # noqa: F811\n    func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n    timeout: Optional[float] = None,\n) -> Union[\n    Callable[..., None],\n    Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],\n]:\n    \"\"\"Testing equivalent of ``@gen.coroutine``, to be applied to test methods.\n\n    ``@gen.coroutine`` cannot be used on tests because the `.IOLoop` is not\n    already running.  ``@gen_test`` should be applied to test methods\n    on subclasses of `AsyncTestCase`.\n\n    Example::\n\n    class MyTest(AsyncHTTPTestCase):\n    @gen_test\n    def test_something(self):\n    response = yield self.http_client.fetch(self.get_url('/'))\n\n    By default, ``@gen_test`` times out after 5 seconds. The timeout may be\n    overridden globally with the ``ASYNC_TEST_TIMEOUT`` environment variable,\n    or for each test with the ``timeout`` keyword argument::\n\n    class MyTest(AsyncHTTPTestCase):\n    @gen_test(timeout=10)\n    def test_something_slow(self):\n    response = yield self.http_client.fetch(self.get_url('/'))\n\n    Note that ``@gen_test`` is incompatible with `AsyncTestCase.stop`,\n    `AsyncTestCase.wait`, and `AsyncHTTPTestCase.fetch`. Use ``yield\n    self.http_client.fetch(self.get_url())`` as shown above instead.\n\n    .. versionadded:: 3.1\n    The ``timeout`` argument and ``ASYNC_TEST_TIMEOUT`` environment\n    variable.\n\n    .. versionchanged:: 4.0\n    The wrapper now passes along ``*args, **kwargs`` so it can be used\n    on functions with arguments.\n\n    \"\"\"\n", "metadata": {"task_id": "tornado/9", "ground_truth": "    if timeout is None:\n        timeout = get_async_test_timeout()\n\n    def wrap(f: Callable[..., Union[Generator, \"Coroutine\"]]) -> Callable[..., None]:\n        # Stack up several decorators to allow us to access the generator\n        # object itself.  In the innermost wrapper, we capture the generator\n        # and save it in an attribute of self.  Next, we run the wrapped\n        # function through @gen.coroutine.  Finally, the coroutine is\n        # wrapped again to make it synchronous with run_sync.\n        #\n        # This is a good case study arguing for either some sort of\n        # extensibility in the gen decorators or cancellation support.\n        @functools.wraps(f)\n        def pre_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> Union[Generator, Coroutine]\n            # Type comments used to avoid pypy3 bug.\n            result = f(self, *args, **kwargs)\n            if isinstance(result, Generator) or inspect.iscoroutine(result):\n                self._test_generator = result\n            else:\n                self._test_generator = None\n            return result\n\n        if inspect.iscoroutinefunction(f):\n            coro = pre_coroutine\n        else:\n            coro = gen.coroutine(pre_coroutine)\n\n        @functools.wraps(coro)\n        def post_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> None\n            try:\n                return self.io_loop.run_sync(\n                    functools.partial(coro, self, *args, **kwargs), timeout=timeout\n                )\n            except TimeoutError as e:\n                # run_sync raises an error with an unhelpful traceback.\n                # If the underlying generator is still running, we can throw the\n                # exception back into it so the stack trace is replaced by the\n                # point where the test is stopped. The only reason the generator\n                # would not be running would be if it were cancelled, which means\n                # a native coroutine, so we can rely on the cr_running attribute.\n                if self._test_generator is not None and getattr(\n                    self._test_generator, \"cr_running\", True\n                ):\n                    self._test_generator.throw(type(e), e)\n                    # In case the test contains an overly broad except\n                    # clause, we may get back here.\n                # Coroutine was stopped or didn't raise a useful stack trace,\n                # so re-raise the original exception which is better than nothing.\n                raise\n\n        return post_coroutine\n\n    if func is not None:\n        # Used like:\n        #     @gen_test\n        #     def f(self):\n        #         pass\n        return wrap(func)\n    else:\n        # Used like @gen_test(timeout=10)\n        return wrap", "fpath_tuple": ["tornado", "tornado", "testing.py"], "context_start_lineno": 524, "line_no": 566, "id": 286, "target_function_prompt": "def gen_test(  # noqa: F811\n    func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n    timeout: Optional[float] = None,\n) -> Union[\n    Callable[..., None],\n    Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],\n]:\n    \"\"\"Testing equivalent of ``@gen.coroutine``, to be applied to test methods.\n\n    ``@gen.coroutine`` cannot be used on tests because the `.IOLoop` is not\n    already running.  ``@gen_test`` should be applied to test methods\n    on subclasses of `AsyncTestCase`.\n\n    Example::\n\n    class MyTest(AsyncHTTPTestCase):\n    @gen_test\n    def test_something(self):\n    response = yield self.http_client.fetch(self.get_url('/'))\n\n    By default, ``@gen_test`` times out after 5 seconds. The timeout may be\n    overridden globally with the ``ASYNC_TEST_TIMEOUT`` environment variable,\n    or for each test with the ``timeout`` keyword argument::\n\n    class MyTest(AsyncHTTPTestCase):\n    @gen_test(timeout=10)\n    def test_something_slow(self):\n    response = yield self.http_client.fetch(self.get_url('/'))\n\n    Note that ``@gen_test`` is incompatible with `AsyncTestCase.stop`,\n    `AsyncTestCase.wait`, and `AsyncHTTPTestCase.fetch`. Use ``yield\n    self.http_client.fetch(self.get_url())`` as shown above instead.\n\n    .. versionadded:: 3.1\n    The ``timeout`` argument and ``ASYNC_TEST_TIMEOUT`` environment\n    variable.\n\n    .. versionchanged:: 4.0\n    The wrapper now passes along ``*args, **kwargs`` so it can be used\n    on functions with arguments.\n\n    \"\"\"\n", "function_signature": "def gen_test(  # noqa: F811\n    func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n    timeout: Optional[float] = None,\n) -> Union[\n    Callable[..., None],\n    Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],\n]:"}}
{"prompt": "def _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth signature for the given request.\n\n    See http://oauth.net/core/1.0/#signing_process\n    \"\"\"\n", "metadata": {"task_id": "tornado/10", "ground_truth": "    parts = urllib.parse.urlparse(url)\n    scheme, netloc, path = parts[:3]\n    normalized_url = scheme.lower() + \"://\" + netloc.lower() + path\n\n    base_elems = []\n    base_elems.append(method.upper())\n    base_elems.append(normalized_url)\n    base_elems.append(\n        \"&\".join(\n            \"%s=%s\" % (k, _oauth_escape(str(v))) for k, v in sorted(parameters.items())\n        )\n    )\n    base_string = \"&\".join(_oauth_escape(e) for e in base_elems)\n\n    key_elems = [escape.utf8(consumer_token[\"secret\"])]\n    key_elems.append(escape.utf8(token[\"secret\"] if token else \"\"))\n    key = b\"&\".join(key_elems)\n\n    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)\n    return binascii.b2a_base64(hash.digest())[:-1]", "fpath_tuple": ["tornado", "tornado", "auth.py"], "context_start_lineno": 1101, "line_no": 1112, "id": 288, "target_function_prompt": "def _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth signature for the given request.\n\n    See http://oauth.net/core/1.0/#signing_process\n    \"\"\"\n", "function_signature": "def _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:"}}
{"prompt": "def _oauth10a_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth 1.0a signature for the given request.\n\n    See http://oauth.net/core/1.0a/#signing_process\n    \"\"\"\n", "metadata": {"task_id": "tornado/11", "ground_truth": "    parts = urllib.parse.urlparse(url)\n    scheme, netloc, path = parts[:3]\n    normalized_url = scheme.lower() + \"://\" + netloc.lower() + path\n\n    base_elems = []\n    base_elems.append(method.upper())\n    base_elems.append(normalized_url)\n    base_elems.append(\n        \"&\".join(\n            \"%s=%s\" % (k, _oauth_escape(str(v))) for k, v in sorted(parameters.items())\n        )\n    )\n\n    base_string = \"&\".join(_oauth_escape(e) for e in base_elems)\n    key_elems = [escape.utf8(urllib.parse.quote(consumer_token[\"secret\"], safe=\"~\"))]\n    key_elems.append(\n        escape.utf8(urllib.parse.quote(token[\"secret\"], safe=\"~\") if token else \"\")\n    )\n    key = b\"&\".join(key_elems)\n\n    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)\n    return binascii.b2a_base64(hash.digest())[:-1]", "fpath_tuple": ["tornado", "tornado", "auth.py"], "context_start_lineno": 1134, "line_no": 1145, "id": 289, "target_function_prompt": "def _oauth10a_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth 1.0a signature for the given request.\n\n    See http://oauth.net/core/1.0a/#signing_process\n    \"\"\"\n", "function_signature": "def _oauth10a_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:"}}
{"prompt": "def to_tornado_future(asyncio_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n\n    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n    Tornado ``Futures`` have been merged with `asyncio.Future`,\n    so this method is now a no-op.\n    \"\"\"\n", "metadata": {"task_id": "tornado/12", "ground_truth": "    return asyncio_future", "fpath_tuple": ["tornado", "tornado", "platform", "asyncio.py"], "context_start_lineno": 337, "line_no": 346, "id": 290, "target_function_prompt": "def to_tornado_future(asyncio_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n\n    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n    Tornado ``Futures`` have been merged with `asyncio.Future`,\n    so this method is now a no-op.\n    \"\"\"\n", "function_signature": "def to_tornado_future(asyncio_future: asyncio.Future) -> asyncio.Future:"}}
{"prompt": "def bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,\n) -> List[socket.socket]:\n    \"\"\"Creates listening sockets bound to the given port and address.\n\n    Returns a list of socket objects (multiple sockets are returned if\n    the given address maps to multiple IP addresses, which is most common\n    for mixed IPv4 and IPv6 use).\n\n    Address may be either an IP address or hostname.  If it's a hostname,\n    the server will listen on all IP addresses associated with the\n    name.  Address may be an empty string or None to listen on all\n    available interfaces.  Family may be set to either `socket.AF_INET`\n    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n    both will be used if available.\n\n    The ``backlog`` argument has the same meaning as for\n    `socket.listen() <socket.socket.listen>`.\n\n    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like\n    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.\n\n    ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket\n    in the list. If your platform doesn't support this option ValueError will\n    be raised.\n    \"\"\"\n", "metadata": {"task_id": "tornado/13", "ground_truth": "    if reuse_port and not hasattr(socket, \"SO_REUSEPORT\"):\n        raise ValueError(\"the platform doesn't support SO_REUSEPORT\")\n\n    sockets = []\n    if address == \"\":\n        address = None\n    if not socket.has_ipv6 and family == socket.AF_UNSPEC:\n        # Python can be compiled with --disable-ipv6, which causes\n        # operations on AF_INET6 sockets to fail, but does not\n        # automatically exclude those results from getaddrinfo\n        # results.\n        # http://bugs.python.org/issue16208\n        family = socket.AF_INET\n    if flags is None:\n        flags = socket.AI_PASSIVE\n    bound_port = None\n    unique_addresses = set()  # type: set\n    for res in sorted(\n        socket.getaddrinfo(address, port, family, socket.SOCK_STREAM, 0, flags),\n        key=lambda x: x[0],\n    ):\n        if res in unique_addresses:\n            continue\n\n        unique_addresses.add(res)\n\n        af, socktype, proto, canonname, sockaddr = res\n        if (\n            sys.platform == \"darwin\"\n            and address == \"localhost\"\n            and af == socket.AF_INET6\n            and sockaddr[3] != 0\n        ):\n            # Mac OS X includes a link-local address fe80::1%lo0 in the\n            # getaddrinfo results for 'localhost'.  However, the firewall\n            # doesn't understand that this is a local address and will\n            # prompt for access (often repeatedly, due to an apparent\n            # bug in its ability to remember granting access to an\n            # application). Skip these addresses.\n            continue\n        try:\n            sock = socket.socket(af, socktype, proto)\n        except socket.error as e:\n            if errno_from_exception(e) == errno.EAFNOSUPPORT:\n                continue\n            raise\n        if os.name != \"nt\":\n            try:\n                sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            except socket.error as e:\n                if errno_from_exception(e) != errno.ENOPROTOOPT:\n                    # Hurd doesn't support SO_REUSEADDR.\n                    raise\n        if reuse_port:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        if af == socket.AF_INET6:\n            # On linux, ipv6 sockets accept ipv4 too by default,\n            # but this makes it impossible to bind to both\n            # 0.0.0.0 in ipv4 and :: in ipv6.  On other systems,\n            # separate sockets *must* be used to listen for both ipv4\n            # and ipv6.  For consistency, always disable ipv4 on our\n            # ipv6 sockets and use a separate ipv4 socket when needed.\n            #\n            # Python 2.x on windows doesn't have IPPROTO_IPV6.\n            if hasattr(socket, \"IPPROTO_IPV6\"):\n                sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1)\n\n        # automatic port allocation with port=None\n        # should bind on the same port on IPv4 and IPv6\n        host, requested_port = sockaddr[:2]\n        if requested_port == 0 and bound_port is not None:\n            sockaddr = tuple([host, bound_port] + list(sockaddr[2:]))\n\n        sock.setblocking(False)\n        try:\n            sock.bind(sockaddr)\n        except OSError as e:\n            if (\n                errno_from_exception(e) == errno.EADDRNOTAVAIL\n                and address == \"localhost\"\n                and sockaddr[0] == \"::1\"\n            ):\n                # On some systems (most notably docker with default\n                # configurations), ipv6 is partially disabled:\n                # socket.has_ipv6 is true, we can create AF_INET6\n                # sockets, and getaddrinfo(\"localhost\", ...,\n                # AF_PASSIVE) resolves to ::1, but we get an error\n                # when binding.\n                #\n                # Swallow the error, but only for this specific case.\n                # If EADDRNOTAVAIL occurs in other situations, it\n                # might be a real problem like a typo in a\n                # configuration.\n                sock.close()\n                continue\n            else:\n                raise\n        bound_port = sock.getsockname()[1]\n        sock.listen(backlog)\n        sockets.append(sock)\n    return sockets", "fpath_tuple": ["tornado", "tornado", "netutil.py"], "context_start_lineno": 54, "line_no": 85, "id": 291, "target_function_prompt": "def bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,\n) -> List[socket.socket]:\n    \"\"\"Creates listening sockets bound to the given port and address.\n\n    Returns a list of socket objects (multiple sockets are returned if\n    the given address maps to multiple IP addresses, which is most common\n    for mixed IPv4 and IPv6 use).\n\n    Address may be either an IP address or hostname.  If it's a hostname,\n    the server will listen on all IP addresses associated with the\n    name.  Address may be an empty string or None to listen on all\n    available interfaces.  Family may be set to either `socket.AF_INET`\n    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n    both will be used if available.\n\n    The ``backlog`` argument has the same meaning as for\n    `socket.listen() <socket.socket.listen>`.\n\n    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like\n    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.\n\n    ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket\n    in the list. If your platform doesn't support this option ValueError will\n    be raised.\n    \"\"\"\n", "function_signature": "def bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,\n) -> List[socket.socket]:"}}
{"prompt": "def add_accept_handler(\n    sock: socket.socket, callback: Callable[[socket.socket, Any], None]\n) -> Callable[[], None]:\n    \"\"\"Adds an `.IOLoop` event handler to accept new connections on ``sock``.\n\n    When a connection is accepted, ``callback(connection, address)`` will\n    be run (``connection`` is a socket object, and ``address`` is the\n    address of the other end of the connection).  Note that this signature\n    is different from the ``callback(fd, events)`` signature used for\n    `.IOLoop` handlers.\n\n    A callable is returned which, when called, will remove the `.IOLoop`\n    event handler and stop processing further incoming connections.\n\n    .. versionchanged:: 5.0\n    The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. versionchanged:: 5.0\n    A callable is returned (``None`` was returned before).\n    \"\"\"\n", "metadata": {"task_id": "tornado/14", "ground_truth": "    io_loop = IOLoop.current()\n    removed = [False]\n\n    def accept_handler(fd: socket.socket, events: int) -> None:\n        # More connections may come in while we're handling callbacks;\n        # to prevent starvation of other tasks we must limit the number\n        # of connections we accept at a time.  Ideally we would accept\n        # up to the number of connections that were waiting when we\n        # entered this method, but this information is not available\n        # (and rearranging this method to call accept() as many times\n        # as possible before running any callbacks would have adverse\n        # effects on load balancing in multiprocess configurations).\n        # Instead, we use the (default) listen backlog as a rough\n        # heuristic for the number of connections we can reasonably\n        # accept at once.\n        for i in range(_DEFAULT_BACKLOG):\n            if removed[0]:\n                # The socket was probably closed\n                return\n            try:\n                connection, address = sock.accept()\n            except BlockingIOError:\n                # EWOULDBLOCK indicates we have accepted every\n                # connection that is available.\n                return\n            except ConnectionAbortedError:\n                # ECONNABORTED indicates that there was a connection\n                # but it was closed while still in the accept queue.\n                # (observed on FreeBSD).\n                continue\n            callback(connection, address)\n\n    def remove_handler() -> None:\n        io_loop.remove_handler(sock)\n        removed[0] = True\n\n    io_loop.add_handler(sock, accept_handler, IOLoop.READ)\n    return remove_handler", "fpath_tuple": ["tornado", "tornado", "netutil.py"], "context_start_lineno": 225, "line_no": 245, "id": 293, "target_function_prompt": "def add_accept_handler(\n    sock: socket.socket, callback: Callable[[socket.socket, Any], None]\n) -> Callable[[], None]:\n    \"\"\"Adds an `.IOLoop` event handler to accept new connections on ``sock``.\n\n    When a connection is accepted, ``callback(connection, address)`` will\n    be run (``connection`` is a socket object, and ``address`` is the\n    address of the other end of the connection).  Note that this signature\n    is different from the ``callback(fd, events)`` signature used for\n    `.IOLoop` handlers.\n\n    A callable is returned which, when called, will remove the `.IOLoop`\n    event handler and stop processing further incoming connections.\n\n    .. versionchanged:: 5.0\n    The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. versionchanged:: 5.0\n    A callable is returned (``None`` was returned before).\n    \"\"\"\n", "function_signature": "def add_accept_handler(\n    sock: socket.socket, callback: Callable[[socket.socket, Any], None]\n) -> Callable[[], None]:"}}
{"prompt": "def is_valid_ip(ip: str) -> bool:\n    \"\"\"Returns ``True`` if the given string is a well-formed IP address.\n\n    Supports IPv4 and IPv6.\n    \"\"\"\n", "metadata": {"task_id": "tornado/15", "ground_truth": "    if not ip or \"\\x00\" in ip:\n        # getaddrinfo resolves empty strings to localhost, and truncates\n        # on zero bytes.\n        return False\n    try:\n        res = socket.getaddrinfo(\n            ip, 0, socket.AF_UNSPEC, socket.SOCK_STREAM, 0, socket.AI_NUMERICHOST\n        )\n        return bool(res)\n    except socket.gaierror as e:\n        if e.args[0] == socket.EAI_NONAME:\n            return False\n        raise\n    return True", "fpath_tuple": ["tornado", "tornado", "netutil.py"], "context_start_lineno": 285, "line_no": 290, "id": 294, "target_function_prompt": "def is_valid_ip(ip: str) -> bool:\n    \"\"\"Returns ``True`` if the given string is a well-formed IP address.\n\n    Supports IPv4 and IPv6.\n    \"\"\"\n", "function_signature": "def is_valid_ip(ip: str) -> bool:"}}
{"prompt": "def ssl_options_to_context(\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext]\n) -> ssl.SSLContext:\n    \"\"\"Try to convert an ``ssl_options`` dictionary to an\n    `~ssl.SSLContext` object.\n\n    The ``ssl_options`` dictionary contains keywords to be passed to\n    `ssl.wrap_socket`.  In Python 2.7.9+, `ssl.SSLContext` objects can\n    be used instead.  This function converts the dict form to its\n    `~ssl.SSLContext` equivalent, and may be used when a component which\n    accepts both forms needs to upgrade to the `~ssl.SSLContext` version\n    to use features like SNI or NPN.\n    \"\"\"\n", "metadata": {"task_id": "tornado/16", "ground_truth": "    if isinstance(ssl_options, ssl.SSLContext):\n        return ssl_options\n    assert isinstance(ssl_options, dict)\n    assert all(k in _SSL_CONTEXT_KEYWORDS for k in ssl_options), ssl_options\n    # Can't use create_default_context since this interface doesn't\n    # tell us client vs server.\n    context = ssl.SSLContext(ssl_options.get(\"ssl_version\", ssl.PROTOCOL_SSLv23))\n    if \"certfile\" in ssl_options:\n        context.load_cert_chain(\n            ssl_options[\"certfile\"], ssl_options.get(\"keyfile\", None)\n        )\n    if \"cert_reqs\" in ssl_options:\n        context.verify_mode = ssl_options[\"cert_reqs\"]\n    if \"ca_certs\" in ssl_options:\n        context.load_verify_locations(ssl_options[\"ca_certs\"])\n    if \"ciphers\" in ssl_options:\n        context.set_ciphers(ssl_options[\"ciphers\"])\n    if hasattr(ssl, \"OP_NO_COMPRESSION\"):\n        # Disable TLS compression to avoid CRIME and related attacks.\n        # This constant depends on openssl version 1.0.\n        # TODO: Do we need to do this ourselves or can we trust\n        # the defaults?\n        context.options |= ssl.OP_NO_COMPRESSION\n    return context", "fpath_tuple": ["tornado", "tornado", "netutil.py"], "context_start_lineno": 554, "line_no": 567, "id": 295, "target_function_prompt": "def ssl_options_to_context(\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext]\n) -> ssl.SSLContext:\n    \"\"\"Try to convert an ``ssl_options`` dictionary to an\n    `~ssl.SSLContext` object.\n\n    The ``ssl_options`` dictionary contains keywords to be passed to\n    `ssl.wrap_socket`.  In Python 2.7.9+, `ssl.SSLContext` objects can\n    be used instead.  This function converts the dict form to its\n    `~ssl.SSLContext` equivalent, and may be used when a component which\n    accepts both forms needs to upgrade to the `~ssl.SSLContext` version\n    to use features like SNI or NPN.\n    \"\"\"\n", "function_signature": "def ssl_options_to_context(\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext]\n) -> ssl.SSLContext:"}}
{"prompt": "def ssl_wrap_socket(\n    socket: socket.socket,\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_hostname: Optional[str] = None,\n    **kwargs: Any\n) -> ssl.SSLSocket:\n    \"\"\"Returns an ``ssl.SSLSocket`` wrapping the given socket.\n\n    ``ssl_options`` may be either an `ssl.SSLContext` object or a\n    dictionary (as accepted by `ssl_options_to_context`).  Additional\n    keyword arguments are passed to ``wrap_socket`` (either the\n    `~ssl.SSLContext` method or the `ssl` module function as\n    appropriate).\n    \"\"\"\n", "metadata": {"task_id": "tornado/17", "ground_truth": "    context = ssl_options_to_context(ssl_options)\n    if ssl.HAS_SNI:\n        # In python 3.4, wrap_socket only accepts the server_hostname\n        # argument if HAS_SNI is true.\n        # TODO: add a unittest (python added server-side SNI support in 3.4)\n        # In the meantime it can be manually tested with\n        # python3 -m tornado.httpclient https://sni.velox.ch\n        return context.wrap_socket(socket, server_hostname=server_hostname, **kwargs)\n    else:\n        return context.wrap_socket(socket, **kwargs)", "fpath_tuple": ["tornado", "tornado", "netutil.py"], "context_start_lineno": 593, "line_no": 607, "id": 296, "target_function_prompt": "def ssl_wrap_socket(\n    socket: socket.socket,\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_hostname: Optional[str] = None,\n    **kwargs: Any\n) -> ssl.SSLSocket:\n    \"\"\"Returns an ``ssl.SSLSocket`` wrapping the given socket.\n\n    ``ssl_options`` may be either an `ssl.SSLContext` object or a\n    dictionary (as accepted by `ssl_options_to_context`).  Additional\n    keyword arguments are passed to ``wrap_socket`` (either the\n    `~ssl.SSLContext` method or the `ssl` module function as\n    appropriate).\n    \"\"\"\n", "function_signature": "def ssl_wrap_socket(\n    socket: socket.socket,\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_hostname: Optional[str] = None,\n    **kwargs: Any\n) -> ssl.SSLSocket:"}}
{"prompt": "def xhtml_escape(value: Union[str, bytes]) -> str:\n    \"\"\"Escapes a string so it is valid within HTML or XML.\n\n    Escapes the characters ``<``, ``>``, ``\"``, ``'``, and ``&``.\n    When used in attribute values the escaped strings must be enclosed\n    in quotes.\n\n    .. versionchanged:: 3.2\n\n    Added the single quote to the list of escaped characters.\n    \"\"\"\n", "metadata": {"task_id": "tornado/18", "ground_truth": "    return _XHTML_ESCAPE_RE.sub(\n        lambda match: _XHTML_ESCAPE_DICT[match.group(0)], to_basestring(value)\n    )", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 42, "line_no": 53, "id": 297, "target_function_prompt": "def xhtml_escape(value: Union[str, bytes]) -> str:\n    \"\"\"Escapes a string so it is valid within HTML or XML.\n\n    Escapes the characters ``<``, ``>``, ``\"``, ``'``, and ``&``.\n    When used in attribute values the escaped strings must be enclosed\n    in quotes.\n\n    .. versionchanged:: 3.2\n\n    Added the single quote to the list of escaped characters.\n    \"\"\"\n", "function_signature": "def xhtml_escape(value: Union[str, bytes]) -> str:"}}
{"prompt": "def xhtml_unescape(value: Union[str, bytes]) -> str:\n    \"\"\"Un-escapes an XML-escaped string.\"\"\"\n", "metadata": {"task_id": "tornado/19", "ground_truth": "    return re.sub(r\"&(#?)(\\w+?);\", _convert_entity, _unicode(value))", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 58, "line_no": 60, "id": 298, "target_function_prompt": "def xhtml_unescape(value: Union[str, bytes]) -> str:\n    \"\"\"Un-escapes an XML-escaped string.\"\"\"\n", "function_signature": "def xhtml_unescape(value: Union[str, bytes]) -> str:"}}
{"prompt": "def json_encode(value: Any) -> str:\n    \"\"\"JSON-encodes the given Python object.\"\"\"\n", "metadata": {"task_id": "tornado/20", "ground_truth": "    # JSON permits but does not require forward slashes to be escaped.\n    # This is useful when json data is emitted in a <script> tag\n    # in HTML, as it prevents </script> tags from prematurely terminating\n    # the JavaScript.  Some json libraries do this escaping by default,\n    # although python's standard library does not, so we do it here.\n    # http://stackoverflow.com/questions/1580647/json-why-are-forward-slashes-escaped\n    return json.dumps(value).replace(\"</\", \"<\\\\/\")", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 66, "line_no": 68, "id": 299, "target_function_prompt": "def json_encode(value: Any) -> str:\n    \"\"\"JSON-encodes the given Python object.\"\"\"\n", "function_signature": "def json_encode(value: Any) -> str:"}}
{"prompt": "def json_decode(value: Union[str, bytes]) -> Any:\n    \"\"\"Returns Python objects for the given JSON string.\n\n    Supports both `str` and `bytes` inputs.\n    \"\"\"\n", "metadata": {"task_id": "tornado/21", "ground_truth": "    return json.loads(to_basestring(value))", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 77, "line_no": 82, "id": 300, "target_function_prompt": "def json_decode(value: Union[str, bytes]) -> Any:\n    \"\"\"Returns Python objects for the given JSON string.\n\n    Supports both `str` and `bytes` inputs.\n    \"\"\"\n", "function_signature": "def json_decode(value: Union[str, bytes]) -> Any:"}}
{"prompt": "def squeeze(value: str) -> str:\n    \"\"\"Replace all sequences of whitespace chars with a single space.\"\"\"\n", "metadata": {"task_id": "tornado/22", "ground_truth": "    return re.sub(r\"[\\x00-\\x20]+\", \" \", value).strip()", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 85, "line_no": 87, "id": 301, "target_function_prompt": "def squeeze(value: str) -> str:\n    \"\"\"Replace all sequences of whitespace chars with a single space.\"\"\"\n", "function_signature": "def squeeze(value: str) -> str:"}}
{"prompt": "def url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n\n    If ``plus`` is true (the default), spaces will be represented\n    as \"+\" instead of \"%20\".  This is appropriate for query strings\n    but not for the path component of a URL.  Note that this default\n    is the reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n    The ``plus`` argument\n    \"\"\"\n", "metadata": {"task_id": "tornado/23", "ground_truth": "    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 90, "line_no": 101, "id": 302, "target_function_prompt": "def url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n\n    If ``plus`` is true (the default), spaces will be represented\n    as \"+\" instead of \"%20\".  This is appropriate for query strings\n    but not for the path component of a URL.  Note that this default\n    is the reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n    The ``plus`` argument\n    \"\"\"\n", "function_signature": "def url_escape(value: Union[str, bytes], plus: bool = True) -> str:"}}
{"prompt": "def url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:\n    \"\"\"Decodes the given value from a URL.\n\n    The argument may be either a byte or unicode string.\n\n    If encoding is None, the result will be a byte string.  Otherwise,\n    the result is a unicode string in the specified encoding.\n\n    If ``plus`` is true (the default), plus signs will be interpreted\n    as spaces (literal plus signs must be represented as \"%2B\").  This\n    is appropriate for query strings and form-encoded values but not\n    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n    The ``plus`` argument\n    \"\"\"\n", "metadata": {"task_id": "tornado/24", "ground_truth": "    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")\n        return urllib.parse.unquote_to_bytes(value)\n    else:\n        unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n        return unquote(to_basestring(value), encoding=encoding)", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 117, "line_no": 136, "id": 303, "target_function_prompt": "def url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:\n    \"\"\"Decodes the given value from a URL.\n\n    The argument may be either a byte or unicode string.\n\n    If encoding is None, the result will be a byte string.  Otherwise,\n    the result is a unicode string in the specified encoding.\n\n    If ``plus`` is true (the default), plus signs will be interpreted\n    as spaces (literal plus signs must be represented as \"%2B\").  This\n    is appropriate for query strings and form-encoded values but not\n    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n    The ``plus`` argument\n    \"\"\"\n", "function_signature": "def url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:"}}
{"prompt": "def parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,\n    but takes bytes and returns the values as byte strings.\n\n    Keys still become type str (interpreted as latin1 in python3!)\n    because it's too painful to keep them as byte strings in\n    python3 and in practice they're nearly always ascii anyway.\n    \"\"\"\n", "metadata": {"task_id": "tornado/25", "ground_truth": "    # This is gross, but python3 doesn't give us another way.\n    # Latin1 is the universal donor of character encodings.\n    if isinstance(qs, bytes):\n        qs = qs.decode(\"latin1\")\n    result = urllib.parse.parse_qs(\n        qs, keep_blank_values, strict_parsing, encoding=\"latin1\", errors=\"strict\"\n    )\n    encoded = {}\n    for k, v in result.items():\n        encoded[k] = [i.encode(\"latin1\") for i in v]\n    return encoded", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 146, "line_no": 156, "id": 304, "target_function_prompt": "def parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,\n    but takes bytes and returns the values as byte strings.\n\n    Keys still become type str (interpreted as latin1 in python3!)\n    because it's too painful to keep them as byte strings in\n    python3 and in practice they're nearly always ascii anyway.\n    \"\"\"\n", "function_signature": "def parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:"}}
{"prompt": "def utf8(value: Union[None, str, bytes]) -> Optional[bytes]:\n    \"\"\"Converts a string argument to a byte string.\n\n    If the argument is already a byte string or None, it is returned unchanged.\n    Otherwise it must be a unicode string and is encoded as utf8.\n    \"\"\"\n", "metadata": {"task_id": "tornado/26", "ground_truth": "    if isinstance(value, _UTF8_TYPES):\n        return value\n    if not isinstance(value, unicode_type):\n        raise TypeError(\"Expected bytes, unicode, or None; got %r\" % type(value))\n    return value.encode(\"utf-8\")", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 187, "line_no": 193, "id": 305, "target_function_prompt": "def utf8(value: Union[None, str, bytes]) -> Optional[bytes]:\n    \"\"\"Converts a string argument to a byte string.\n\n    If the argument is already a byte string or None, it is returned unchanged.\n    Otherwise it must be a unicode string and is encoded as utf8.\n    \"\"\"\n", "function_signature": "def utf8(value: Union[None, str, bytes]) -> Optional[bytes]:"}}
{"prompt": "def to_unicode(value: Union[None, str, bytes]) -> Optional[str]:\n    \"\"\"Converts a string argument to a unicode string.\n\n    If the argument is already a unicode string or None, it is returned\n    unchanged.  Otherwise it must be a byte string and is decoded as utf8.\n    \"\"\"\n", "metadata": {"task_id": "tornado/27", "ground_truth": "    if isinstance(value, _TO_UNICODE_TYPES):\n        return value\n    if not isinstance(value, bytes):\n        raise TypeError(\"Expected bytes, unicode, or None; got %r\" % type(value))\n    return value.decode(\"utf-8\")", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 218, "line_no": 224, "id": 306, "target_function_prompt": "def to_unicode(value: Union[None, str, bytes]) -> Optional[str]:\n    \"\"\"Converts a string argument to a unicode string.\n\n    If the argument is already a unicode string or None, it is returned\n    unchanged.  Otherwise it must be a byte string and is decoded as utf8.\n    \"\"\"\n", "function_signature": "def to_unicode(value: Union[None, str, bytes]) -> Optional[str]:"}}
{"prompt": "def recursive_unicode(obj: Any) -> Any:\n    \"\"\"Walks a simple data structure, converting byte strings to unicode.\n\n    Supports lists, tuples, and dictionaries.\n    \"\"\"\n", "metadata": {"task_id": "tornado/28", "ground_truth": "    if isinstance(obj, dict):\n        return dict(\n            (recursive_unicode(k), recursive_unicode(v)) for (k, v) in obj.items()\n        )\n    elif isinstance(obj, list):\n        return list(recursive_unicode(i) for i in obj)\n    elif isinstance(obj, tuple):\n        return tuple(recursive_unicode(i) for i in obj)\n    elif isinstance(obj, bytes):\n        return to_unicode(obj)\n    else:\n        return obj", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 241, "line_no": 246, "id": 307, "target_function_prompt": "def recursive_unicode(obj: Any) -> Any:\n    \"\"\"Walks a simple data structure, converting byte strings to unicode.\n\n    Supports lists, tuples, and dictionaries.\n    \"\"\"\n", "function_signature": "def recursive_unicode(obj: Any) -> Any:"}}
{"prompt": "def linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n    taking the link as an argument and returning the extra text\n    e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n    or::\n\n    def extra_params_cb(url):\n    if url.startswith(\"http://example.com\"):\n    return 'class=\"internal\"'\n    else:\n    return 'class=\"external\" rel=\"nofollow\"'\n    linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n    this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n    linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n    \"mailto\"])``. It is very unsafe to include protocols such as\n    ``javascript``.\n    \"\"\"\n", "metadata": {"task_id": "tornado/29", "ground_truth": "    if extra_params and not callable(extra_params):\n        extra_params = \" \" + extra_params.strip()\n\n    def make_link(m: typing.Match) -> str:\n        url = m.group(1)\n        proto = m.group(2)\n        if require_protocol and not proto:\n            return url  # not protocol, no linkify\n\n        if proto and proto not in permitted_protocols:\n            return url  # bad protocol, no linkify\n\n        href = m.group(1)\n        if not proto:\n            href = \"http://\" + href  # no proto specified, use http\n\n        if callable(extra_params):\n            params = \" \" + extra_params(href).strip()\n        else:\n            params = extra_params\n\n        # clip long urls. max_len is just an approximation\n        max_len = 30\n        if shorten and len(url) > max_len:\n            before_clip = url\n            if proto:\n                proto_len = len(proto) + 1 + len(m.group(3) or \"\")  # +1 for :\n            else:\n                proto_len = 0\n\n            parts = url[proto_len:].split(\"/\")\n            if len(parts) > 1:\n                # Grab the whole host part plus the first bit of the path\n                # The path is usually not that interesting once shortened\n                # (no more slug, etc), so it really just provides a little\n                # extra indication of shortening.\n                url = (\n                    url[:proto_len]\n                    + parts[0]\n                    + \"/\"\n                    + parts[1][:8].split(\"?\")[0].split(\".\")[0]\n                )\n\n            if len(url) > max_len * 1.5:  # still too long\n                url = url[:max_len]\n\n            if url != before_clip:\n                amp = url.rfind(\"&\")\n                # avoid splitting html char entities\n                if amp > max_len - 5:\n                    url = url[:amp]\n                url += \"...\"\n\n                if len(url) >= len(before_clip):\n                    url = before_clip\n                else:\n                    # full url is visible on mouse-over (for those who don't\n                    # have a status bar, such as Safari by default)\n                    params += ' title=\"%s\"' % href\n\n        return u'<a href=\"%s\"%s>%s</a>' % (href, params, url)\n\n    # First HTML-escape so that our strings are all safe.\n    # The regex is modified to avoid character entites other than &amp; so\n    # that we won't pick up &quot;, etc.\n    text = _unicode(xhtml_escape(text))\n    return _URL_RE.sub(make_link, text)", "fpath_tuple": ["tornado", "tornado", "escape.py"], "context_start_lineno": 274, "line_no": 310, "id": 308, "target_function_prompt": "def linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n    taking the link as an argument and returning the extra text\n    e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n    or::\n\n    def extra_params_cb(url):\n    if url.startswith(\"http://example.com\"):\n    return 'class=\"internal\"'\n    else:\n    return 'class=\"external\" rel=\"nofollow\"'\n    linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n    this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n    linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n    \"mailto\"])``. It is very unsafe to include protocols such as\n    ``javascript``.\n    \"\"\"\n", "function_signature": "def linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:"}}
{"prompt": "def _normalize_header(name: str) -> str:\n    \"\"\"Map a header name to Http-Header-Case.\n\n    >>> _normalize_header(\"coNtent-TYPE\")\n    'Content-Type'\n    \"\"\"\n", "metadata": {"task_id": "tornado/30", "ground_truth": "    return \"-\".join([w.capitalize() for w in name.split(\"-\")])", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 66, "line_no": 72, "id": 309, "target_function_prompt": "def _normalize_header(name: str) -> str:\n    \"\"\"Map a header name to Http-Header-Case.\n\n    >>> _normalize_header(\"coNtent-TYPE\")\n    'Content-Type'\n    \"\"\"\n", "function_signature": "def _normalize_header(name: str) -> str:"}}
{"prompt": "def url_concat(\n    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:\n    \"\"\"Concatenate url and arguments regardless of whether\n    url has existing query parameters.\n\n    ``args`` may be either a dictionary or a list of key-value pairs\n    (the latter allows for multiple values with the same key.\n\n    >>> url_concat(\"http://example.com/foo\", dict(c=\"d\"))\n    'http://example.com/foo?c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", dict(c=\"d\"))\n    'http://example.com/foo?a=b&c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", [(\"c\", \"d\"), (\"c\", \"d2\")])\n    'http://example.com/foo?a=b&c=d&c=d2'\n    \"\"\"\n", "metadata": {"task_id": "tornado/31", "ground_truth": "    if args is None:\n        return url\n    parsed_url = urlparse(url)\n    if isinstance(args, dict):\n        parsed_query = parse_qsl(parsed_url.query, keep_blank_values=True)\n        parsed_query.extend(args.items())\n    elif isinstance(args, list) or isinstance(args, tuple):\n        parsed_query = parse_qsl(parsed_url.query, keep_blank_values=True)\n        parsed_query.extend(args)\n    else:\n        err = \"'args' parameter should be dict, list or tuple. Not {0}\".format(\n            type(args)\n        )\n        raise TypeError(err)\n    final_query = urlencode(parsed_query)\n    url = urlunparse(\n        (\n            parsed_url[0],\n            parsed_url[1],\n            parsed_url[2],\n            parsed_url[3],\n            final_query,\n            parsed_url[5],\n        )\n    )\n    return url", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 609, "line_no": 628, "id": 310, "target_function_prompt": "def url_concat(\n    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:\n    \"\"\"Concatenate url and arguments regardless of whether\n    url has existing query parameters.\n\n    ``args`` may be either a dictionary or a list of key-value pairs\n    (the latter allows for multiple values with the same key.\n\n    >>> url_concat(\"http://example.com/foo\", dict(c=\"d\"))\n    'http://example.com/foo?c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", dict(c=\"d\"))\n    'http://example.com/foo?a=b&c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", [(\"c\", \"d\"), (\"c\", \"d2\")])\n    'http://example.com/foo?a=b&c=d&c=d2'\n    \"\"\"\n", "function_signature": "def url_concat(\n    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:"}}
{"prompt": "def _parse_request_range(\n    range_header: str,\n) -> Optional[Tuple[Optional[int], Optional[int]]]:\n    \"\"\"Parses a Range header.\n\n    Returns either ``None`` or tuple ``(start, end)``.\n    Note that while the HTTP headers use inclusive byte positions,\n    this method returns indexes suitable for use in slices.\n\n    >>> start, end = _parse_request_range(\"bytes=1-2\")\n    >>> start, end\n    (1, 3)\n    >>> [0, 1, 2, 3, 4][start:end]\n    [1, 2]\n    >>> _parse_request_range(\"bytes=6-\")\n    (6, None)\n    >>> _parse_request_range(\"bytes=-6\")\n    (-6, None)\n    >>> _parse_request_range(\"bytes=-0\")\n    (None, 0)\n    >>> _parse_request_range(\"bytes=\")\n    (None, None)\n    >>> _parse_request_range(\"foo=42\")\n    >>> _parse_request_range(\"bytes=1-2,6-10\")\n\n    Note: only supports one range (ex, ``bytes=1-2,6-10`` is not allowed).\n\n    See [0] for the details of the range header.\n\n    [0]: http://greenbytes.de/tech/webdav/draft-ietf-httpbis-p5-range-latest.html#byte.ranges\n    \"\"\"\n", "metadata": {"task_id": "tornado/32", "ground_truth": "    unit, _, value = range_header.partition(\"=\")\n    unit, value = unit.strip(), value.strip()\n    if unit != \"bytes\":\n        return None\n    start_b, _, end_b = value.partition(\"-\")\n    try:\n        start = _int_or_none(start_b)\n        end = _int_or_none(end_b)\n    except ValueError:\n        return None\n    if end is not None:\n        if start is None:\n            if end != 0:\n                start = -end\n                end = None\n        else:\n            end += 1\n    return (start, end)", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 670, "line_no": 701, "id": 311, "target_function_prompt": "def _parse_request_range(\n    range_header: str,\n) -> Optional[Tuple[Optional[int], Optional[int]]]:\n    \"\"\"Parses a Range header.\n\n    Returns either ``None`` or tuple ``(start, end)``.\n    Note that while the HTTP headers use inclusive byte positions,\n    this method returns indexes suitable for use in slices.\n\n    >>> start, end = _parse_request_range(\"bytes=1-2\")\n    >>> start, end\n    (1, 3)\n    >>> [0, 1, 2, 3, 4][start:end]\n    [1, 2]\n    >>> _parse_request_range(\"bytes=6-\")\n    (6, None)\n    >>> _parse_request_range(\"bytes=-6\")\n    (-6, None)\n    >>> _parse_request_range(\"bytes=-0\")\n    (None, 0)\n    >>> _parse_request_range(\"bytes=\")\n    (None, None)\n    >>> _parse_request_range(\"foo=42\")\n    >>> _parse_request_range(\"bytes=1-2,6-10\")\n\n    Note: only supports one range (ex, ``bytes=1-2,6-10`` is not allowed).\n\n    See [0] for the details of the range header.\n\n    [0]: http://greenbytes.de/tech/webdav/draft-ietf-httpbis-p5-range-latest.html#byte.ranges\n    \"\"\"\n", "function_signature": "def _parse_request_range(\n    range_header: str,\n) -> Optional[Tuple[Optional[int], Optional[int]]]:"}}
{"prompt": "def _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:\n    \"\"\"Returns a suitable Content-Range header:\n\n    >>> print(_get_content_range(None, 1, 4))\n    bytes 0-0/4\n    >>> print(_get_content_range(1, 3, 4))\n    bytes 1-2/4\n    >>> print(_get_content_range(None, None, 4))\n    bytes 0-3/4\n    \"\"\"\n", "metadata": {"task_id": "tornado/33", "ground_truth": "    start = start or 0\n    end = (end or total) - 1\n    return \"bytes %s-%s/%s\" % (start, end, total)", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 721, "line_no": 731, "id": 312, "target_function_prompt": "def _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:\n    \"\"\"Returns a suitable Content-Range header:\n\n    >>> print(_get_content_range(None, 1, 4))\n    bytes 0-0/4\n    >>> print(_get_content_range(1, 3, 4))\n    bytes 1-2/4\n    >>> print(_get_content_range(None, None, 4))\n    bytes 0-3/4\n    \"\"\"\n", "function_signature": "def _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:"}}
{"prompt": "def format_timestamp(\n    ts: Union[int, float, tuple, time.struct_time, datetime.datetime]\n) -> str:\n    \"\"\"Formats a timestamp in the format used by HTTP.\n\n    The argument may be a numeric timestamp as returned by `time.time`,\n    a time tuple as returned by `time.gmtime`, or a `datetime.datetime`\n    object.\n\n    >>> format_timestamp(1359312200)\n    'Sun, 27 Jan 2013 18:43:20 GMT'\n    \"\"\"\n", "metadata": {"task_id": "tornado/34", "ground_truth": "    if isinstance(ts, (int, float)):\n        time_num = ts\n    elif isinstance(ts, (tuple, time.struct_time)):\n        time_num = calendar.timegm(ts)\n    elif isinstance(ts, datetime.datetime):\n        time_num = calendar.timegm(ts.utctimetuple())\n    else:\n        raise TypeError(\"unknown timestamp type: %r\" % ts)\n    return email.utils.formatdate(time_num, usegmt=True)", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 850, "line_no": 862, "id": 313, "target_function_prompt": "def format_timestamp(\n    ts: Union[int, float, tuple, time.struct_time, datetime.datetime]\n) -> str:\n    \"\"\"Formats a timestamp in the format used by HTTP.\n\n    The argument may be a numeric timestamp as returned by `time.time`,\n    a time tuple as returned by `time.gmtime`, or a `datetime.datetime`\n    object.\n\n    >>> format_timestamp(1359312200)\n    'Sun, 27 Jan 2013 18:43:20 GMT'\n    \"\"\"\n", "function_signature": "def format_timestamp(\n    ts: Union[int, float, tuple, time.struct_time, datetime.datetime]\n) -> str:"}}
{"prompt": "def parse_request_start_line(line: str) -> RequestStartLine:\n    \"\"\"Returns a (method, path, version) tuple for an HTTP 1.x request line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_request_start_line(\"GET /foo HTTP/1.1\")\n    RequestStartLine(method='GET', path='/foo', version='HTTP/1.1')\n    \"\"\"\n", "metadata": {"task_id": "tornado/35", "ground_truth": "    try:\n        method, path, version = line.split(\" \")\n    except ValueError:\n        # https://tools.ietf.org/html/rfc7230#section-3.1.1\n        # invalid request-line SHOULD respond with a 400 (Bad Request)\n        raise HTTPInputError(\"Malformed HTTP request line\")\n    if not _http_version_re.match(version):\n        raise HTTPInputError(\n            \"Malformed HTTP version in HTTP Request-Line: %r\" % version\n        )\n    return RequestStartLine(method, path, version)", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 881, "line_no": 889, "id": 314, "target_function_prompt": "def parse_request_start_line(line: str) -> RequestStartLine:\n    \"\"\"Returns a (method, path, version) tuple for an HTTP 1.x request line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_request_start_line(\"GET /foo HTTP/1.1\")\n    RequestStartLine(method='GET', path='/foo', version='HTTP/1.1')\n    \"\"\"\n", "function_signature": "def parse_request_start_line(line: str) -> RequestStartLine:"}}
{"prompt": "def parse_response_start_line(line: str) -> ResponseStartLine:\n    \"\"\"Returns a (version, code, reason) tuple for an HTTP 1.x response line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_response_start_line(\"HTTP/1.1 200 OK\")\n    ResponseStartLine(version='HTTP/1.1', code=200, reason='OK')\n    \"\"\"\n", "metadata": {"task_id": "tornado/36", "ground_truth": "    line = native_str(line)\n    match = _http_response_line_re.match(line)\n    if not match:\n        raise HTTPInputError(\"Error parsing response start line\")\n    return ResponseStartLine(match.group(1), int(match.group(2)), match.group(3))", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 910, "line_no": 918, "id": 315, "target_function_prompt": "def parse_response_start_line(line: str) -> ResponseStartLine:\n    \"\"\"Returns a (version, code, reason) tuple for an HTTP 1.x response line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_response_start_line(\"HTTP/1.1 200 OK\")\n    ResponseStartLine(version='HTTP/1.1', code=200, reason='OK')\n    \"\"\"\n", "function_signature": "def parse_response_start_line(line: str) -> ResponseStartLine:"}}
{"prompt": "def _parse_header(line: str) -> Tuple[str, Dict[str, str]]:\n    r\"\"\"Parse a Content-type like header.\n\n    Return the main content-type and a dictionary of options.\n\n    >>> d = \"form-data; foo=\\\"b\\\\\\\\a\\\\\\\"r\\\"; file*=utf-8''T%C3%A4st\"\n    >>> ct, d = _parse_header(d)\n    >>> ct\n    'form-data'\n    >>> d['file'] == r'T\\u00e4st'.encode('ascii').decode('unicode_escape')\n    True\n    >>> d['foo']\n    'b\\\\a\"r'\n    \"\"\"\n", "metadata": {"task_id": "tornado/37", "ground_truth": "    parts = _parseparam(\";\" + line)\n    key = next(parts)\n    # decode_params treats first argument special, but we already stripped key\n    params = [(\"Dummy\", \"value\")]\n    for p in parts:\n        i = p.find(\"=\")\n        if i >= 0:\n            name = p[:i].strip().lower()\n            value = p[i + 1 :].strip()\n            params.append((name, native_str(value)))\n    decoded_params = email.utils.decode_params(params)\n    decoded_params.pop(0)  # get rid of the dummy again\n    pdict = {}\n    for name, decoded_value in decoded_params:\n        value = email.utils.collapse_rfc2231_value(decoded_value)\n        if len(value) >= 2 and value[0] == '\"' and value[-1] == '\"':\n            value = value[1:-1]\n        pdict[name] = value\n    return key, pdict", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 946, "line_no": 960, "id": 316, "target_function_prompt": "def _parse_header(line: str) -> Tuple[str, Dict[str, str]]:\n    r\"\"\"Parse a Content-type like header.\n\n    Return the main content-type and a dictionary of options.\n\n    >>> d = \"form-data; foo=\\\"b\\\\\\\\a\\\\\\\"r\\\"; file*=utf-8''T%C3%A4st\"\n    >>> ct, d = _parse_header(d)\n    >>> ct\n    'form-data'\n    >>> d['file'] == r'T\\u00e4st'.encode('ascii').decode('unicode_escape')\n    True\n    >>> d['foo']\n    'b\\\\a\"r'\n    \"\"\"\n", "function_signature": "def _parse_header(line: str) -> Tuple[str, Dict[str, str]]:"}}
{"prompt": "def _encode_header(key: str, pdict: Dict[str, str]) -> str:\n    \"\"\"Inverse of _parse_header.\n\n    >>> _encode_header('permessage-deflate',\n    ...     {'client_max_window_bits': 15, 'client_no_context_takeover': None})\n    'permessage-deflate; client_max_window_bits=15; client_no_context_takeover'\n    \"\"\"\n", "metadata": {"task_id": "tornado/38", "ground_truth": "    if not pdict:\n        return key\n    out = [key]\n    # Sort the parameters just to make it easy to test.\n    for k, v in sorted(pdict.items()):\n        if v is None:\n            out.append(k)\n        else:\n            # TODO: quote if necessary.\n            out.append(\"%s=%s\" % (k, v))\n    return \"; \".join(out)", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 981, "line_no": 988, "id": 317, "target_function_prompt": "def _encode_header(key: str, pdict: Dict[str, str]) -> str:\n    \"\"\"Inverse of _parse_header.\n\n    >>> _encode_header('permessage-deflate',\n    ...     {'client_max_window_bits': 15, 'client_no_context_takeover': None})\n    'permessage-deflate; client_max_window_bits=15; client_no_context_takeover'\n    \"\"\"\n", "function_signature": "def _encode_header(key: str, pdict: Dict[str, str]) -> str:"}}
{"prompt": "def encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n", "metadata": {"task_id": "tornado/39", "ground_truth": "    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 1001, "line_no": 1010, "id": 318, "target_function_prompt": "def encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n", "function_signature": "def encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:"}}
{"prompt": "def split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Returns ``(host, port)`` tuple from ``netloc``.\n\n    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n", "metadata": {"task_id": "tornado/40", "ground_truth": "    match = _netloc_re.match(netloc)\n    if match:\n        host = match.group(1)\n        port = int(match.group(2))  # type: Optional[int]\n    else:\n        host = netloc\n        port = None\n    return (host, port)", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 1027, "line_no": 1034, "id": 319, "target_function_prompt": "def split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Returns ``(host, port)`` tuple from ``netloc``.\n\n    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n", "function_signature": "def split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:"}}
{"prompt": "def qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n", "metadata": {"task_id": "tornado/41", "ground_truth": "    for k, vs in qs.items():\n        for v in vs:\n            yield (k, v)", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 1044, "line_no": 1049, "id": 320, "target_function_prompt": "def qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n", "function_signature": "def qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:"}}
{"prompt": "def _unquote_cookie(s: str) -> str:\n    \"\"\"Handle double quotes and escaping in cookie values.\n\n    This method is copied verbatim from the Python 3.5 standard\n    library (http.cookies._unquote) so we don't have to depend on\n    non-public interfaces.\n    \"\"\"\n", "metadata": {"task_id": "tornado/42", "ground_truth": "    # If there aren't any doublequotes,\n    # then there can't be any special characters.  See RFC 2109.\n    if s is None or len(s) < 2:\n        return s\n    if s[0] != '\"' or s[-1] != '\"':\n        return s\n\n    # We have to assume that we must decode this string.\n    # Down to work.\n\n    # Remove the \"s\n    s = s[1:-1]\n\n    # Check for special sequences.  Examples:\n    #    \\012 --> \\n\n    #    \\\"   --> \"\n    #\n    i = 0\n    n = len(s)\n    res = []\n    while 0 <= i < n:\n        o_match = _OctalPatt.search(s, i)\n        q_match = _QuotePatt.search(s, i)\n        if not o_match and not q_match:  # Neither matched\n            res.append(s[i:])\n            break\n        # else:\n        j = k = -1\n        if o_match:\n            j = o_match.start(0)\n        if q_match:\n            k = q_match.start(0)\n        if q_match and (not o_match or k < j):  # QuotePatt matched\n            res.append(s[i:k])\n            res.append(s[k + 1])\n            i = k + 2\n        else:  # OctalPatt matched\n            res.append(s[i:j])\n            res.append(chr(int(s[j + 1 : j + 4], 8)))\n            i = j + 4\n    return _nulljoin(res)", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 1059, "line_no": 1066, "id": 321, "target_function_prompt": "def _unquote_cookie(s: str) -> str:\n    \"\"\"Handle double quotes and escaping in cookie values.\n\n    This method is copied verbatim from the Python 3.5 standard\n    library (http.cookies._unquote) so we don't have to depend on\n    non-public interfaces.\n    \"\"\"\n", "function_signature": "def _unquote_cookie(s: str) -> str:"}}
{"prompt": "def parse_cookie(cookie: str) -> Dict[str, str]:\n    \"\"\"Parse a ``Cookie`` HTTP header into a dict of name/value pairs.\n\n    This function attempts to mimic browser cookie parsing behavior;\n    it specifically does not follow any of the cookie-related RFCs\n    (because browsers don't either).\n\n    The algorithm used is identical to that used by Django version 1.9.10.\n\n    .. versionadded:: 4.4.2\n    \"\"\"\n", "metadata": {"task_id": "tornado/43", "ground_truth": "    cookiedict = {}\n    for chunk in cookie.split(str(\";\")):\n        if str(\"=\") in chunk:\n            key, val = chunk.split(str(\"=\"), 1)\n        else:\n            # Assume an empty name per\n            # https://bugzilla.mozilla.org/show_bug.cgi?id=169091\n            key, val = str(\"\"), chunk\n        key, val = key.strip(), val.strip()\n        if key or val:\n            # unquote using Python's algorithm.\n            cookiedict[key] = _unquote_cookie(val)\n    return cookiedict", "fpath_tuple": ["tornado", "tornado", "httputil.py"], "context_start_lineno": 1109, "line_no": 1120, "id": 322, "target_function_prompt": "def parse_cookie(cookie: str) -> Dict[str, str]:\n    \"\"\"Parse a ``Cookie`` HTTP header into a dict of name/value pairs.\n\n    This function attempts to mimic browser cookie parsing behavior;\n    it specifically does not follow any of the cookie-related RFCs\n    (because browsers don't either).\n\n    The algorithm used is identical to that used by Django version 1.9.10.\n\n    .. versionadded:: 4.4.2\n    \"\"\"\n", "function_signature": "def parse_cookie(cookie: str) -> Dict[str, str]:"}}
{"prompt": "def import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n    ...\n    ImportError: No module named missing_module\n    \"\"\"\n", "metadata": {"task_id": "tornado/44", "ground_truth": "    if name.count(\".\") == 0:\n        return __import__(name)\n\n    parts = name.split(\".\")\n    obj = __import__(\".\".join(parts[:-1]), fromlist=[parts[-1]])\n    try:\n        return getattr(obj, parts[-1])\n    except AttributeError:\n        raise ImportError(\"No module named %s\" % parts[-1])", "fpath_tuple": ["tornado", "tornado", "util.py"], "context_start_lineno": 130, "line_no": 148, "id": 323, "target_function_prompt": "def import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n    ...\n    ImportError: No module named missing_module\n    \"\"\"\n", "function_signature": "def import_object(name: str) -> Any:"}}
{"prompt": "def errno_from_exception(e: BaseException) -> Optional[int]:\n    \"\"\"Provides the errno from an Exception object.\n\n    There are cases that the errno attribute was not set so we pull\n    the errno out of the args but if someone instantiates an Exception\n    without any args you will get a tuple error. So this function\n    abstracts all that behavior to give you a safe way to get the\n    errno.\n    \"\"\"\n", "metadata": {"task_id": "tornado/45", "ground_truth": "\n    if hasattr(e, \"errno\"):\n        return e.errno  # type: ignore\n    elif e.args:\n        return e.args[0]\n    else:\n        return None", "fpath_tuple": ["tornado", "tornado", "util.py"], "context_start_lineno": 189, "line_no": 198, "id": 324, "target_function_prompt": "def errno_from_exception(e: BaseException) -> Optional[int]:\n    \"\"\"Provides the errno from an Exception object.\n\n    There are cases that the errno attribute was not set so we pull\n    the errno out of the args but if someone instantiates an Exception\n    without any args you will get a tuple error. So this function\n    abstracts all that behavior to give you a safe way to get the\n    errno.\n    \"\"\"\n", "function_signature": "def errno_from_exception(e: BaseException) -> Optional[int]:"}}
{"prompt": "def re_unescape(s: str) -> str:\n    r\"\"\"Unescape a string escaped by `re.escape`.\n\n    May raise ``ValueError`` for regular expressions which could not\n    have been produced by `re.escape` (for example, strings containing\n    ``\\d`` cannot be unescaped).\n\n    .. versionadded:: 4.4\n    \"\"\"\n", "metadata": {"task_id": "tornado/46", "ground_truth": "    return _re_unescape_pattern.sub(_re_unescape_replacement, s)", "fpath_tuple": ["tornado", "tornado", "util.py"], "context_start_lineno": 220, "line_no": 229, "id": 325, "target_function_prompt": "def re_unescape(s: str) -> str:\n    r\"\"\"Unescape a string escaped by `re.escape`.\n\n    May raise ``ValueError`` for regular expressions which could not\n    have been produced by `re.escape` (for example, strings containing\n    ``\\d`` cannot be unescaped).\n\n    .. versionadded:: 4.4\n    \"\"\"\n", "function_signature": "def re_unescape(s: str) -> str:"}}
{"prompt": "def _websocket_mask_python(mask: bytes, data: bytes) -> bytes:\n    \"\"\"Websocket masking function.\n\n    `mask` is a `bytes` object of length 4; `data` is a `bytes` object of any length.\n    Returns a `bytes` object of the same length as `data` with the mask applied\n    as specified in section 5.3 of RFC 6455.\n\n    This pure-python implementation may be replaced by an optimized version when available.\n    \"\"\"\n", "metadata": {"task_id": "tornado/47", "ground_truth": "    mask_arr = array.array(\"B\", mask)\n    unmasked_arr = array.array(\"B\", data)\n    for i in range(len(data)):\n        unmasked_arr[i] = unmasked_arr[i] ^ mask_arr[i % 4]\n    return unmasked_arr.tobytes()", "fpath_tuple": ["tornado", "tornado", "util.py"], "context_start_lineno": 440, "line_no": 449, "id": 326, "target_function_prompt": "def _websocket_mask_python(mask: bytes, data: bytes) -> bytes:\n    \"\"\"Websocket masking function.\n\n    `mask` is a `bytes` object of length 4; `data` is a `bytes` object of any length.\n    Returns a `bytes` object of the same length as `data` with the mask applied\n    as specified in section 5.3 of RFC 6455.\n\n    This pure-python implementation may be replaced by an optimized version when available.\n    \"\"\"\n", "function_signature": "def _websocket_mask_python(mask: bytes, data: bytes) -> bytes:"}}
{"prompt": "def filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:\n\n    * ``all``: Return all whitespace unmodified.\n    * ``single``: Collapse consecutive whitespace with a single whitespace\n    character, preserving newlines.\n    * ``oneline``: Collapse all runs of whitespace into a single space\n    character, removing all newlines in the process.\n\n    .. versionadded:: 4.3\n    \"\"\"\n", "metadata": {"task_id": "tornado/48", "ground_truth": "    if mode == \"all\":\n        return text\n    elif mode == \"single\":\n        text = re.sub(r\"([\\t ]+)\", \" \", text)\n        text = re.sub(r\"(\\s*\\n\\s*)\", \"\\n\", text)\n        return text\n    elif mode == \"oneline\":\n        return re.sub(r\"(\\s+)\", \" \", text)\n    else:\n        raise Exception(\"invalid whitespace mode %s\" % mode)", "fpath_tuple": ["tornado", "tornado", "template.py"], "context_start_lineno": 226, "line_no": 239, "id": 327, "target_function_prompt": "def filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:\n\n    * ``all``: Return all whitespace unmodified.\n    * ``single``: Collapse consecutive whitespace with a single whitespace\n    character, preserving newlines.\n    * ``oneline``: Collapse all runs of whitespace into a single space\n    character, removing all newlines in the process.\n\n    .. versionadded:: 4.3\n    \"\"\"\n", "function_signature": "def filter_whitespace(mode: str, text: str) -> str:"}}
{"prompt": "def get(*locale_codes: str) -> \"Locale\":\n    \"\"\"Returns the closest match for the given locale codes.\n\n    We iterate over all given locale codes in order. If we have a tight\n    or a loose match for the code (e.g., \"en\" for \"en_US\"), we return\n    the locale. Otherwise we move to the next code in the list.\n\n    By default we return ``en_US`` if no translations are found for any of\n    the specified locales. You can change the default locale with\n    `set_default_locale()`.\n    \"\"\"\n", "metadata": {"task_id": "tornado/49", "ground_truth": "    return Locale.get_closest(*locale_codes)", "fpath_tuple": ["tornado", "tornado", "locale.py"], "context_start_lineno": 60, "line_no": 71, "id": 328, "target_function_prompt": "def get(*locale_codes: str) -> \"Locale\":\n    \"\"\"Returns the closest match for the given locale codes.\n\n    We iterate over all given locale codes in order. If we have a tight\n    or a loose match for the code (e.g., \"en\" for \"en_US\"), we return\n    the locale. Otherwise we move to the next code in the list.\n\n    By default we return ``en_US`` if no translations are found for any of\n    the specified locales. You can change the default locale with\n    `set_default_locale()`.\n    \"\"\"\n", "function_signature": "def get(*locale_codes: str) -> \"Locale\":"}}
{"prompt": "def get_supported_locales() -> Iterable[str]:\n    \"\"\"Returns a list of all the supported locale codes.\"\"\"\n", "metadata": {"task_id": "tornado/50", "ground_truth": "    return _supported_locales", "fpath_tuple": ["tornado", "tornado", "locale.py"], "context_start_lineno": 218, "line_no": 220, "id": 329, "target_function_prompt": "def get_supported_locales() -> Iterable[str]:\n    \"\"\"Returns a list of all the supported locale codes.\"\"\"\n", "function_signature": "def get_supported_locales() -> Iterable[str]:"}}
{"prompt": "def curry(x, args_count=None):\n    \"\"\"\n    In mathematics and computer science, currying is the technique of translating the evaluation of a function.\n    It that takes multiple arguments (or a tuple of arguments) into evaluating a sequence of functions.\n    each with a single argument.\n    \"\"\"\n", "metadata": {"task_id": "pyMonet/0", "ground_truth": "    if args_count is None:\n        args_count = x.__code__.co_argcount\n\n    def fn(*args):\n        if len(args) == args_count:\n            return x(*args)\n        return curry(lambda *args1: x(*(args + args1)), args_count - len(args))\n    return fn", "fpath_tuple": ["pyMonet", "pymonet", "utils.py"], "context_start_lineno": 8, "line_no": 14, "id": 330, "target_function_prompt": "def curry(x, args_count=None):\n    \"\"\"\n    In mathematics and computer science, currying is the technique of translating the evaluation of a function.\n    It that takes multiple arguments (or a tuple of arguments) into evaluating a sequence of functions.\n    each with a single argument.\n    \"\"\"\n", "function_signature": "def curry(x, args_count=None):"}}
{"prompt": "def identity(value: T) -> T:\n    \"\"\"\n    Return first argument.\n\n    :param value:\n    :type value: Any\n    :returns:\n    :rtype: Any\n    \"\"\"\n", "metadata": {"task_id": "pyMonet/1", "ground_truth": "    return value", "fpath_tuple": ["pyMonet", "pymonet", "utils.py"], "context_start_lineno": 24, "line_no": 33, "id": 331, "target_function_prompt": "def identity(value: T) -> T:\n    \"\"\"\n    Return first argument.\n\n    :param value:\n    :type value: Any\n    :returns:\n    :rtype: Any\n    \"\"\"\n", "function_signature": "def identity(value: T) -> T:"}}
{"prompt": "def increase(value: int) -> int:\n    \"\"\"\n    Return increased by 1 argument.\n\n    :param value:\n    :type value: Int\n    :returns:\n    :rtype: Int\n    \"\"\"\n", "metadata": {"task_id": "pyMonet/2", "ground_truth": "    return value + 1", "fpath_tuple": ["pyMonet", "pymonet", "utils.py"], "context_start_lineno": 36, "line_no": 45, "id": 332, "target_function_prompt": "def increase(value: int) -> int:\n    \"\"\"\n    Return increased by 1 argument.\n\n    :param value:\n    :type value: Int\n    :returns:\n    :rtype: Int\n    \"\"\"\n", "function_signature": "def increase(value: int) -> int:"}}
{"prompt": "def find(collection: List[T], key: Callable[[T], bool]):\n    \"\"\"\n    Return the first element of the list which matches the keys, or None if no element matches.\n\n    :param collection: collection to search\n    :type collection: List[A]\n    :param key: function to decide witch element should be found\n    :type key: Function(A) -> Boolean\n    :returns: element of collection or None\n    :rtype: A | None\n    \"\"\"\n", "metadata": {"task_id": "pyMonet/3", "ground_truth": "    for item in collection:\n        if key(item):\n            return item", "fpath_tuple": ["pyMonet", "pymonet", "utils.py"], "context_start_lineno": 64, "line_no": 75, "id": 333, "target_function_prompt": "def find(collection: List[T], key: Callable[[T], bool]):\n    \"\"\"\n    Return the first element of the list which matches the keys, or None if no element matches.\n\n    :param collection: collection to search\n    :type collection: List[A]\n    :param key: function to decide witch element should be found\n    :type key: Function(A) -> Boolean\n    :returns: element of collection or None\n    :rtype: A | None\n    \"\"\"\n", "function_signature": "def find(collection: List[T], key: Callable[[T], bool]):"}}
{"prompt": "def compose(value, *functions):\n    \"\"\"\n    Perform right-to-left function composition.\n\n    :param value: argument of first applied function\n    :type value: Any\n    :param functions: list of functions to applied from right-to-left\n    :type functions: List[Function]\n    :returns: result of all functions\n    :rtype: Any\n    \"\"\"\n", "metadata": {"task_id": "pyMonet/4", "ground_truth": "    return reduce(\n        lambda current_value, function: function(current_value),\n        functions[::-1],\n        value\n    )", "fpath_tuple": ["pyMonet", "pymonet", "utils.py"], "context_start_lineno": 80, "line_no": 91, "id": 334, "target_function_prompt": "def compose(value, *functions):\n    \"\"\"\n    Perform right-to-left function composition.\n\n    :param value: argument of first applied function\n    :type value: Any\n    :param functions: list of functions to applied from right-to-left\n    :type functions: List[Function]\n    :returns: result of all functions\n    :rtype: Any\n    \"\"\"\n", "function_signature": "def compose(value, *functions):"}}
{"prompt": "def pipe(value, *functions):\n    \"\"\"\n    Perform left-to-right function composition.\n\n    :param value: argument of first applied function\n    :type value: Any\n    :param functions: list of functions to applied from left-to-right\n    :type functions: List[Function]\n    :returns: result of all functions\n    :rtype: Any\n    \"\"\"\n", "metadata": {"task_id": "pyMonet/5", "ground_truth": "    return reduce(\n        lambda current_value, function: function(current_value),\n        functions,\n        value\n    )", "fpath_tuple": ["pyMonet", "pymonet", "utils.py"], "context_start_lineno": 98, "line_no": 109, "id": 335, "target_function_prompt": "def pipe(value, *functions):\n    \"\"\"\n    Perform left-to-right function composition.\n\n    :param value: argument of first applied function\n    :type value: Any\n    :param functions: list of functions to applied from left-to-right\n    :type functions: List[Function]\n    :returns: result of all functions\n    :rtype: Any\n    \"\"\"\n", "function_signature": "def pipe(value, *functions):"}}
{"prompt": "def cond(condition_list: List[Tuple[\n    Callable[[T], bool],\n    Callable,\n]]):\n    \"\"\"\n    Function for return function depended on first function argument\n    cond get list of two-item tuples,\n    first is condition_function, second is execute_function.\n    Returns this execute_function witch first condition_function return truly value.\n\n    :param condition_list: list of two-item tuples (condition_function, execute_function)\n    :type condition_list: List[(Function, Function)]\n    :returns: Returns this execute_function witch first condition_function return truly value\n    :rtype: Function\n    \"\"\"\n", "metadata": {"task_id": "pyMonet/6", "ground_truth": "    def result(*args):\n        for (condition_function, execute_function) in condition_list:\n            if condition_function(*args):\n                return execute_function(*args)\n\n    return result", "fpath_tuple": ["pyMonet", "pymonet", "utils.py"], "context_start_lineno": 116, "line_no": 131, "id": 336, "target_function_prompt": "def cond(condition_list: List[Tuple[\n    Callable[[T], bool],\n    Callable,\n]]):\n    \"\"\"\n    Function for return function depended on first function argument\n    cond get list of two-item tuples,\n    first is condition_function, second is execute_function.\n    Returns this execute_function witch first condition_function return truly value.\n\n    :param condition_list: list of two-item tuples (condition_function, execute_function)\n    :type condition_list: List[(Function, Function)]\n    :returns: Returns this execute_function witch first condition_function return truly value\n    :rtype: Function\n    \"\"\"\n", "function_signature": "def cond(condition_list: List[Tuple[\n    Callable[[T], bool],\n    Callable,\n]]):"}}
{"prompt": "def memoize(fn: Callable, key=eq) -> Callable:\n    \"\"\"\n    Create a new function that, when invoked,\n    caches the result of calling fn for a given argument set and returns the result.\n    Subsequent calls to the memoized fn with the same argument set will not result in an additional call to fn;\n    instead, the cached result for that set of arguments will be returned.\n\n    :param fn: function to invoke\n    :type fn: Function(A) -> B\n    :param key: function to decide if result should be taken from cache\n    :type key: Function(A, A) -> Boolean\n    :returns: new function invoking old one\n    :rtype: Function(A) -> B\n    \"\"\"\n", "metadata": {"task_id": "pyMonet/7", "ground_truth": "    cache: List[Any] = []\n\n    def memoized_fn(argument):\n        cached_result = find(cache, lambda cacheItem: key(cacheItem[0], argument))\n        if cached_result is not None:\n            return cached_result[1]\n        fn_result = fn(argument)\n        cache.append((argument, fn_result))\n\n        return fn_result\n\n    return memoized_fn", "fpath_tuple": ["pyMonet", "pymonet", "utils.py"], "context_start_lineno": 139, "line_no": 153, "id": 337, "target_function_prompt": "def memoize(fn: Callable, key=eq) -> Callable:\n    \"\"\"\n    Create a new function that, when invoked,\n    caches the result of calling fn for a given argument set and returns the result.\n    Subsequent calls to the memoized fn with the same argument set will not result in an additional call to fn;\n    instead, the cached result for that set of arguments will be returned.\n\n    :param fn: function to invoke\n    :type fn: Function(A) -> B\n    :param key: function to decide if result should be taken from cache\n    :type key: Function(A, A) -> Boolean\n    :returns: new function invoking old one\n    :rtype: Function(A) -> B\n    \"\"\"\n", "function_signature": "def memoize(fn: Callable, key=eq) -> Callable:"}}
{"prompt": "def build_general_ledger(\n    period: DateRange, journal: Iterable[JournalEntry[_T]], initial: InitialBalances\n) -> GeneralLedger[_T]:\n    \"\"\"\n    Builds a general ledger.\n\n    :param period: Accounting period.\n    :param journal: All available journal entries.\n    :param initial: Opening balances for terminal accounts, if any.\n    :return: A :py:class:`GeneralLedger` instance.\n    \"\"\"\n", "metadata": {"task_id": "pypara/0", "ground_truth": "    ## Initialize ledgers buffer as per available initial balances:\n    ledgers: Dict[Account, Ledger[_T]] = {a: Ledger(a, b) for a, b in initial.items()}\n\n    ## Iterate over journal postings and populate ledgers:\n    for posting in (p for j in journal for p in j.postings if period.since <= j.date <= period.until):\n        ## Check if we have the ledger yet, and create if not:\n        if posting.account not in ledgers:\n            ledgers[posting.account] = Ledger(posting.account, Balance(period.since, Quantity(Decimal(0))))\n\n        ## Add the posting to the ledger:\n        ledgers[posting.account].add(posting)\n\n    ## Done, return general ledger.\n    return GeneralLedger(period, ledgers)", "fpath_tuple": ["pypara", "pypara", "accounting", "ledger.py"], "context_start_lineno": 161, "line_no": 172, "id": 338, "target_function_prompt": "def build_general_ledger(\n    period: DateRange, journal: Iterable[JournalEntry[_T]], initial: InitialBalances\n) -> GeneralLedger[_T]:\n    \"\"\"\n    Builds a general ledger.\n\n    :param period: Accounting period.\n    :param journal: All available journal entries.\n    :param initial: Opening balances for terminal accounts, if any.\n    :return: A :py:class:`GeneralLedger` instance.\n    \"\"\"\n", "function_signature": "def build_general_ledger(\n    period: DateRange, journal: Iterable[JournalEntry[_T]], initial: InitialBalances\n) -> GeneralLedger[_T]:"}}
{"prompt": "def makeguid() -> Guid:\n    \"\"\"\n    Creates a new :py:class:`Guid`.\n\n    :return: :py:class:`Guid` instance.\n    \"\"\"\n", "metadata": {"task_id": "pypara/1", "ground_truth": "    return Guid(uuid4().hex)", "fpath_tuple": ["pypara", "pypara", "commons", "others.py"], "context_start_lineno": 13, "line_no": 19, "id": 339, "target_function_prompt": "def makeguid() -> Guid:\n    \"\"\"\n    Creates a new :py:class:`Guid`.\n\n    :return: :py:class:`Guid` instance.\n    \"\"\"\n", "function_signature": "def makeguid() -> Guid:"}}
{"prompt": "def identity(x: _T) -> _T:\n    \"\"\"\n    Provides the identity function.\n\n    :param x: Any value of the generic type.\n    :return: The value consumed.\n    \"\"\"\n", "metadata": {"task_id": "pypara/2", "ground_truth": "    return x", "fpath_tuple": ["pypara", "pypara", "commons", "others.py"], "context_start_lineno": 26, "line_no": 33, "id": 340, "target_function_prompt": "def identity(x: _T) -> _T:\n    \"\"\"\n    Provides the identity function.\n\n    :param x: Any value of the generic type.\n    :return: The value consumed.\n    \"\"\"\n", "function_signature": "def identity(x: _T) -> _T:"}}
{"prompt": "def make_quantizer(precision: int) -> Decimal:\n    \"\"\"\n    Creates a quantifier as per the given precision.\n    \"\"\"\n", "metadata": {"task_id": "pypara/3", "ground_truth": "    return Decimal(f\"0.{''.join(['0' * precision])}\")", "fpath_tuple": ["pypara", "pypara", "commons", "numbers.py"], "context_start_lineno": 52, "line_no": 56, "id": 341, "target_function_prompt": "def make_quantizer(precision: int) -> Decimal:\n    \"\"\"\n    Creates a quantifier as per the given precision.\n    \"\"\"\n", "function_signature": "def make_quantizer(precision: int) -> Decimal:"}}
{"prompt": "def isum(xs: Iterable[DecimalLike], start: Optional[DecimalLike] = None) -> DecimalLike:\n    \"\"\"\n    Computes the sum of an iterable of :py:class:`DecimalLike` values such as :py:class:`Amount` or\n    :py:class:`Quantity` including :py:class:`Decimal` itself.\n\n    The return type is the same as the input element type. The base condition is :py:const:`ZERO` of\n    :py:class:`decimal.Decimal` type but cast to the type variable if required.\n\n    :param xs: An iterable of :py:class:`Decimal`-like values.\n    :param start: Optional initial value. This defaults to :py:const:`ZERO` in the implementation.\n    :return: Sum of the elements in the same type as the elements in the argument.\n\n    >>> isum([Amount(ONE), Amount(ONE)])  # Return value is of type `Amount` during type-checking.\n    Decimal('2')\n    >>> isum([Quantity(ONE), Quantity(ONE)])  # Return value is of type `Quantity` during type-checking.\n    Decimal('2')\n    >>> isum([Amount(ONE), Amount(ONE)], Amount(ONE))  # Return value is of type `Amount` during type-checking.\n    Decimal('3')\n    >>> isum([Quantity(ONE), Quantity(ONE)], Quantity(ONE))  # Return value is of type `Quantity` during type-checking.\n    Decimal('3')\n    \"\"\"\n", "metadata": {"task_id": "pypara/4", "ground_truth": "    return sum(xs, start or cast(DecimalLike, ZERO))", "fpath_tuple": ["pypara", "pypara", "commons", "numbers.py"], "context_start_lineno": 66, "line_no": 87, "id": 342, "target_function_prompt": "def isum(xs: Iterable[DecimalLike], start: Optional[DecimalLike] = None) -> DecimalLike:\n    \"\"\"\n    Computes the sum of an iterable of :py:class:`DecimalLike` values such as :py:class:`Amount` or\n    :py:class:`Quantity` including :py:class:`Decimal` itself.\n\n    The return type is the same as the input element type. The base condition is :py:const:`ZERO` of\n    :py:class:`decimal.Decimal` type but cast to the type variable if required.\n\n    :param xs: An iterable of :py:class:`Decimal`-like values.\n    :param start: Optional initial value. This defaults to :py:const:`ZERO` in the implementation.\n    :return: Sum of the elements in the same type as the elements in the argument.\n\n    >>> isum([Amount(ONE), Amount(ONE)])  # Return value is of type `Amount` during type-checking.\n    Decimal('2')\n    >>> isum([Quantity(ONE), Quantity(ONE)])  # Return value is of type `Quantity` during type-checking.\n    Decimal('2')\n    >>> isum([Amount(ONE), Amount(ONE)], Amount(ONE))  # Return value is of type `Amount` during type-checking.\n    Decimal('3')\n    >>> isum([Quantity(ONE), Quantity(ONE)], Quantity(ONE))  # Return value is of type `Quantity` during type-checking.\n    Decimal('3')\n    \"\"\"\n", "function_signature": "def isum(xs: Iterable[DecimalLike], start: Optional[DecimalLike] = None) -> DecimalLike:"}}
{"prompt": "def _as_ccys(codes: Set[str]) -> Set[Currency]:\n    \"\"\"\n    Converts a set of currency codes to a set of currencies.\n    \"\"\"\n", "metadata": {"task_id": "pypara/5", "ground_truth": "    return {Currencies[c] for c in codes}", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 22, "line_no": 26, "id": 343, "target_function_prompt": "def _as_ccys(codes: Set[str]) -> Set[Currency]:\n    \"\"\"\n    Converts a set of currency codes to a set of currencies.\n    \"\"\"\n", "function_signature": "def _as_ccys(codes: Set[str]) -> Set[Currency]:"}}
{"prompt": "def _get_date_range(start: Date, end: Date) -> Iterable[Date]:\n    \"\"\"\n    Returns a generator of dates falling into range within the given period (``end`` is exclusive).\n\n    :param start: The start date of the period.\n    :param end: The end date of the period.\n    :return: A generator of dates.\n    \"\"\"\n", "metadata": {"task_id": "pypara/6", "ground_truth": "    for i in range((end - start).days):\n        yield start + datetime.timedelta(days=i)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 29, "line_no": 37, "id": 344, "target_function_prompt": "def _get_date_range(start: Date, end: Date) -> Iterable[Date]:\n    \"\"\"\n    Returns a generator of dates falling into range within the given period (``end`` is exclusive).\n\n    :param start: The start date of the period.\n    :param end: The end date of the period.\n    :return: A generator of dates.\n    \"\"\"\n", "function_signature": "def _get_date_range(start: Date, end: Date) -> Iterable[Date]:"}}
{"prompt": "def _get_actual_day_count(start: Date, end: Date) -> int:\n    \"\"\"\n    Counts the actual number of days in the given period.\n\n    :param start: The start date of the period.\n    :param end: The end date of the period.\n    :return: The number of days in the given period.\n\n    >>> _get_actual_day_count(datetime.date(2017, 1, 1), datetime.date(2017, 1, 1))\n    0\n    >>> _get_actual_day_count(datetime.date(2017, 1, 1), datetime.date(2017, 1, 2))\n    1\n    \"\"\"\n", "metadata": {"task_id": "pypara/7", "ground_truth": "    return (end - start).days", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 41, "line_no": 54, "id": 345, "target_function_prompt": "def _get_actual_day_count(start: Date, end: Date) -> int:\n    \"\"\"\n    Counts the actual number of days in the given period.\n\n    :param start: The start date of the period.\n    :param end: The end date of the period.\n    :return: The number of days in the given period.\n\n    >>> _get_actual_day_count(datetime.date(2017, 1, 1), datetime.date(2017, 1, 1))\n    0\n    >>> _get_actual_day_count(datetime.date(2017, 1, 1), datetime.date(2017, 1, 2))\n    1\n    \"\"\"\n", "function_signature": "def _get_actual_day_count(start: Date, end: Date) -> int:"}}
{"prompt": "def _has_leap_day(start: Date, end: Date) -> bool:\n    \"\"\"\n    Indicates if the range has any leap day.\n    \"\"\"\n", "metadata": {"task_id": "pypara/8", "ground_truth": "    ## Get all leap years:\n    years = {year for year in range(start.year, end.year + 1) if calendar.isleap(year)}\n\n    ## Check if any of the lap day falls in our range:\n    for year in years:\n        ## Construct the leap day:\n        leapday = datetime.date(year, 2, 29)\n\n        ## Is the leap date in the range?\n        if start <= leapday <= end:\n            ## Yes, the leap day is within the date range. Return True:\n            return True\n\n    ## No leap day in the range, return False:\n    return False", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 57, "line_no": 61, "id": 346, "target_function_prompt": "def _has_leap_day(start: Date, end: Date) -> bool:\n    \"\"\"\n    Indicates if the range has any leap day.\n    \"\"\"\n", "function_signature": "def _has_leap_day(start: Date, end: Date) -> bool:"}}
{"prompt": "def _is_last_day_of_month(date: Date) -> bool:\n    \"\"\"\n    Indicates if the date is the last day of the month.\n    \"\"\"\n", "metadata": {"task_id": "pypara/9", "ground_truth": "    return date.day == calendar.monthrange(date.year, date.month)[1]", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 78, "line_no": 82, "id": 347, "target_function_prompt": "def _is_last_day_of_month(date: Date) -> bool:\n    \"\"\"\n    Indicates if the date is the last day of the month.\n    \"\"\"\n", "function_signature": "def _is_last_day_of_month(date: Date) -> bool:"}}
{"prompt": "def _last_payment_date(start: Date, asof: Date, frequency: Union[int, Decimal], eom: Optional[int] = None) -> Date:\n    \"\"\"\n    Returns the last coupon payment date.\n\n    >>> _last_payment_date(datetime.date(2014,  1,  1), datetime.date(2015, 12, 31), 1)\n    datetime.date(2015, 1, 1)\n\n    >>> _last_payment_date(datetime.date(2015,  1,  1), datetime.date(2015, 12, 31), 1)\n    datetime.date(2015, 1, 1)\n\n    >>> _last_payment_date(datetime.date(2014,  1,  1), datetime.date(2015, 12, 31), 2)\n    datetime.date(2015, 7, 1)\n\n    >>> _last_payment_date(datetime.date(2014,  1,  1), datetime.date(2015,  8, 31), 2)\n    datetime.date(2015, 7, 1)\n\n    >>> _last_payment_date(datetime.date(2014,  1,  1), datetime.date(2015,  4, 30), 2)\n    datetime.date(2015, 1, 1)\n\n    >>> _last_payment_date(datetime.date(2014,  6,  1), datetime.date(2015,  4, 30), 1)\n    datetime.date(2014, 6, 1)\n\n    >>> _last_payment_date(datetime.date(2008,  7,  7), datetime.date(2015, 10,  6), 4)\n    datetime.date(2015, 7, 7)\n\n    >>> _last_payment_date(datetime.date(2014, 12,  9), datetime.date(2015, 12,  4), 1)\n    datetime.date(2014, 12, 9)\n\n    >>> _last_payment_date(datetime.date(2012, 12, 15), datetime.date(2016,  1,  6), 2)\n    datetime.date(2015, 12, 15)\n\n    >>> _last_payment_date(datetime.date(2012, 12, 15), datetime.date(2015, 12, 31), 2)\n    datetime.date(2015, 12, 15)\n    \"\"\"\n", "metadata": {"task_id": "pypara/10", "ground_truth": "    ## Make sure that we have eom:\n    eom = eom or start.day\n\n    ## Get the starting month:\n    s_month = start.month\n\n    ## Get the period:\n    period = int(12 / frequency)\n\n    ## Get the current day, month and year:\n    c_day, c_month, c_year = asof.day, asof.month, asof.year\n\n    ## Get the payment schedule:\n    schedule = sorted([i > 0 and i or 12 for i in sorted([(i + s_month) % 12 for i in range(0, 12, period)])])\n\n    ## Filter out previous:\n    future = [month for month in schedule if (month < c_month) or (month == c_month and eom <= c_day)]\n\n    ## Get the previous month and year:\n    p_year, p_month = (c_year, future[-1]) if future else (c_year - 1, schedule[-1])\n\n    ## Return the date:\n    if p_year < 1 or p_month < 1 or eom < 1:\n        return start\n\n    ## Construct and return the date safely:\n    return _construct_date(p_year, p_month, eom)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 85, "line_no": 119, "id": 348, "target_function_prompt": "def _last_payment_date(start: Date, asof: Date, frequency: Union[int, Decimal], eom: Optional[int] = None) -> Date:\n    \"\"\"\n    Returns the last coupon payment date.\n\n    >>> _last_payment_date(datetime.date(2014,  1,  1), datetime.date(2015, 12, 31), 1)\n    datetime.date(2015, 1, 1)\n\n    >>> _last_payment_date(datetime.date(2015,  1,  1), datetime.date(2015, 12, 31), 1)\n    datetime.date(2015, 1, 1)\n\n    >>> _last_payment_date(datetime.date(2014,  1,  1), datetime.date(2015, 12, 31), 2)\n    datetime.date(2015, 7, 1)\n\n    >>> _last_payment_date(datetime.date(2014,  1,  1), datetime.date(2015,  8, 31), 2)\n    datetime.date(2015, 7, 1)\n\n    >>> _last_payment_date(datetime.date(2014,  1,  1), datetime.date(2015,  4, 30), 2)\n    datetime.date(2015, 1, 1)\n\n    >>> _last_payment_date(datetime.date(2014,  6,  1), datetime.date(2015,  4, 30), 1)\n    datetime.date(2014, 6, 1)\n\n    >>> _last_payment_date(datetime.date(2008,  7,  7), datetime.date(2015, 10,  6), 4)\n    datetime.date(2015, 7, 7)\n\n    >>> _last_payment_date(datetime.date(2014, 12,  9), datetime.date(2015, 12,  4), 1)\n    datetime.date(2014, 12, 9)\n\n    >>> _last_payment_date(datetime.date(2012, 12, 15), datetime.date(2016,  1,  6), 2)\n    datetime.date(2015, 12, 15)\n\n    >>> _last_payment_date(datetime.date(2012, 12, 15), datetime.date(2015, 12, 31), 2)\n    datetime.date(2015, 12, 15)\n    \"\"\"\n", "function_signature": "def _last_payment_date(start: Date, asof: Date, frequency: Union[int, Decimal], eom: Optional[int] = None) -> Date:"}}
{"prompt": "def _next_payment_date(start: Date, frequency: Union[int, Decimal], eom: Optional[int] = None) -> Date:\n    \"\"\"\n    Returns the last coupon payment date.\n\n    >>> _next_payment_date(datetime.date(2014,  1,  1), 1, None)\n    datetime.date(2015, 1, 1)\n\n    >>> _next_payment_date(datetime.date(2014,  1,  1), 1, 15)\n    datetime.date(2015, 1, 15)\n    \"\"\"\n", "metadata": {"task_id": "pypara/11", "ground_truth": "    ## Get the number of months to move forward:\n    months = int(12 / frequency)\n\n    ## Find the next date:\n    nextdate = start + relativedelta(months=months)\n\n    ## Do we have any end of month?\n    if eom:\n        try:\n            nextdate = nextdate.replace(day=eom)\n        except ValueError:\n            pass\n\n    ## Done, return:\n    return nextdate", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 148, "line_no": 158, "id": 349, "target_function_prompt": "def _next_payment_date(start: Date, frequency: Union[int, Decimal], eom: Optional[int] = None) -> Date:\n    \"\"\"\n    Returns the last coupon payment date.\n\n    >>> _next_payment_date(datetime.date(2014,  1,  1), 1, None)\n    datetime.date(2015, 1, 1)\n\n    >>> _next_payment_date(datetime.date(2014,  1,  1), 1, 15)\n    datetime.date(2015, 1, 15)\n    \"\"\"\n", "function_signature": "def _next_payment_date(start: Date, frequency: Union[int, Decimal], eom: Optional[int] = None) -> Date:"}}
{"prompt": "def _construct_date(year: int, month: int, day: int) -> Date:\n    \"\"\"\n    Constructs and returns date safely.\n    \"\"\"\n", "metadata": {"task_id": "pypara/12", "ground_truth": "    if year <= 0 or month <= 0 or day <= 0:\n        raise ValueError(\"year, month and day must be greater than 0.\")\n    try:\n        return datetime.date(year, month, day)\n    except ValueError as exc:\n        if str(exc) == \"day is out of range for month\":\n            return _construct_date(year, month, day - 1)\n        else:\n            raise exc", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 175, "line_no": 179, "id": 350, "target_function_prompt": "def _construct_date(year: int, month: int, day: int) -> Date:\n    \"\"\"\n    Constructs and returns date safely.\n    \"\"\"\n", "function_signature": "def _construct_date(year: int, month: int, day: int) -> Date:"}}
{"prompt": "def dcc(name: str, altnames: Optional[Set[str]] = None, ccys: Optional[Set[Currency]] = None) -> Callable[[DCFC], DCFC]:\n    \"\"\"\n    Registers a day count fraction calculator under the given names and alternative names (if any).\n\n    :param name: The name of the day count convention.\n    :param altnames: A set of alternative names of the day count convention, if any.\n    :param ccys: A set of currencies which are known to use this convention by default, if any.\n    :return: Registered day count fraction calculation function.\n    \"\"\"\n", "metadata": {"task_id": "pypara/13", "ground_truth": "\n    def register_and_return_dcfc(func: DCFC) -> DCFC:\n        \"\"\"\n        Registers the given day count fraction calculator and returns it.\n\n        :param func: Day count fraction calculation function to be registered.\n        :return: Registered day count fraction calculation function.\n        \"\"\"\n        ## Create the DCC instance:\n        dcc = DCC(name, altnames or set([]), ccys or set([]), func)\n\n        ## Attempt to register the DCC:\n        DCCRegistry.register(dcc)\n\n        ## Attach the dcc instance to the day count fraction calculation function (for whatever it is worth):\n        setattr(func, \"__dcc\", dcc)\n\n        ## Done, return the function (if above statment did not raise any exceptions):\n        return func\n\n    return register_and_return_dcfc", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 366, "line_no": 375, "id": 351, "target_function_prompt": "def dcc(name: str, altnames: Optional[Set[str]] = None, ccys: Optional[Set[Currency]] = None) -> Callable[[DCFC], DCFC]:\n    \"\"\"\n    Registers a day count fraction calculator under the given names and alternative names (if any).\n\n    :param name: The name of the day count convention.\n    :param altnames: A set of alternative names of the day count convention, if any.\n    :param ccys: A set of currencies which are known to use this convention by default, if any.\n    :return: Registered day count fraction calculation function.\n    \"\"\"\n", "function_signature": "def dcc(name: str, altnames: Optional[Set[str]] = None, ccys: Optional[Set[Currency]] = None) -> Callable[[DCFC], DCFC]:"}}
{"prompt": "def dcfc_act_act(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for \"Act/Act\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :param freq: The frequency of payments in a year.\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_act_act(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16942884946478')\n    >>> round(dcfc_act_act(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.17216108990194')\n    >>> round(dcfc_act_act(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08243131970956')\n    >>> round(dcfc_act_act(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.32625945055768')\n    \"\"\"\n", "metadata": {"task_id": "pypara/14", "ground_truth": "    ## Get all years of interest by checking the leap year:\n    years = {year: calendar.isleap(year) for year in range(start.year, asof.year + 1)}\n\n    ## Define the buffer of days for the day count. The former is for non-leap years, the latter for leap years:\n    buffer: List[int] = [0, 0]\n\n    ## Iterate over the date range and count:\n    for date in _get_date_range(start, asof):\n        ## Check the year and modify buffer accordingly:\n        if years[date.year]:\n            ## Yep, it is a leap year:\n            buffer[1] += 1\n        else:\n            ## Nope, not a leap year:\n            buffer[0] += 1\n\n    ## Done, compute and return:\n    return Decimal(buffer[0]) / Decimal(365) + Decimal(buffer[1]) / Decimal(366)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 399, "line_no": 422, "id": 352, "target_function_prompt": "def dcfc_act_act(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for \"Act/Act\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :param freq: The frequency of payments in a year.\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_act_act(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16942884946478')\n    >>> round(dcfc_act_act(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.17216108990194')\n    >>> round(dcfc_act_act(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08243131970956')\n    >>> round(dcfc_act_act(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.32625945055768')\n    \"\"\"\n", "function_signature": "def dcfc_act_act(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_act_act_icma(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for \"Act/Act (ICMA)\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof, ex1_end = datetime.date(2019, 3, 2), datetime.date(2019, 9, 10), datetime.date(2020, 3, 2)\n    >>> round(dcfc_act_act_icma(start=ex1_start, asof=ex1_asof, end=ex1_end), 10)\n    Decimal('0.5245901639')\n    \"\"\"\n", "metadata": {"task_id": "pypara/15", "ground_truth": "    ## Get the number of actual days:\n    p1 = Decimal(_get_actual_day_count(start, asof))\n\n    ## Get the number of days in the period:\n    p2 = Decimal(_get_actual_day_count(start, end))\n\n    ## Compute the ratio and return:\n    return p1 / p2 / Decimal(freq or ONE)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 443, "line_no": 456, "id": 353, "target_function_prompt": "def dcfc_act_act_icma(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for \"Act/Act (ICMA)\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof, ex1_end = datetime.date(2019, 3, 2), datetime.date(2019, 9, 10), datetime.date(2020, 3, 2)\n    >>> round(dcfc_act_act_icma(start=ex1_start, asof=ex1_asof, end=ex1_end), 10)\n    Decimal('0.5245901639')\n    \"\"\"\n", "function_signature": "def dcfc_act_act_icma(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_act_360(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for \"Act/360\" convention.\n\n    :param start: The start date of the period.\n    :param end: The end date of the period.\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_act_360(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.17222222222222')\n    >>> round(dcfc_act_360(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.17500000000000')\n    >>> round(dcfc_act_360(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.10000000000000')\n    >>> round(dcfc_act_360(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.34722222222222')\n    \"\"\"\n", "metadata": {"task_id": "pypara/16", "ground_truth": "    return _get_actual_day_count(start, asof) / Decimal(360)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 471, "line_no": 492, "id": 354, "target_function_prompt": "def dcfc_act_360(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for \"Act/360\" convention.\n\n    :param start: The start date of the period.\n    :param end: The end date of the period.\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_act_360(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.17222222222222')\n    >>> round(dcfc_act_360(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.17500000000000')\n    >>> round(dcfc_act_360(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.10000000000000')\n    >>> round(dcfc_act_360(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.34722222222222')\n    \"\"\"\n", "function_signature": "def dcfc_act_360(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_act_365_f(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"Act/365F\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_act_365_f(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16986301369863')\n    >>> round(dcfc_act_365_f(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.17260273972603')\n    >>> round(dcfc_act_365_f(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08493150684932')\n    >>> round(dcfc_act_365_f(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.32876712328767')\n    \"\"\"\n", "metadata": {"task_id": "pypara/17", "ground_truth": "    return _get_actual_day_count(start, asof) / Decimal(365)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 496, "line_no": 518, "id": 355, "target_function_prompt": "def dcfc_act_365_f(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"Act/365F\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_act_365_f(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16986301369863')\n    >>> round(dcfc_act_365_f(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.17260273972603')\n    >>> round(dcfc_act_365_f(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08493150684932')\n    >>> round(dcfc_act_365_f(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.32876712328767')\n    \"\"\"\n", "function_signature": "def dcfc_act_365_f(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_act_365_a(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"Act/365A\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_act_365_a(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16986301369863')\n    >>> round(dcfc_act_365_a(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.17213114754098')\n    >>> round(dcfc_act_365_a(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08196721311475')\n    >>> round(dcfc_act_365_a(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.32513661202186')\n    \"\"\"\n", "metadata": {"task_id": "pypara/18", "ground_truth": "    return _get_actual_day_count(start, asof) / Decimal(366 if _has_leap_day(start, asof) else 365)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 522, "line_no": 544, "id": 356, "target_function_prompt": "def dcfc_act_365_a(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"Act/365A\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_act_365_a(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16986301369863')\n    >>> round(dcfc_act_365_a(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.17213114754098')\n    >>> round(dcfc_act_365_a(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08196721311475')\n    >>> round(dcfc_act_365_a(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.32513661202186')\n    \"\"\"\n", "function_signature": "def dcfc_act_365_a(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_act_365_l(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"Act/365L\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_act_365_l(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16939890710383')\n    >>> round(dcfc_act_365_l(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.17213114754098')\n    >>> round(dcfc_act_365_l(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08196721311475')\n    >>> round(dcfc_act_365_l(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.32876712328767')\n    \"\"\"\n", "metadata": {"task_id": "pypara/19", "ground_truth": "    return _get_actual_day_count(start, asof) / Decimal(366 if calendar.isleap(asof.year) else 365)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 548, "line_no": 570, "id": 357, "target_function_prompt": "def dcfc_act_365_l(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"Act/365L\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_act_365_l(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16939890710383')\n    >>> round(dcfc_act_365_l(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.17213114754098')\n    >>> round(dcfc_act_365_l(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08196721311475')\n    >>> round(dcfc_act_365_l(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.32876712328767')\n    \"\"\"\n", "function_signature": "def dcfc_act_365_l(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_nl_365(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"NL/365\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_nl_365(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16986301369863')\n    >>> round(dcfc_nl_365(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16986301369863')\n    >>> round(dcfc_nl_365(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08219178082192')\n    >>> round(dcfc_nl_365(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.32602739726027')\n    \"\"\"\n", "metadata": {"task_id": "pypara/20", "ground_truth": "    return (_get_actual_day_count(start, asof) - (1 if _has_leap_day(start, asof) else 0)) / Decimal(365)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 574, "line_no": 596, "id": 358, "target_function_prompt": "def dcfc_nl_365(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"NL/365\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_nl_365(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16986301369863')\n    >>> round(dcfc_nl_365(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16986301369863')\n    >>> round(dcfc_nl_365(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08219178082192')\n    >>> round(dcfc_nl_365(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.32602739726027')\n    \"\"\"\n", "function_signature": "def dcfc_nl_365(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_30_360_isda(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"30/360 ISDA\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_30_360_isda(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16666666666667')\n    >>> round(dcfc_30_360_isda(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16944444444444')\n    >>> round(dcfc_30_360_isda(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08333333333333')\n    >>> round(dcfc_30_360_isda(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.33333333333333')\n    \"\"\"\n", "metadata": {"task_id": "pypara/21", "ground_truth": "    ## Get the new start date, if required:\n    if start.day == 31:\n        start = datetime.date(start.year, start.month, 30)\n\n    ## Get the new asof date, if required:\n    if start.day == 30 and asof.day == 31:\n        asof = datetime.date(asof.year, asof.month, 30)\n\n    ## Compute number of days:\n    nod = (asof.day - start.day) + 30 * (asof.month - start.month) + 360 * (asof.year - start.year)\n\n    ## Done, compute and return the day count fraction:\n    return nod / Decimal(360)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 600, "line_no": 622, "id": 359, "target_function_prompt": "def dcfc_30_360_isda(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"30/360 ISDA\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_30_360_isda(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16666666666667')\n    >>> round(dcfc_30_360_isda(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16944444444444')\n    >>> round(dcfc_30_360_isda(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08333333333333')\n    >>> round(dcfc_30_360_isda(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.33333333333333')\n    \"\"\"\n", "function_signature": "def dcfc_30_360_isda(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_30_e_360(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"30E/360\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_30_e_360(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16666666666667')\n    >>> round(dcfc_30_e_360(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16944444444444')\n    >>> round(dcfc_30_e_360(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08333333333333')\n    >>> round(dcfc_30_e_360(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.33055555555556')\n    \"\"\"\n", "metadata": {"task_id": "pypara/22", "ground_truth": "    ## Get the new start date, if required:\n    if start.day == 31:\n        start = datetime.date(start.year, start.month, 30)\n\n    ## Get the new asof date, if required:\n    if asof.day == 31:\n        asof = datetime.date(asof.year, asof.month, 30)\n\n    ## Compute number of days:\n    nod = (asof.day - start.day) + 30 * (asof.month - start.month) + 360 * (asof.year - start.year)\n\n    ## Done, compute and return the day count fraction:\n    return nod / Decimal(360)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 638, "line_no": 660, "id": 360, "target_function_prompt": "def dcfc_30_e_360(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"30E/360\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_30_e_360(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16666666666667')\n    >>> round(dcfc_30_e_360(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16944444444444')\n    >>> round(dcfc_30_e_360(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08333333333333')\n    >>> round(dcfc_30_e_360(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.33055555555556')\n    \"\"\"\n", "function_signature": "def dcfc_30_e_360(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_30_e_plus_360(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"30E+/360\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_30_e_plus_360(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16666666666667')\n    >>> round(dcfc_30_e_plus_360(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16944444444444')\n    >>> round(dcfc_30_e_plus_360(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08333333333333')\n    >>> round(dcfc_30_e_plus_360(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.33333333333333')\n    \"\"\"\n", "metadata": {"task_id": "pypara/23", "ground_truth": "    ## Get the new start date, if required:\n    if start.day == 31:\n        start = datetime.date(start.year, start.month, 30)\n\n    ## Get the new asof date, if required:\n    if asof.day == 31:\n        asof = asof + datetime.timedelta(days=1)\n\n    ## Compute number of days:\n    nod = (asof.day - start.day) + 30 * (asof.month - start.month) + 360 * (asof.year - start.year)\n\n    ## Done, compute and return the day count fraction:\n    return nod / Decimal(360)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 676, "line_no": 699, "id": 361, "target_function_prompt": "def dcfc_30_e_plus_360(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"30E+/360\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_30_e_plus_360(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16666666666667')\n    >>> round(dcfc_30_e_plus_360(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16944444444444')\n    >>> round(dcfc_30_e_plus_360(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08333333333333')\n    >>> round(dcfc_30_e_plus_360(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.33333333333333')\n    \"\"\"\n", "function_signature": "def dcfc_30_e_plus_360(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_30_360_german(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_30_360_german(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16666666666667')\n    >>> round(dcfc_30_360_german(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16944444444444')\n    >>> round(dcfc_30_360_german(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08333333333333')\n    >>> round(dcfc_30_360_german(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.33055555555556')\n    \"\"\"\n", "metadata": {"task_id": "pypara/24", "ground_truth": "    ## Get the new start date, if required:\n    if start.day == 31 or (start.month == 2 and _is_last_day_of_month(start)):\n        d1 = 30\n    else:\n        d1 = start.day\n\n    ## Get the new asof date, if required:\n    if asof.day == 31 or (asof.month == 2 and _is_last_day_of_month(asof) and end != asof):\n        d2 = 30\n    else:\n        d2 = asof.day\n\n    ## Compute number of days:\n    nod = (d2 - d1) + 30 * (asof.month - start.month) + 360 * (asof.year - start.year)\n\n    ## Done, compute and return the day count fraction:\n    return nod / Decimal(360)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 715, "line_no": 737, "id": 362, "target_function_prompt": "def dcfc_30_360_german(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_30_360_german(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16666666666667')\n    >>> round(dcfc_30_360_german(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16944444444444')\n    >>> round(dcfc_30_360_german(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08333333333333')\n    >>> round(dcfc_30_360_german(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.33055555555556')\n    \"\"\"\n", "function_signature": "def dcfc_30_360_german(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def dcfc_30_360_us(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"30/360 US\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_30_360_us(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16666666666667')\n    >>> round(dcfc_30_360_us(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16944444444444')\n    >>> round(dcfc_30_360_us(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08333333333333')\n    >>> round(dcfc_30_360_us(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.33333333333333')\n    \"\"\"\n", "metadata": {"task_id": "pypara/25", "ground_truth": "    ## Get D1 and D2:\n    d1 = start.day\n    d2 = asof.day\n\n    ## Need to change D1?\n    if _is_last_day_of_month(start):\n        ## Yep, change it:\n        d1 = 30\n\n        ## Shall we change the d2, too?\n        if _is_last_day_of_month(asof):\n            d2 = 30\n\n    ## Revisit d2:\n    if d2 == 31 and (d1 == 30 or d1 == 31):\n        d2 = 30\n\n    ## Revisit d1:\n    if d1 == 31:\n        d1 = 30\n\n    ## Compute number of days:\n    nod = (d2 - d1) + 30 * (asof.month - start.month) + 360 * (asof.year - start.year)\n\n    ## Done, return:\n    return nod / Decimal(360)", "fpath_tuple": ["pypara", "pypara", "dcc.py"], "context_start_lineno": 757, "line_no": 779, "id": 363, "target_function_prompt": "def dcfc_30_360_us(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:\n    \"\"\"\n    Computes the day count fraction for the \"30/360 US\" convention.\n\n    :param start: The start date of the period.\n    :param asof: The date which the day count fraction to be calculated as of.\n    :param end: The end date of the period (a.k.a. termination date).\n    :return: Day count fraction.\n\n    >>> ex1_start, ex1_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 28)\n    >>> ex2_start, ex2_asof = datetime.date(2007, 12, 28), datetime.date(2008, 2, 29)\n    >>> ex3_start, ex3_asof = datetime.date(2007, 10, 31), datetime.date(2008, 11, 30)\n    >>> ex4_start, ex4_asof = datetime.date(2008, 2, 1), datetime.date(2009, 5, 31)\n    >>> round(dcfc_30_360_us(start=ex1_start, asof=ex1_asof, end=ex1_asof), 14)\n    Decimal('0.16666666666667')\n    >>> round(dcfc_30_360_us(start=ex2_start, asof=ex2_asof, end=ex2_asof), 14)\n    Decimal('0.16944444444444')\n    >>> round(dcfc_30_360_us(start=ex3_start, asof=ex3_asof, end=ex3_asof), 14)\n    Decimal('1.08333333333333')\n    >>> round(dcfc_30_360_us(start=ex4_start, asof=ex4_asof, end=ex4_asof), 14)\n    Decimal('1.33333333333333')\n    \"\"\"\n", "function_signature": "def dcfc_30_360_us(start: Date, asof: Date, end: Date, freq: Optional[Decimal] = None) -> Decimal:"}}
{"prompt": "def humanize_bytes(n, precision=2):\n    \"\"\"Return a humanized string representation of a number of bytes.\n\n    Assumes `from __future__ import division`.\n\n    >>> humanize_bytes(1)\n    '1 B'\n    >>> humanize_bytes(1024, precision=1)\n    '1.0 kB'\n    >>> humanize_bytes(1024 * 123, precision=1)\n    '123.0 kB'\n    >>> humanize_bytes(1024 * 12342, precision=1)\n    '12.1 MB'\n    >>> humanize_bytes(1024 * 12342, precision=2)\n    '12.05 MB'\n    >>> humanize_bytes(1024 * 1234, precision=2)\n    '1.21 MB'\n    >>> humanize_bytes(1024 * 1234 * 1111, precision=2)\n    '1.31 GB'\n    >>> humanize_bytes(1024 * 1234 * 1111, precision=1)\n    '1.3 GB'\n\n    \"\"\"\n", "metadata": {"task_id": "httpie/0", "ground_truth": "    abbrevs = [\n        (1 << 50, 'PB'),\n        (1 << 40, 'TB'),\n        (1 << 30, 'GB'),\n        (1 << 20, 'MB'),\n        (1 << 10, 'kB'),\n        (1, 'B')\n    ]\n\n    if n == 1:\n        return '1 B'\n\n    for factor, suffix in abbrevs:\n        if n >= factor:\n            break\n\n    # noinspection PyUnboundLocalVariable\n    return '%.*f %s' % (precision, n / factor, suffix)", "fpath_tuple": ["httpie", "httpie", "utils.py"], "context_start_lineno": 21, "line_no": 47, "id": 364, "target_function_prompt": "def humanize_bytes(n, precision=2):\n    \"\"\"Return a humanized string representation of a number of bytes.\n\n    Assumes `from __future__ import division`.\n\n    >>> humanize_bytes(1)\n    '1 B'\n    >>> humanize_bytes(1024, precision=1)\n    '1.0 kB'\n    >>> humanize_bytes(1024 * 123, precision=1)\n    '123.0 kB'\n    >>> humanize_bytes(1024 * 12342, precision=1)\n    '12.1 MB'\n    >>> humanize_bytes(1024 * 12342, precision=2)\n    '12.05 MB'\n    >>> humanize_bytes(1024 * 1234, precision=2)\n    '1.21 MB'\n    >>> humanize_bytes(1024 * 1234 * 1111, precision=2)\n    '1.31 GB'\n    >>> humanize_bytes(1024 * 1234 * 1111, precision=1)\n    '1.3 GB'\n\n    \"\"\"\n", "function_signature": "def humanize_bytes(n, precision=2):"}}
{"prompt": "def get_content_type(filename):\n    \"\"\"\n    Return the content type for ``filename`` in format appropriate\n    for Content-Type headers, or ``None`` if the file type is unknown\n    to ``mimetypes``.\n\n    \"\"\"\n", "metadata": {"task_id": "httpie/1", "ground_truth": "    mime, encoding = mimetypes.guess_type(filename, strict=False)\n    if mime:\n        content_type = mime\n        if encoding:\n            content_type = '%s; charset=%s' % (mime, encoding)\n        return content_type", "fpath_tuple": ["httpie", "httpie", "utils.py"], "context_start_lineno": 76, "line_no": 83, "id": 365, "target_function_prompt": "def get_content_type(filename):\n    \"\"\"\n    Return the content type for ``filename`` in format appropriate\n    for Content-Type headers, or ``None`` if the file type is unknown\n    to ``mimetypes``.\n\n    \"\"\"\n", "function_signature": "def get_content_type(filename):"}}
{"prompt": "def get_default_config_dir() -> Path:\n    \"\"\"\n    Return the path to the httpie configuration directory.\n\n    This directory isn't guaranteed to exist, and nor are any of its\n    ancestors (only the legacy ~/.httpie, if returned, is guaranteed to exist).\n\n    XDG Base Directory Specification support:\n\n    <https://wiki.archlinux.org/index.php/XDG_Base_Directory>\n\n    $XDG_CONFIG_HOME is supported; $XDG_CONFIG_DIRS is not\n\n    \"\"\"\n", "metadata": {"task_id": "httpie/2", "ground_truth": "    # 1. explicitly set through env\n    env_config_dir = os.environ.get(ENV_HTTPIE_CONFIG_DIR)\n    if env_config_dir:\n        return Path(env_config_dir)\n\n    # 2. Windows\n    if is_windows:\n        return DEFAULT_WINDOWS_CONFIG_DIR\n\n    home_dir = Path.home()\n\n    # 3. legacy ~/.httpie\n    legacy_config_dir = home_dir / DEFAULT_RELATIVE_LEGACY_CONFIG_DIR\n    if legacy_config_dir.exists():\n        return legacy_config_dir\n\n    # 4. XDG\n    xdg_config_home_dir = os.environ.get(\n        ENV_XDG_CONFIG_HOME,  # 4.1. explicit\n        home_dir / DEFAULT_RELATIVE_XDG_CONFIG_HOME  # 4.2. default\n    )\n    return Path(xdg_config_home_dir) / DEFAULT_CONFIG_DIRNAME", "fpath_tuple": ["httpie", "httpie", "config.py"], "context_start_lineno": 19, "line_no": 33, "id": 370, "target_function_prompt": "def get_default_config_dir() -> Path:\n    \"\"\"\n    Return the path to the httpie configuration directory.\n\n    This directory isn't guaranteed to exist, and nor are any of its\n    ancestors (only the legacy ~/.httpie, if returned, is guaranteed to exist).\n\n    XDG Base Directory Specification support:\n\n    <https://wiki.archlinux.org/index.php/XDG_Base_Directory>\n\n    $XDG_CONFIG_HOME is supported; $XDG_CONFIG_DIRS is not\n\n    \"\"\"\n", "function_signature": "def get_default_config_dir() -> Path:"}}
{"prompt": "def http_status_to_exit_status(http_status: int, follow=False) -> ExitStatus:\n    \"\"\"\n    Translate HTTP status code to exit status code.\n\n    (Relevant only when invoked with --check-status or --download.)\n\n    \"\"\"\n", "metadata": {"task_id": "httpie/3", "ground_truth": "    if 300 <= http_status <= 399 and not follow:\n        # Redirect\n        return ExitStatus.ERROR_HTTP_3XX\n    elif 400 <= http_status <= 499:\n        # Client Error\n        return ExitStatus.ERROR_HTTP_4XX\n    elif 500 <= http_status <= 599:\n        # Server Error\n        return ExitStatus.ERROR_HTTP_5XX\n    else:\n        return ExitStatus.SUCCESS", "fpath_tuple": ["httpie", "httpie", "status.py"], "context_start_lineno": 22, "line_no": 29, "id": 371, "target_function_prompt": "def http_status_to_exit_status(http_status: int, follow=False) -> ExitStatus:\n    \"\"\"\n    Translate HTTP status code to exit status code.\n\n    (Relevant only when invoked with --check-status or --download.)\n\n    \"\"\"\n", "function_signature": "def http_status_to_exit_status(http_status: int, follow=False) -> ExitStatus:"}}
{"prompt": "def validate_yaml(\n    content: typing.Union[str, bytes],\n    validator: typing.Union[Field, typing.Type[Schema]],\n) -> typing.Any:\n    \"\"\"\n    Parse and validate a YAML string, returning positionally marked error\n    messages on parse or validation failures.\n\n    content - A YAML string or bytestring.\n    validator - A Field instance or Schema class to validate against.\n\n    Returns a two-tuple of (value, error_messages)\n    \"\"\"\n", "metadata": {"task_id": "typesystem/0", "ground_truth": "    assert yaml is not None, \"'pyyaml' must be installed.\"\n\n    token = tokenize_yaml(content)\n    return validate_with_positions(token=token, validator=validator)", "fpath_tuple": ["typesystem", "typesystem", "tokenize", "tokenize_yaml.py"], "context_start_lineno": 111, "line_no": 124, "id": 374, "target_function_prompt": "def validate_yaml(\n    content: typing.Union[str, bytes],\n    validator: typing.Union[Field, typing.Type[Schema]],\n) -> typing.Any:\n    \"\"\"\n    Parse and validate a YAML string, returning positionally marked error\n    messages on parse or validation failures.\n\n    content - A YAML string or bytestring.\n    validator - A Field instance or Schema class to validate against.\n\n    Returns a two-tuple of (value, error_messages)\n    \"\"\"\n", "function_signature": "def validate_yaml(\n    content: typing.Union[str, bytes],\n    validator: typing.Union[Field, typing.Type[Schema]],\n) -> typing.Any:"}}
{"prompt": "def type_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    \"\"\"\n    Build a typed field or union of typed fields from a JSON schema object.\n    \"\"\"\n", "metadata": {"task_id": "typesystem/1", "ground_truth": "    type_strings, allow_null = get_valid_types(data)\n\n    if len(type_strings) > 1:\n        items = [\n            from_json_schema_type(\n                data, type_string=type_string, allow_null=False, definitions=definitions\n            )\n            for type_string in type_strings\n        ]\n        return Union(any_of=items, allow_null=allow_null)\n\n    if len(type_strings) == 0:\n        return {True: Const(None), False: NeverMatch()}[allow_null]\n\n    type_string = type_strings.pop()\n    return from_json_schema_type(\n        data, type_string=type_string, allow_null=allow_null, definitions=definitions\n    )", "fpath_tuple": ["typesystem", "typesystem", "json_schema.py"], "context_start_lineno": 149, "line_no": 153, "id": 375, "target_function_prompt": "def type_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:\n    \"\"\"\n    Build a typed field or union of typed fields from a JSON schema object.\n    \"\"\"\n", "function_signature": "def type_from_json_schema(data: dict, definitions: SchemaDefinitions) -> Field:"}}
{"prompt": "def get_valid_types(data: dict) -> typing.Tuple[typing.Set[str], bool]:\n    \"\"\"\n    Returns a two-tuple of `(type_strings, allow_null)`.\n    \"\"\"\n", "metadata": {"task_id": "typesystem/2", "ground_truth": "\n    type_strings = data.get(\"type\", [])\n    if isinstance(type_strings, str):\n        type_strings = {type_strings}\n    else:\n        type_strings = set(type_strings)\n\n    if not type_strings:\n        type_strings = {\"null\", \"boolean\", \"object\", \"array\", \"number\", \"string\"}\n\n    if \"number\" in type_strings:\n        type_strings.discard(\"integer\")\n\n    allow_null = False\n    if \"null\" in type_strings:\n        allow_null = True\n        type_strings.remove(\"null\")\n\n    return (type_strings, allow_null)", "fpath_tuple": ["typesystem", "typesystem", "json_schema.py"], "context_start_lineno": 173, "line_no": 177, "id": 376, "target_function_prompt": "def get_valid_types(data: dict) -> typing.Tuple[typing.Set[str], bool]:\n    \"\"\"\n    Returns a two-tuple of `(type_strings, allow_null)`.\n    \"\"\"\n", "function_signature": "def get_valid_types(data: dict) -> typing.Tuple[typing.Set[str], bool]:"}}
{"prompt": "def validate_json(\n    content: typing.Union[str, bytes],\n    validator: typing.Union[Field, typing.Type[Schema]],\n) -> typing.Any:\n    \"\"\"\n    Parse and validate a JSON string, returning positionally marked error\n    messages on parse or validation failures.\n\n    content - A JSON string or bytestring.\n    validator - A Field instance or Schema class to validate against.\n\n    Returns a two-tuple of (value, error_messages)\n    \"\"\"\n", "metadata": {"task_id": "typesystem/3", "ground_truth": "    token = tokenize_json(content)\n    return validate_with_positions(token=token, validator=validator)", "fpath_tuple": ["typesystem", "typesystem", "tokenize", "tokenize_json.py"], "context_start_lineno": 182, "line_no": 195, "id": 377, "target_function_prompt": "def validate_json(\n    content: typing.Union[str, bytes],\n    validator: typing.Union[Field, typing.Type[Schema]],\n) -> typing.Any:\n    \"\"\"\n    Parse and validate a JSON string, returning positionally marked error\n    messages on parse or validation failures.\n\n    content - A JSON string or bytestring.\n    validator - A Field instance or Schema class to validate against.\n\n    Returns a two-tuple of (value, error_messages)\n    \"\"\"\n", "function_signature": "def validate_json(\n    content: typing.Union[str, bytes],\n    validator: typing.Union[Field, typing.Type[Schema]],\n) -> typing.Any:"}}
{"prompt": "def reverse_map(d: Dict[T, int]) -> List[T]:\n    r\"\"\"Given a dict containing pairs of ``(item, id)``, return a list where the ``id``-th element is ``item``.\n\n    .. note::\n    It is assumed that the ``id``\\ s form a permutation.\n\n    .. code:: python\n\n    >>> words = ['a', 'aardvark', 'abandon', ...]\n    >>> word_to_id = {word: idx for idx, word in enumerate(words)}\n    >>> id_to_word = reverse_map(word_to_id)\n    >>> (words == id_to_word)\n    True\n\n    :param d: The dictionary mapping ``item`` to ``id``.\n    \"\"\"\n", "metadata": {"task_id": "flutes/0", "ground_truth": "    return [k for k, _ in sorted(d.items(), key=lambda xs: xs[1])]", "fpath_tuple": ["flutes", "flutes", "structure.py"], "context_start_lineno": 15, "line_no": 31, "id": 378, "target_function_prompt": "def reverse_map(d: Dict[T, int]) -> List[T]:\n    r\"\"\"Given a dict containing pairs of ``(item, id)``, return a list where the ``id``-th element is ``item``.\n\n    .. note::\n    It is assumed that the ``id``\\ s form a permutation.\n\n    .. code:: python\n\n    >>> words = ['a', 'aardvark', 'abandon', ...]\n    >>> word_to_id = {word: idx for idx, word in enumerate(words)}\n    >>> id_to_word = reverse_map(word_to_id)\n    >>> (words == id_to_word)\n    True\n\n    :param d: The dictionary mapping ``item`` to ``id``.\n    \"\"\"\n", "function_signature": "def reverse_map(d: Dict[T, int]) -> List[T]:"}}
{"prompt": "def no_map_instance(instance: T) -> T:\n    r\"\"\"Register a container instance as `non-mappable`, i.e., it will be treated as a singleton object in\n    :func:`map_structure` and :func:`map_structure_zip`, its contents will not be traversed.\n\n    :param instance: The container instance.\n    \"\"\"\n", "metadata": {"task_id": "flutes/1", "ground_truth": "    try:\n        setattr(instance, _NO_MAP_INSTANCE_ATTR, True)\n        return instance\n    except AttributeError:\n        return _no_map_type(type(instance))(instance)", "fpath_tuple": ["flutes", "flutes", "structure.py"], "context_start_lineno": 60, "line_no": 66, "id": 379, "target_function_prompt": "def no_map_instance(instance: T) -> T:\n    r\"\"\"Register a container instance as `non-mappable`, i.e., it will be treated as a singleton object in\n    :func:`map_structure` and :func:`map_structure_zip`, its contents will not be traversed.\n\n    :param instance: The container instance.\n    \"\"\"\n", "function_signature": "def no_map_instance(instance: T) -> T:"}}
{"prompt": "def map_structure(fn: Callable[[T], R], obj: Collection[T]) -> Collection[R]:\n    r\"\"\"Map a function over all elements in a (possibly nested) collection.\n\n    :param fn: The function to call on elements.\n    :param obj: The collection to map function over.\n    :return: The collection in the same structure, with elements mapped.\n    \"\"\"\n", "metadata": {"task_id": "flutes/2", "ground_truth": "    if obj.__class__ in _NO_MAP_TYPES or hasattr(obj, _NO_MAP_INSTANCE_ATTR):\n        return fn(obj)\n    if isinstance(obj, list):\n        return [map_structure(fn, x) for x in obj]\n    if isinstance(obj, tuple):\n        if hasattr(obj, '_fields'):  # namedtuple\n            return type(obj)(*[map_structure(fn, x) for x in obj])\n        else:\n            return tuple(map_structure(fn, x) for x in obj)\n    if isinstance(obj, dict):\n        # could be `OrderedDict`\n        return type(obj)((k, map_structure(fn, v)) for k, v in obj.items())\n    if isinstance(obj, set):\n        return {map_structure(fn, x) for x in obj}\n    return fn(obj)", "fpath_tuple": ["flutes", "flutes", "structure.py"], "context_start_lineno": 74, "line_no": 81, "id": 380, "target_function_prompt": "def map_structure(fn: Callable[[T], R], obj: Collection[T]) -> Collection[R]:\n    r\"\"\"Map a function over all elements in a (possibly nested) collection.\n\n    :param fn: The function to call on elements.\n    :param obj: The collection to map function over.\n    :return: The collection in the same structure, with elements mapped.\n    \"\"\"\n", "function_signature": "def map_structure(fn: Callable[[T], R], obj: Collection[T]) -> Collection[R]:"}}
{"prompt": "def map_structure_zip(fn: Callable[..., R], objs: Sequence[Collection[T]]) -> Collection[R]:\n    r\"\"\"Map a function over tuples formed by taking one elements from each (possibly nested) collection. Each collection\n    must have identical structures.\n\n    .. note::\n    Although identical structures are required, it is not enforced by assertions. The structure of the first\n    collection is assumed to be the structure for all collections.\n\n    :param fn: The function to call on elements.\n    :param objs: The list of collections to map function over.\n    :return: A collection with the same structure, with elements mapped.\n    \"\"\"\n", "metadata": {"task_id": "flutes/3", "ground_truth": "    obj = objs[0]\n    if obj.__class__ in _NO_MAP_TYPES or hasattr(obj, _NO_MAP_INSTANCE_ATTR):\n        return fn(*objs)\n    if isinstance(obj, list):\n        return [map_structure_zip(fn, xs) for xs in zip(*objs)]\n    if isinstance(obj, tuple):\n        if hasattr(obj, '_fields'):  # namedtuple\n            return type(obj)(*[map_structure_zip(fn, xs) for xs in zip(*objs)])\n        else:\n            return tuple(map_structure_zip(fn, xs) for xs in zip(*objs))\n    if isinstance(obj, dict):\n        # could be `OrderedDict`\n        return type(obj)((k, map_structure_zip(fn, [o[k] for o in objs])) for k in obj.keys())\n    if isinstance(obj, set):\n        raise ValueError(\"Structures cannot contain `set` because it's unordered\")\n    return fn(*objs)", "fpath_tuple": ["flutes", "flutes", "structure.py"], "context_start_lineno": 99, "line_no": 111, "id": 381, "target_function_prompt": "def map_structure_zip(fn: Callable[..., R], objs: Sequence[Collection[T]]) -> Collection[R]:\n    r\"\"\"Map a function over tuples formed by taking one elements from each (possibly nested) collection. Each collection\n    must have identical structures.\n\n    .. note::\n    Although identical structures are required, it is not enforced by assertions. The structure of the first\n    collection is assumed to be the structure for all collections.\n\n    :param fn: The function to call on elements.\n    :param objs: The list of collections to map function over.\n    :return: A collection with the same structure, with elements mapped.\n    \"\"\"\n", "function_signature": "def map_structure_zip(fn: Callable[..., R], objs: Sequence[Collection[T]]) -> Collection[R]:"}}
{"prompt": "def ceil_div(a: int, b: int) -> int:\n    r\"\"\"Integer division that rounds up.\"\"\"\n", "metadata": {"task_id": "flutes/4", "ground_truth": "    return (a - 1) // b + 1", "fpath_tuple": ["flutes", "flutes", "math.py"], "context_start_lineno": 5, "line_no": 7, "id": 382, "target_function_prompt": "def ceil_div(a: int, b: int) -> int:\n    r\"\"\"Integer division that rounds up.\"\"\"\n", "function_signature": "def ceil_div(a: int, b: int) -> int:"}}
{"prompt": "def chunk(n: int, iterable: Iterable[T]) -> Iterator[List[T]]:\n    r\"\"\"Split the iterable into chunks, with each chunk containing no more than ``n`` elements.\n\n    .. code:: python\n\n    >>> list(chunk(3, range(10)))\n    [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n\n    :param n: The maximum number of elements in one chunk.\n    :param iterable: The iterable.\n    :return: An iterator over chunks.\n    \"\"\"\n", "metadata": {"task_id": "flutes/5", "ground_truth": "    if n <= 0:\n        raise ValueError(\"`n` should be positive\")\n    group = []\n    for x in iterable:\n        group.append(x)\n        if len(group) == n:\n            yield group\n            group = []\n    if len(group) > 0:\n        yield group", "fpath_tuple": ["flutes", "flutes", "iterator.py"], "context_start_lineno": 22, "line_no": 34, "id": 383, "target_function_prompt": "def chunk(n: int, iterable: Iterable[T]) -> Iterator[List[T]]:\n    r\"\"\"Split the iterable into chunks, with each chunk containing no more than ``n`` elements.\n\n    .. code:: python\n\n    >>> list(chunk(3, range(10)))\n    [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n\n    :param n: The maximum number of elements in one chunk.\n    :param iterable: The iterable.\n    :return: An iterator over chunks.\n    \"\"\"\n", "function_signature": "def chunk(n: int, iterable: Iterable[T]) -> Iterator[List[T]]:"}}
{"prompt": "def take(n: int, iterable: Iterable[T]) -> Iterator[T]:\n    r\"\"\"Take the first :attr:`n` elements from an iterable.\n\n    .. code:: python\n\n    >>> list(take(5, range(1000000)))\n    [0, 1, 2, 3, 4]\n\n    :param n: The number of elements to take.\n    :param iterable: The iterable.\n    :return: An iterator returning the first :attr:`n` elements from the iterable.\n    \"\"\"\n", "metadata": {"task_id": "flutes/6", "ground_truth": "    if n < 0:\n        raise ValueError(\"`n` should be non-negative\")\n    try:\n        it = iter(iterable)\n        for _ in range(n):\n            yield next(it)\n    except StopIteration:\n        pass", "fpath_tuple": ["flutes", "flutes", "iterator.py"], "context_start_lineno": 46, "line_no": 58, "id": 384, "target_function_prompt": "def take(n: int, iterable: Iterable[T]) -> Iterator[T]:\n    r\"\"\"Take the first :attr:`n` elements from an iterable.\n\n    .. code:: python\n\n    >>> list(take(5, range(1000000)))\n    [0, 1, 2, 3, 4]\n\n    :param n: The number of elements to take.\n    :param iterable: The iterable.\n    :return: An iterator returning the first :attr:`n` elements from the iterable.\n    \"\"\"\n", "function_signature": "def take(n: int, iterable: Iterable[T]) -> Iterator[T]:"}}
{"prompt": "def drop(n: int, iterable: Iterable[T]) -> Iterator[T]:\n    r\"\"\"Drop the first :attr:`n` elements from an iterable, and return the rest as an iterator.\n\n    .. code:: python\n\n    >>> next(drop(5, range(1000000)))\n    5\n\n    :param n: The number of elements to drop.\n    :param iterable: The iterable.\n    :return: An iterator returning the remaining part of the iterable after the first :attr:`n` elements.\n    \"\"\"\n", "metadata": {"task_id": "flutes/7", "ground_truth": "    if n < 0:\n        raise ValueError(\"`n` should be non-negative\")\n    try:\n        it = iter(iterable)\n        for _ in range(n):\n            next(it)\n        yield from it\n    except StopIteration:\n        pass", "fpath_tuple": ["flutes", "flutes", "iterator.py"], "context_start_lineno": 68, "line_no": 80, "id": 385, "target_function_prompt": "def drop(n: int, iterable: Iterable[T]) -> Iterator[T]:\n    r\"\"\"Drop the first :attr:`n` elements from an iterable, and return the rest as an iterator.\n\n    .. code:: python\n\n    >>> next(drop(5, range(1000000)))\n    5\n\n    :param n: The number of elements to drop.\n    :param iterable: The iterable.\n    :return: An iterator returning the remaining part of the iterable after the first :attr:`n` elements.\n    \"\"\"\n", "function_signature": "def drop(n: int, iterable: Iterable[T]) -> Iterator[T]:"}}
{"prompt": "def drop_until(pred_fn: Callable[[T], bool], iterable: Iterable[T]) -> Iterator[T]:\n    r\"\"\"Drop elements from the iterable until an element that satisfies the predicate is encountered. Similar to the\n    built-in :py:func:`filter` function, but only applied to a prefix of the iterable.\n\n    .. code:: python\n\n    >>> list(drop_until(lambda x: x > 5, range(10)))\n    [6, 7, 8, 9]\n\n    :param pred_fn: The predicate that returned elements should satisfy.\n    :param iterable: The iterable.\n    :return: The iterator after dropping elements.\n    \"\"\"\n", "metadata": {"task_id": "flutes/8", "ground_truth": "    iterator = iter(iterable)\n    for item in iterator:\n        if not pred_fn(item):\n            continue\n        yield item\n        break\n    yield from iterator", "fpath_tuple": ["flutes", "flutes", "iterator.py"], "context_start_lineno": 91, "line_no": 104, "id": 386, "target_function_prompt": "def drop_until(pred_fn: Callable[[T], bool], iterable: Iterable[T]) -> Iterator[T]:\n    r\"\"\"Drop elements from the iterable until an element that satisfies the predicate is encountered. Similar to the\n    built-in :py:func:`filter` function, but only applied to a prefix of the iterable.\n\n    .. code:: python\n\n    >>> list(drop_until(lambda x: x > 5, range(10)))\n    [6, 7, 8, 9]\n\n    :param pred_fn: The predicate that returned elements should satisfy.\n    :param iterable: The iterable.\n    :return: The iterator after dropping elements.\n    \"\"\"\n", "function_signature": "def drop_until(pred_fn: Callable[[T], bool], iterable: Iterable[T]) -> Iterator[T]:"}}
{"prompt": "def split_by(iterable: Iterable[A], empty_segments: bool = False, *, criterion=None, separator=None) \\\n        -> Iterator[List[A]]:\n    r\"\"\"Split a list into sub-lists by dropping certain elements. Exactly one of ``criterion`` and ``separator`` must be\n    specified. For example:\n\n    .. code:: python\n\n    >>> list(split_by(range(10), criterion=lambda x: x % 3 == 0))\n    [[1, 2], [4, 5], [7, 8]]\n\n    >>> list(split_by(\" Split by: \", empty_segments=True, separator='.'))\n    [[], ['S', 'p', 'l', 'i', 't'], ['b', 'y', ':'], []]\n\n    :param iterable: The list to split.\n    :param empty_segments: If ``True``, include an empty list in cases where two adjacent elements satisfy\n    the criterion.\n    :param criterion: The criterion to decide whether to drop an element.\n    :param separator: The separator for sub-lists. An element is dropped if it is equal to ``parameter``.\n    :return: List of sub-lists.\n    \"\"\"\n", "metadata": {"task_id": "flutes/9", "ground_truth": "    if not ((criterion is None) ^ (separator is None)):\n        raise ValueError(\"Exactly one of `criterion` and `separator` should be specified\")\n    if criterion is None:\n        criterion = lambda x: x == separator\n    group = []\n    for x in iterable:\n        if not criterion(x):\n            group.append(x)\n        else:\n            if len(group) > 0 or empty_segments:\n                yield group\n            group = []\n    if len(group) > 0 or empty_segments:\n        yield group", "fpath_tuple": ["flutes", "flutes", "iterator.py"], "context_start_lineno": 123, "line_no": 143, "id": 387, "target_function_prompt": "def split_by(iterable: Iterable[A], empty_segments: bool = False, *, criterion=None, separator=None) \\\n        -> Iterator[List[A]]:\n    r\"\"\"Split a list into sub-lists by dropping certain elements. Exactly one of ``criterion`` and ``separator`` must be\n    specified. For example:\n\n    .. code:: python\n\n    >>> list(split_by(range(10), criterion=lambda x: x % 3 == 0))\n    [[1, 2], [4, 5], [7, 8]]\n\n    >>> list(split_by(\" Split by: \", empty_segments=True, separator='.'))\n    [[], ['S', 'p', 'l', 'i', 't'], ['b', 'y', ':'], []]\n\n    :param iterable: The list to split.\n    :param empty_segments: If ``True``, include an empty list in cases where two adjacent elements satisfy\n    the criterion.\n    :param criterion: The criterion to decide whether to drop an element.\n    :param separator: The separator for sub-lists. An element is dropped if it is equal to ``parameter``.\n    :return: List of sub-lists.\n    \"\"\"\n", "function_signature": "def split_by(iterable: Iterable[A], empty_segments: bool = False, *, criterion=None, separator=None) \\\n        -> Iterator[List[A]]:"}}
{"prompt": "def scanr(func, iterable, *args):\n    r\"\"\"Computes the intermediate results of :py:func:`~functools.reduce` applied in reverse. Equivalent to Haskell's\n    ``scanr``. For example:\n\n    .. code:: python\n\n    >>> scanr(operator.add, [1, 2, 3, 4], 0)\n    [10, 9, 7, 4, 0]\n    >>> scanr(lambda s, x: x + s, ['a', 'b', 'c', 'd'])\n    ['abcd', 'bcd', 'cd', 'd']\n\n    Learn more at `Learn You a Haskell: Higher Order Functions <http://learnyouahaskell.com/higher-order-functions>`_.\n\n    :param func: The function to apply. This should be a binary function where the arguments are: the accumulator,\n    and the current element.\n    :param iterable: The list of elements to iteratively apply the function to.\n    :param initial: The initial value for the accumulator. If not supplied, the first element in the list is used.\n    :return: The intermediate results at each step, starting from the end.\n    \"\"\"\n", "metadata": {"task_id": "flutes/10", "ground_truth": "    return list(scanl(func, reversed(iterable), *args))[::-1]", "fpath_tuple": ["flutes", "flutes", "iterator.py"], "context_start_lineno": 207, "line_no": 226, "id": 388, "target_function_prompt": "def scanr(func, iterable, *args):\n    r\"\"\"Computes the intermediate results of :py:func:`~functools.reduce` applied in reverse. Equivalent to Haskell's\n    ``scanr``. For example:\n\n    .. code:: python\n\n    >>> scanr(operator.add, [1, 2, 3, 4], 0)\n    [10, 9, 7, 4, 0]\n    >>> scanr(lambda s, x: x + s, ['a', 'b', 'c', 'd'])\n    ['abcd', 'bcd', 'cd', 'd']\n\n    Learn more at `Learn You a Haskell: Higher Order Functions <http://learnyouahaskell.com/higher-order-functions>`_.\n\n    :param func: The function to apply. This should be a binary function where the arguments are: the accumulator,\n    and the current element.\n    :param iterable: The list of elements to iteratively apply the function to.\n    :param initial: The initial value for the accumulator. If not supplied, the first element in the list is used.\n    :return: The intermediate results at each step, starting from the end.\n    \"\"\"\n", "function_signature": "def scanr(func, iterable, *args):"}}
{"prompt": "def _decode_letter_case_overrides(field_names, overrides):\n    \"\"\"Override letter case of field names for encode/decode\"\"\"\n", "metadata": {"task_id": "dataclasses-json/0", "ground_truth": "    names = {}\n    for field_name in field_names:\n        field_override = overrides.get(field_name)\n        if field_override is not None:\n            letter_case = field_override.letter_case\n            if letter_case is not None:\n                names[letter_case(field_name)] = field_name\n    return names", "fpath_tuple": ["dataclasses-json", "dataclasses_json", "core.py"], "context_start_lineno": 117, "line_no": 119, "id": 391, "target_function_prompt": "def _decode_letter_case_overrides(field_names, overrides):\n    \"\"\"Override letter case of field names for encode/decode\"\"\"\n", "function_signature": "def _decode_letter_case_overrides(field_names, overrides):"}}
{"prompt": "def _decode_dict_keys(key_type, xs, infer_missing):\n    \"\"\"\n    Because JSON object keys must be strs, we need the extra step of decoding\n    them back into the user's chosen python type\n    \"\"\"\n", "metadata": {"task_id": "dataclasses-json/1", "ground_truth": "    # handle NoneType keys... it's weird to type a Dict as NoneType keys\n    # but it's valid...\n    key_type = ((lambda x: x) if key_type is None or key_type == Any\n                else key_type)  # noqa: E721\n    return map(key_type, _decode_items(key_type, xs, infer_missing))", "fpath_tuple": ["dataclasses-json", "dataclasses_json", "core.py"], "context_start_lineno": 282, "line_no": 287, "id": 392, "target_function_prompt": "def _decode_dict_keys(key_type, xs, infer_missing):\n    \"\"\"\n    Because JSON object keys must be strs, we need the extra step of decoding\n    them back into the user's chosen python type\n    \"\"\"\n", "function_signature": "def _decode_dict_keys(key_type, xs, infer_missing):"}}
{"prompt": "def _decode_items(type_arg, xs, infer_missing):\n    \"\"\"\n    This is a tricky situation where we need to check both the annotated\n    type info (which is usually a type from `typing`) and check the\n    value's type directly using `type()`.\n\n    If the type_arg is a generic we can use the annotated type, but if the\n    type_arg is a typevar we need to extract the reified type information\n    hence the check of `is_dataclass(vs)`\n    \"\"\"\n", "metadata": {"task_id": "dataclasses-json/2", "ground_truth": "    if is_dataclass(type_arg) or is_dataclass(xs):\n        items = (_decode_dataclass(type_arg, x, infer_missing)\n                 for x in xs)\n    elif _is_supported_generic(type_arg):\n        items = (_decode_generic(type_arg, x, infer_missing) for x in xs)\n    else:\n        items = xs\n    return items", "fpath_tuple": ["dataclasses-json", "dataclasses_json", "core.py"], "context_start_lineno": 294, "line_no": 304, "id": 393, "target_function_prompt": "def _decode_items(type_arg, xs, infer_missing):\n    \"\"\"\n    This is a tricky situation where we need to check both the annotated\n    type info (which is usually a type from `typing`) and check the\n    value's type directly using `type()`.\n\n    If the type_arg is a generic we can use the annotated type, but if the\n    type_arg is a typevar we need to extract the reified type information\n    hence the check of `is_dataclass(vs)`\n    \"\"\"\n", "function_signature": "def _decode_items(type_arg, xs, infer_missing):"}}
{"prompt": "def _asdict(obj, encode_json=False):\n    \"\"\"\n    A re-implementation of `asdict` (based on the original in the `dataclasses`\n    source) to support arbitrary Collection and Mapping types.\n    \"\"\"\n", "metadata": {"task_id": "dataclasses-json/3", "ground_truth": "    if _is_dataclass_instance(obj):\n        result = []\n        for field in fields(obj):\n            value = _asdict(getattr(obj, field.name), encode_json=encode_json)\n            result.append((field.name, value))\n\n        result = _handle_undefined_parameters_safe(cls=obj, kvs=dict(result),\n                                                   usage=\"to\")\n        return _encode_overrides(dict(result), _user_overrides_or_exts(obj),\n                                 encode_json=encode_json)\n    elif isinstance(obj, Mapping):\n        return dict((_asdict(k, encode_json=encode_json),\n                     _asdict(v, encode_json=encode_json)) for k, v in\n                    obj.items())\n    elif isinstance(obj, Collection) and not isinstance(obj, str) \\\n            and not isinstance(obj, bytes):\n        return list(_asdict(v, encode_json=encode_json) for v in obj)\n    else:\n        return copy.deepcopy(obj)", "fpath_tuple": ["dataclasses-json", "dataclasses_json", "core.py"], "context_start_lineno": 314, "line_no": 319, "id": 394, "target_function_prompt": "def _asdict(obj, encode_json=False):\n    \"\"\"\n    A re-implementation of `asdict` (based on the original in the `dataclasses`\n    source) to support arbitrary Collection and Mapping types.\n    \"\"\"\n", "function_signature": "def _asdict(obj, encode_json=False):"}}
{"prompt": "def dataclass_json(_cls=None, *, letter_case=None,\n                   undefined: Optional[Union[str, Undefined]] = None):\n    \"\"\"\n    Based on the code in the `dataclasses` module to handle optional-parens\n    decorators. See example below:\n\n    @dataclass_json\n    @dataclass_json(letter_case=LetterCase.CAMEL)\n    class Example:\n    ...\n    \"\"\"\n", "metadata": {"task_id": "dataclasses-json/4", "ground_truth": "\n    def wrap(cls):\n        return _process_class(cls, letter_case, undefined)\n\n    if _cls is None:\n        return wrap\n    return wrap(_cls)", "fpath_tuple": ["dataclasses-json", "dataclasses_json", "api.py"], "context_start_lineno": 117, "line_no": 128, "id": 395, "target_function_prompt": "def dataclass_json(_cls=None, *, letter_case=None,\n                   undefined: Optional[Union[str, Undefined]] = None):\n    \"\"\"\n    Based on the code in the `dataclasses` module to handle optional-parens\n    decorators. See example below:\n\n    @dataclass_json\n    @dataclass_json(letter_case=LetterCase.CAMEL)\n    class Example:\n    ...\n    \"\"\"\n", "function_signature": "def dataclass_json(_cls=None, *, letter_case=None,\n                   undefined: Optional[Union[str, Undefined]] = None):"}}
{"prompt": "def _get_type_origin(type_):\n    \"\"\"Some spaghetti logic to accommodate differences between 3.6 and 3.7 in\n    the typing api\"\"\"\n", "metadata": {"task_id": "dataclasses-json/5", "ground_truth": "    try:\n        origin = type_.__origin__\n    except AttributeError:\n        if sys.version_info.minor == 6:\n            try:\n                origin = type_.__extra__\n            except AttributeError:\n                origin = type_\n            else:\n                origin = type_ if origin is None else origin\n        else:\n            origin = type_\n    return origin", "fpath_tuple": ["dataclasses-json", "dataclasses_json", "utils.py"], "context_start_lineno": 28, "line_no": 31, "id": 396, "target_function_prompt": "def _get_type_origin(type_):\n    \"\"\"Some spaghetti logic to accommodate differences between 3.6 and 3.7 in\n    the typing api\"\"\"\n", "function_signature": "def _get_type_origin(type_):"}}
{"prompt": "def _get_normal_name(orig_enc: str) -> str:\n    \"\"\"Imitates get_normal_name in tokenizer.c.\"\"\"\n", "metadata": {"task_id": "black/0", "ground_truth": "    # Only care about the first 12 characters.\n    enc = orig_enc[:12].lower().replace(\"_\", \"-\")\n    if enc == \"utf-8\" or enc.startswith(\"utf-8-\"):\n        return \"utf-8\"\n    if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or enc.startswith(\n        (\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")\n    ):\n        return \"iso-8859-1\"\n    return orig_enc", "fpath_tuple": ["black", "src", "blib2to3", "pgen2", "tokenize.py"], "context_start_lineno": 291, "line_no": 293, "id": 397, "target_function_prompt": "def _get_normal_name(orig_enc: str) -> str:\n    \"\"\"Imitates get_normal_name in tokenizer.c.\"\"\"\n", "function_signature": "def _get_normal_name(orig_enc: str) -> str:"}}
{"prompt": "def detect_encoding(readline: Callable[[], bytes]) -> Tuple[str, List[bytes]]:\n    \"\"\"\n    The detect_encoding() function is used to detect the encoding that should\n    be used to decode a Python source file. It requires one argument, readline,\n    in the same way as the tokenize() generator.\n\n    It will call readline a maximum of twice, and return the encoding used\n    (as a string) and a list of any lines (left as bytes) it has read\n    in.\n\n    It detects the encoding from the presence of a utf-8 bom or an encoding\n    cookie as specified in pep-0263. If both a bom and a cookie are present, but\n    disagree, a SyntaxError will be raised. If the encoding cookie is an invalid\n    charset, raise a SyntaxError.  Note that if a utf-8 bom is found,\n    'utf-8-sig' is returned.\n\n    If no encoding is specified, then the default of 'utf-8' will be returned.\n    \"\"\"\n", "metadata": {"task_id": "black/1", "ground_truth": "    bom_found = False\n    encoding = None\n    default = \"utf-8\"\n\n    def read_or_stop() -> bytes:\n        try:\n            return readline()\n        except StopIteration:\n            return bytes()\n\n    def find_cookie(line: bytes) -> Optional[str]:\n        try:\n            line_string = line.decode(\"ascii\")\n        except UnicodeDecodeError:\n            return None\n        match = cookie_re.match(line_string)\n        if not match:\n            return None\n        encoding = _get_normal_name(match.group(1))\n        try:\n            codec = lookup(encoding)\n        except LookupError:\n            # This behaviour mimics the Python interpreter\n            raise SyntaxError(\"unknown encoding: \" + encoding)\n\n        if bom_found:\n            if codec.name != \"utf-8\":\n                # This behaviour mimics the Python interpreter\n                raise SyntaxError(\"encoding problem: utf-8\")\n            encoding += \"-sig\"\n        return encoding\n\n    first = read_or_stop()\n    if first.startswith(BOM_UTF8):\n        bom_found = True\n        first = first[3:]\n        default = \"utf-8-sig\"\n    if not first:\n        return default, []\n\n    encoding = find_cookie(first)\n    if encoding:\n        return encoding, [first]\n    if not blank_re.match(first):\n        return default, [first]\n\n    second = read_or_stop()\n    if not second:\n        return default, [first]\n\n    encoding = find_cookie(second)\n    if encoding:\n        return encoding, [first, second]\n\n    return default, [first, second]", "fpath_tuple": ["black", "src", "blib2to3", "pgen2", "tokenize.py"], "context_start_lineno": 304, "line_no": 322, "id": 398, "target_function_prompt": "def detect_encoding(readline: Callable[[], bytes]) -> Tuple[str, List[bytes]]:\n    \"\"\"\n    The detect_encoding() function is used to detect the encoding that should\n    be used to decode a Python source file. It requires one argument, readline,\n    in the same way as the tokenize() generator.\n\n    It will call readline a maximum of twice, and return the encoding used\n    (as a string) and a list of any lines (left as bytes) it has read\n    in.\n\n    It detects the encoding from the presence of a utf-8 bom or an encoding\n    cookie as specified in pep-0263. If both a bom and a cookie are present, but\n    disagree, a SyntaxError will be raised. If the encoding cookie is an invalid\n    charset, raise a SyntaxError.  Note that if a utf-8 bom is found,\n    'utf-8-sig' is returned.\n\n    If no encoding is specified, then the default of 'utf-8' will be returned.\n    \"\"\"\n", "function_signature": "def detect_encoding(readline: Callable[[], bytes]) -> Tuple[str, List[bytes]]:"}}
{"prompt": "def untokenize(iterable: Iterable[TokenInfo]) -> Text:\n    \"\"\"Transform tokens back into Python source code.\n\n    Each element returned by the iterable must be a token sequence\n    with at least two elements, a token number and token value.  If\n    only two tokens are passed, the resulting output is poor.\n\n    Round-trip invariant for full input:\n    Untokenized source will match input source exactly\n\n    Round-trip invariant for limited input:\n    # Output text will tokenize the back to the input\n    t1 = [tok[:2] for tok in generate_tokens(f.readline)]\n    newcode = untokenize(t1)\n    readline = iter(newcode.splitlines(1)).next\n    t2 = [tok[:2] for tokin generate_tokens(readline)]\n    assert t1 == t2\n    \"\"\"\n", "metadata": {"task_id": "black/2", "ground_truth": "    ut = Untokenizer()\n    return ut.untokenize(iterable)", "fpath_tuple": ["black", "src", "blib2to3", "pgen2", "tokenize.py"], "context_start_lineno": 379, "line_no": 397, "id": 399, "target_function_prompt": "def untokenize(iterable: Iterable[TokenInfo]) -> Text:\n    \"\"\"Transform tokens back into Python source code.\n\n    Each element returned by the iterable must be a token sequence\n    with at least two elements, a token number and token value.  If\n    only two tokens are passed, the resulting output is poor.\n\n    Round-trip invariant for full input:\n    Untokenized source will match input source exactly\n\n    Round-trip invariant for limited input:\n    # Output text will tokenize the back to the input\n    t1 = [tok[:2] for tok in generate_tokens(f.readline)]\n    newcode = untokenize(t1)\n    readline = iter(newcode.splitlines(1)).next\n    t2 = [tok[:2] for tokin generate_tokens(readline)]\n    assert t1 == t2\n    \"\"\"\n", "function_signature": "def untokenize(iterable: Iterable[TokenInfo]) -> Text:"}}
{"prompt": "def normalize_repr(item_repr):\n    \"\"\"Remove memory address (0x...) from a default python repr\"\"\"\n", "metadata": {"task_id": "PySnooper/0", "ground_truth": "    return DEFAULT_REPR_RE.sub('', item_repr)", "fpath_tuple": ["PySnooper", "pysnooper", "utils.py"], "context_start_lineno": 61, "line_no": 63, "id": 401, "target_function_prompt": "def normalize_repr(item_repr):\n    \"\"\"Remove memory address (0x...) from a default python repr\"\"\"\n", "function_signature": "def normalize_repr(item_repr):"}}
